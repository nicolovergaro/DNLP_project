{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-11-25T11:30:27.648952Z",
     "iopub.status.busy": "2022-11-25T11:30:27.648547Z",
     "iopub.status.idle": "2022-11-25T11:31:12.274720Z",
     "shell.execute_reply": "2022-11-25T11:31:12.273312Z",
     "shell.execute_reply.started": "2022-11-25T11:30:27.648918Z"
    },
    "id": "QfcVgkWiRUGE",
    "outputId": "e3f6ea02-8e8e-4f65-ccd2-24e6c9f68792"
   },
   "outputs": [],
   "source": [
    "!pip install evaluate\n",
    "!pip install transformers --upgrade\n",
    "!pip install bert_score\n",
    "!pip install rouge_score\n",
    "!pip uninstall huggingface_hub\n",
    "!pip install huggingface_hub --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-11-25T11:30:13.610304Z",
     "iopub.status.busy": "2022-11-25T11:30:13.609640Z",
     "iopub.status.idle": "2022-11-25T11:30:21.082446Z",
     "shell.execute_reply": "2022-11-25T11:30:21.081175Z",
     "shell.execute_reply.started": "2022-11-25T11:30:13.610189Z"
    },
    "id": "qhm5z8h7RGqx",
    "outputId": "95bc1b0d-79a5-4ce8-ecf9-4a766da9ca47"
   },
   "outputs": [],
   "source": [
    "!git clone https://[USERNAME]:[TOKEN]@github.com/nicolovergaro/DNLP_project.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-11-25T11:30:21.086525Z",
     "iopub.status.busy": "2022-11-25T11:30:21.085819Z",
     "iopub.status.idle": "2022-11-25T11:30:21.095200Z",
     "shell.execute_reply": "2022-11-25T11:30:21.094185Z",
     "shell.execute_reply.started": "2022-11-25T11:30:21.086464Z"
    },
    "id": "IC8B2bkjRKbA",
    "outputId": "355a09bf-b8e4-420c-f7c9-cf740025716e"
   },
   "outputs": [],
   "source": [
    "%cd /kaggle/working/DNLP_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-11-25T11:30:22.268599Z",
     "iopub.status.busy": "2022-11-25T11:30:22.268107Z",
     "iopub.status.idle": "2022-11-25T11:30:27.644706Z",
     "shell.execute_reply": "2022-11-25T11:30:27.643092Z",
     "shell.execute_reply.started": "2022-11-25T11:30:22.268550Z"
    },
    "id": "IZfysvumsTxV",
    "outputId": "53f1f593-84a7-4ca3-deab-fcca858d4e77"
   },
   "outputs": [],
   "source": [
    "!unzip microCSPubSumm.zip\n",
    "!unzip microBIOPubSumm.zip\n",
    "!unzip microAIPubSumm.zip\n",
    "!unzip microMiscPubSumm.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-25T11:31:12.278622Z",
     "iopub.status.busy": "2022-11-25T11:31:12.278177Z",
     "iopub.status.idle": "2022-11-25T11:31:25.720236Z",
     "shell.execute_reply": "2022-11-25T11:31:25.718329Z",
     "shell.execute_reply.started": "2022-11-25T11:31:12.278582Z"
    },
    "id": "TK7wfbDORPTu"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, TrainingArguments, Trainer\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from huggingface_hub import login, logout\n",
    "\n",
    "from utils.reproducibility import *\n",
    "from utils.datasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-25T11:31:25.727188Z",
     "iopub.status.busy": "2022-11-25T11:31:25.725890Z",
     "iopub.status.idle": "2022-11-25T11:31:28.552640Z",
     "shell.execute_reply": "2022-11-25T11:31:28.551624Z",
     "shell.execute_reply.started": "2022-11-25T11:31:25.727147Z"
    },
    "id": "YX2g5dIPWVka"
   },
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained(\"sshleifer/distilbart-cnn-12-6\")\n",
    "\n",
    "make_it_reproducible()\n",
    "# misc datasets\n",
    "train_ds = TitleGenDataset(\"microMiscPubSumm_train.json\", tokenizer, 1024, 32)\n",
    "# to reduce the train dataset to work with to 2000 elements\n",
    "micro_train_ds, _ = random_split(train_ds, [2000, len(train_ds)-2000], generator=get_generator())\n",
    "test_ds = TitleGenDataset(\"microMiscPubSumm_test.json\", tokenizer, 1024, 32)\n",
    "# to reduce the test dataset to work with to 200 elements\n",
    "micro_test_ds, _ = random_split(test_ds, [200, len(test_ds)-200], generator=get_generator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-25T11:31:28.556805Z",
     "iopub.status.busy": "2022-11-25T11:31:28.555271Z",
     "iopub.status.idle": "2022-11-25T11:31:29.194148Z",
     "shell.execute_reply": "2022-11-25T11:31:29.193151Z",
     "shell.execute_reply.started": "2022-11-25T11:31:28.556751Z"
    },
    "id": "XlTa2tM_Wjsi"
   },
   "outputs": [],
   "source": [
    "bertscore = evaluate.load(\"bertscore\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "# function to extract the encodings predicted by the model\n",
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    pred_ids = torch.argmax(logits[0], dim=-1)\n",
    "    return pred_ids, labels\n",
    "\n",
    "# function to compute the metric on which the trainer decides the best model\n",
    "def compute_metric(pred):\n",
    "    label_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions[0]\n",
    "\n",
    "    # extraction of the 2 strings (predicted and original)\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    # for debug porpuses\n",
    "    print(\"pred:\", pred_str[0], \"\\n original:\", label_str[0])\n",
    "\n",
    "    rg_out = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"])\n",
    "\n",
    "    bs_res = bertscore.compute(predictions=pred_str, references=label_str, lang=\"en\")\n",
    "\n",
    "    return {\n",
    "        \"bertscore\": round(np.mean(bs_res[\"recall\"]), 4),\n",
    "        \"R1\": round(rg_out[\"rouge1\"], 4),\n",
    "        \"R2\": round(rg_out[\"rouge2\"], 4),\n",
    "        \"RL\": round(rg_out[\"rougeL\"], 4),\n",
    "        \"RLsum\": round(rg_out[\"rougeLsum\"], 4)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First tuning on misc-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-25T10:20:30.107871Z",
     "iopub.status.busy": "2022-11-25T10:20:30.107404Z",
     "iopub.status.idle": "2022-11-25T10:21:27.835562Z",
     "shell.execute_reply": "2022-11-25T10:21:27.834513Z",
     "shell.execute_reply.started": "2022-11-25T10:20:30.107808Z"
    },
    "id": "2_cTftIwYXgX"
   },
   "outputs": [],
   "source": [
    "# original bart distil model\n",
    "model = BartForConditionalGeneration.from_pretrained(\"sshleifer/distilbart-cnn-12-6\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    warmup_steps=100,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=1e-2,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"bertscore\"  # change to choose based on other metrics like R1, R2, RL, RLsum\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=micro_train_ds,\n",
    "    eval_dataset=micro_test_ds,\n",
    "    compute_metrics=compute_metric,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "execution": {
     "iopub.execute_input": "2022-11-25T10:21:27.837924Z",
     "iopub.status.busy": "2022-11-25T10:21:27.837530Z",
     "iopub.status.idle": "2022-11-25T10:32:17.976839Z",
     "shell.execute_reply": "2022-11-25T10:32:17.975801Z",
     "shell.execute_reply.started": "2022-11-25T10:21:27.837886Z"
    },
    "id": "poyHwjw7aq7F",
    "outputId": "87e7d707-0471-4b62-ca06-ee36709077ab"
   },
   "outputs": [],
   "source": [
    "make_it_reproducible()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-25T10:33:35.435010Z",
     "iopub.status.busy": "2022-11-25T10:33:35.434608Z",
     "iopub.status.idle": "2022-11-25T10:33:39.041442Z",
     "shell.execute_reply": "2022-11-25T10:33:39.040394Z",
     "shell.execute_reply.started": "2022-11-25T10:33:35.434969Z"
    }
   },
   "outputs": [],
   "source": [
    "# save the model locally\n",
    "trainer.save_model(\"./misc_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-25T11:21:47.419702Z",
     "iopub.status.busy": "2022-11-25T11:21:47.419329Z",
     "iopub.status.idle": "2022-11-25T11:21:58.729695Z",
     "shell.execute_reply": "2022-11-25T11:21:58.727946Z",
     "shell.execute_reply.started": "2022-11-25T11:21:47.419667Z"
    }
   },
   "outputs": [],
   "source": [
    "# login to huggingface to save the model online\n",
    "login(\"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\")\n",
    "\n",
    "trainer.model.push_to_hub(\"titlist-bart-misc-2000\")\n",
    "\n",
    "logout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning on AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-25T11:31:29.196217Z",
     "iopub.status.busy": "2022-11-25T11:31:29.195516Z",
     "iopub.status.idle": "2022-11-25T11:31:29.210436Z",
     "shell.execute_reply": "2022-11-25T11:31:29.209575Z",
     "shell.execute_reply.started": "2022-11-25T11:31:29.196173Z"
    }
   },
   "outputs": [],
   "source": [
    "# ai datasets\n",
    "ai_ds = TitleGenDataset(\"microAIPubSumm_train.json\", tokenizer, 1024, 32)\n",
    "ai_ds_test = TitleGenDataset(\"microAIPubSumm_test.json\", tokenizer, 1024, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-25T11:35:41.034310Z",
     "iopub.status.busy": "2022-11-25T11:35:41.033895Z",
     "iopub.status.idle": "2022-11-25T11:35:46.415891Z",
     "shell.execute_reply": "2022-11-25T11:35:46.414814Z",
     "shell.execute_reply.started": "2022-11-25T11:35:41.034278Z"
    }
   },
   "outputs": [],
   "source": [
    "login(\"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\")  # read token, the model is private\n",
    "model = BartForConditionalGeneration.from_pretrained(\"pietrocagnasso/titlist-bart-misc-2000\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_ai\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    warmup_steps=60,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=1e-2,\n",
    "    logging_dir=\"./logs_ai\",\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"bertscore\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ai_ds,\n",
    "    eval_dataset=ai_ds_test,\n",
    "    compute_metrics=compute_metric,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-25T11:35:51.995323Z",
     "iopub.status.busy": "2022-11-25T11:35:51.994337Z",
     "iopub.status.idle": "2022-11-25T11:43:24.323160Z",
     "shell.execute_reply": "2022-11-25T11:43:24.322172Z",
     "shell.execute_reply.started": "2022-11-25T11:35:51.995285Z"
    }
   },
   "outputs": [],
   "source": [
    "make_it_reproducible()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-25T11:43:41.326827Z",
     "iopub.status.busy": "2022-11-25T11:43:41.326275Z",
     "iopub.status.idle": "2022-11-25T11:43:49.197562Z",
     "shell.execute_reply": "2022-11-25T11:43:49.196450Z",
     "shell.execute_reply.started": "2022-11-25T11:43:41.326785Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.save_model(\"./ai_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-25T10:56:26.975527Z",
     "iopub.status.busy": "2022-11-25T10:56:26.975157Z",
     "iopub.status.idle": "2022-11-25T10:56:32.586609Z",
     "shell.execute_reply": "2022-11-25T10:56:32.583333Z",
     "shell.execute_reply.started": "2022-11-25T10:56:26.975496Z"
    }
   },
   "outputs": [],
   "source": [
    "# login to huggingface to save the model online\n",
    "login(\"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\")\n",
    "\n",
    "trainer.model.push_to_hub(\"titlist-bart-ai\")\n",
    "\n",
    "logout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cagliero, La Quatra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-25T11:45:25.838354Z",
     "iopub.status.busy": "2022-11-25T11:45:25.837987Z",
     "iopub.status.idle": "2022-11-25T11:45:26.313770Z",
     "shell.execute_reply": "2022-11-25T11:45:26.312745Z",
     "shell.execute_reply.started": "2022-11-25T11:45:25.838320Z"
    }
   },
   "outputs": [],
   "source": [
    "s = \"We propose a novel Transformer-based Highlights Extractor (THExt, in short). We achieve performance superior to state-of-the-art highlights extraction methods. Section-level context encoding turns out to be very effective for sentence ranking. Highlights are short sentences used to annotate scientific papers. They complement the abstract content by conveying the main result findings. To automate the process of paper annotation, highlights extraction aims at extracting from 3 to 5 paper sentences via supervised learning. Existing approaches rely on ad hoc linguistic features, which depend on the analyzed context, and apply recurrent neural networks, which are not effective in learning long-range text dependencies. This paper leverages the attention mechanism adopted in transformer models to improve the accuracy of sentence relevance estimation. Unlike existing approaches, it relies on the end-to-end training of a deep regression model. To attend patterns relevant to highlights content it also enriches sentence encodings with a section-level contextualization. The experimental results, achieved on three different benchmark datasets, show that the designed architecture is able to achieve significant performance improvements compared to the state-of-the-art.\"\n",
    "\n",
    "ins = tokenizer.encode(s, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-25T11:45:26.771693Z",
     "iopub.status.busy": "2022-11-25T11:45:26.771230Z",
     "iopub.status.idle": "2022-11-25T11:45:27.997804Z",
     "shell.execute_reply": "2022-11-25T11:45:27.996836Z",
     "shell.execute_reply.started": "2022-11-25T11:45:26.771649Z"
    }
   },
   "outputs": [],
   "source": [
    "model = BartForConditionalGeneration.from_pretrained(\"./ai_model\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"[MODEL_NAME]\")  # the model pretrained on ai-dataset\n",
    "\n",
    "model.to(\"cuda\")\n",
    "outs = model.generate(ins.to(\"cuda\"), num_beams=10, min_length=5, max_length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-25T11:45:28.001333Z",
     "iopub.status.busy": "2022-11-25T11:45:28.000618Z",
     "iopub.status.idle": "2022-11-25T11:45:28.422575Z",
     "shell.execute_reply": "2022-11-25T11:45:28.421626Z",
     "shell.execute_reply.started": "2022-11-25T11:45:28.001296Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_str = tokenizer.batch_decode(outs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-25T11:45:31.291530Z",
     "iopub.status.busy": "2022-11-25T11:45:31.291058Z",
     "iopub.status.idle": "2022-11-25T11:45:31.790638Z",
     "shell.execute_reply": "2022-11-25T11:45:31.789616Z",
     "shell.execute_reply.started": "2022-11-25T11:45:31.291462Z"
    }
   },
   "outputs": [],
   "source": [
    "print(pred_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Transformer-based highlights extraction from scientific papers\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
