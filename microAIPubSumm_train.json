{"S0925231219305260": {"highlights": ["Ocular artifact-contaminated single-channel EEGs were artificially generated.", "Four artifact reduction methods were fairly compared.", "Our method improved artifact reduction performance for single-channel EEGs."], "abstract": "This paper addresses two issues toward practical use of wearable electroencephalogram (EEG) measurement devices. Ocular (eye movement and blink) artifacts often contaminate EEGs and deteriorate the performance of EEG-based brain\u2013computer interfaces (BCIs). Although wearable consumer-grade EEG devices with single electrode allow users to operate BCIs conveniently in daily lives, it remains a challenging issue to attenuate ocular artifacts from single-channel measurements without spatial information. Existing ocular artifact reduction methods are, however, not simple enough for single-channel EEG data in the sense that they require an additional reference channel and/or pre-processing for artifact segment detection. Another issue is how to assess the performance of artifact reduction; the existing studies have used their own datasets that are not accessible from other researchers. Then, this paper makes two major contributions. (1)\u00a0This paper proposes a novel ocular artifact reduction method, multi-scale dictionary learning (MSDL), which operates under single-channel measurements and without artifact segment detection. (2)\u00a0We also develop a semi-simulation setting for quantitative evaluation with a publicly available EEG dataset. In particular, we employed BCI Competition IV Dataset 2a, on which the proposed method was compared with state-of-art methods. The proposed technique showed the best performance for recovering artifact-reduced waveforms from single-channel data compared to the other artifact reduction methods. The Matlab scripts for semi-simulation data generation and single-channel artifact reduction are available on GitHub.", "title": "Multi-scale dictionary learning for ocular artifact reduction from single-channel electroencephalograms"}, "S0888613X14001716": {"highlights": ["A method of partitioning universe based on interval information granules is proposed.", "The method fully exploit the amplitude and trends information of time series.", "The method can produce more reasonable intervals with profound semantics.", "The method can prominently improve performance of fuzzy time series model."], "abstract": "In the process of modeling and forecasting of fuzzy time series, an issue on how to partition the universe of discourse impacts the quality of the forecasting performance of the constructed fuzzy time series model. In this paper, a novel method of partitioning the universe of discourse of time series based on interval information granules is proposed for improving forecasting accuracy of model. In the method, the universe of discourse of time series is first pre-divided into some intervals according to the predefined number of intervals to be partitioned, and then information granules are constructed in the amplitude-change space on the basis of data of time series belonging to each of intervals and their corresponding change (trends). In the sequel, optimal intervals are formed by continually adjusting width of these intervals to make information granules which associate with the corresponding intervals become most \u201cinformative\u201d. Three benchmark time series are used to perform experiments to validate the feasibility and effectiveness of proposed method. The experimental results clearly show that the proposed method produces more reasonable intervals exhibiting sound semantics. When using the proposed partitioning method to determine intervals for modeling of fuzzy time series, forecasting accuracy of the constructed model are prominently enhanced.", "title": "Using interval information granules to improve forecasting in fuzzy time series"}, "S0952197619301745": {"highlights": ["A large reproducible survey of ontology-based similarity measures and word embeddings.", "Embeddings using ontologies get the best overall results on word similarity and relatedness.", "Best performing WordNet-based similarity measures use IC models & path-based features.", "Linear combinations of best-performing word embeddings improve the state of the art."], "abstract": "Graphical abstract", "title": "A reproducible survey on word embeddings and ontology-based methods for word similarity: Linear combinations outperform the state of the art"}, "S0921889016304808": {"highlights": ["Novel classification of bio-cooperative robotic systems.", "A multimodal 3D robotic platform for upper limb rehabilitation of post stroke patients.", "Mechatronic module for guaranteeing arm-weight support during therapy."], "abstract": "Robot-mediated neuro-rehabilitation has been proved to be an effective therapeutic approach for upper limb motor recovery after stroke, though its actual potential when compared to other conventional approaches has still to be fully demonstrated. Most of the proposed solutions use a planar workspace. One key aspect for influencing motor recovery mechanisms, such as neuroplasticity and the level of motivation and involvement of the patient in the exercise, is the design of patient-tailored protocols and on-line adaptation of the assistance provided by the robotic agent to the patient performance. Also, when abilities for performing activities of daily living shall be targeted, exercises in 3D workspace are highly preferable. This paper wants to provide a complete overview on bio-cooperative systems on neuro-rehabilitation, with a special focus on 3D multimodal adaptive interfaces, by partly in-depth reviewing the literature and partly proposing an illustrative case of how to build such a bio-cooperative based on the authors\u2019 current research. It consists of an operational robotic platform for 3D upper limb robot-aided rehabilitation, directly derived from the MAAT system previously developed by the same research group. The system features on-line adaptation of therapy characteristics to specific patient needs and to the measured level of performance, by including the patient in the control loop. The system is composed of a 7-DoF robot arm, an adaptive interaction control system, a motorized arm-weight support system and a module for on-line evaluation of patient performance. Such module records patient biomechanical data through an unobtrusive, wearable sensory system, evaluates patient biomechanical state and updates robot control parameters for modifying level of assistance and task complexity in the 3D workspace. In addition, a multimodal interface provides information needed to control the motorized arm-weight support by means of a dedicated cable\u2013pulley system.", "title": "Multimodal adaptive interfaces for 3D robot-mediated upper limb neuro-rehabilitation: An overview of bio-cooperative systems"}, "S0306437917306385": {"highlights": ["ScQL: a metadata aware query language for databases of scientific samples.", "ScQL is compiled to a lower level representation suitable for optimization.", "The novel meta-first optimization exploits metadata so as to speed up query evaluation."], "abstract": "Most scientific databases consist of datasets (or sources) which in turn include samples (or files) with an identical structure (or schema). In many cases, samples are associated with rich metadata, describing the process that leads to building them (e.g.: the experimental conditions used during sample generation). Metadata are typically used in scientific computations just for the initial data selection; at most, metadata about query results is recovered after executing the query, and associated with its results by post-processing. In this way, a large body of information that could be relevant for interpreting query results goes unused during query processing.\n                  In this paper, we present ScQL, a new algebraic relational language, whose operations apply to objects consisting of data\u2013metadatapairs, by preserving such one-to-one correspondence throughout the computation. We formally define each operation and we describe an optimization, called meta-first, that may significantly reduce the query processing overhead by anticipating the use of metadata for selectively loading into the execution environment only those input samples that contribute to the result samples.\n                  In ScQL, metadata have the same relevance as data, and contribute to building query results; in this way, the resulting samples are systematically associated with metadata about either the specific input samples involved or about query processing, thereby yielding a new form of metadata provenance. We present many examples of use of ScQL, relative to several application domains, and we demonstrate the effectiveness of the meta-first optimization.\n               \n            \n\nThe organizations of scientific databases are very different. In many scientific fields, such as biology and astronomy, big consortia produce large, well-organized data repositories for public use. In other contexts, such as public administrations, data are open but much less organized and much more dispersed. Other big data players, such as Internet companies or mobile phone operators, produce information mostly for internal use, but often support third parties in research studies (e.g.,\u00a0about consumers\u2019 interests) by providing them with services for data retrieval.\n\nWe abstract a scientific data source as a container of several datasets, that in turn consists of thousands of samples, one for each experimental condition, often stored as files and not within a database; typically, samples are described by metadata, i.e.,\u00a0descriptive information about the content and production process of each sample. In meteorology, typical metadata describe \u201cthe WDM station, the sources of meteorological data, and the period of record for which the data is available\u201d; then the samples describe millions of records registered at the station. In genomics, typical metadata describe \u201cthe technology used for DNA sequencing, the process of DNA preparation, the genotype and phenotype of the donor\u201d; then, samples describe millions of genomic regions collected during the experiment.\n\nMetadata support the selection of the relevant experimental data by means of user interfaces (e.g.\u00a0see genomic repositories such as ENCODE (the Encyclopedia of Genomic Elements,\u00a0[1]) or TCGA (The Cancer Genome Atlas,\u00a0[2]). When a source exposes APIs or WEB interfaces, metadata associated to each sample (such as Twitter\u2019s hashtags or timestamps) support data retrieval. As a result, data scientists select the best datasets and samples within sources after analyzing the metadata, but typically they do not further use them; in most cases, then they retrieve samples and use scripting languages to query and analyze them. In this paper, we present a new query language for scientific databases where metadata and samples are processed together, thereby allowing for important optimizations and also producing metadata describing query results.\n\nOur approach is influenced by our experience in biological databases. In that domain, we developed GMQL (GenoMetric Query Language)\u00a0[3], a language for the integration of heterogeneous biological datasets. Some of the lessons learned in that domain include aspects that can be shared and generalized to virtually all scientific databases, namely:\n\n\n                     \n                        \n                           \u2022\n                           Metadata describing the content and production process of a sample can be explicitly associated with the sample in the form of attribute\u2013value pairs.\n\nSamples can be represented as parts of larger datasets (e.g., files in a file system or tables in a database) to be loaded for the query process. Metadata associated with them can be used at query execution time for selectively loading data from the relevant repositories and transferring them to the query processing components. Such components can, e.g.,\u00a0be the nodes of a cloud computing system running dedicated database engines.\n\nThe query language must allow for metadata-aware query processing: metadata should thus be enriched as the operations are applied to samples and should describe the partial as well as the final results produced by the query.\n\nHowever, GMQL was tailored to meet the requirements of biological data and was based on several domain-specific assumptions that only apply when observations refer to DNA regions.\n\nThe aim of this paper is, instead, to widen the applicability of metadata-aware query languages by providing a general-purpose approach that encompasses arbitrary observations of scientific databases. To this end, we present the new Scientific Query Language ScQL. We provide a formal definition of the language semantics, which makes it possible to explain the interplay between metadata and observations during the evaluation of ScQL operations and the propagation of metadata to partial and final results. The precise definition of ScQL semantics also enables us to define an important optimization principle, called meta-first, that allows executing the computation of metadata operations before loading the observation samples, thereby offering remarkable efficiency improvements.\n\nScQL supports a new notion of provenance: in its classic use, this term denotes the ability to understand, for each observation in the result, which individual observations of the input have contributed to its generation; we refer to this notion as fine-grained database provenance, associated to each database tuple. In our approach, datasets produced as query result are decomposed into homogeneous samples, and the observations within each sample are globally described by metadata. Meta-data of each result sample are either properties of the input samples that contributed to its construction or aggregate properties computed during query processing. Hence, our approach provides a more global notion of sample provenance, which is easier to compute than fine-grained database provenance and yet provides very relevant information to the data scientist.\n\nSample provenance can be very effective for follow-up activities of data analysis and mining applied to query results; for instance, resulting samples can be classified or clustered by using as parameters, in addition to their values, also their metadata.\n\nFrom an implementation point of view, metadata and observation computations can take place separately, possibly using very different implementation strategies and even technologies, as metadata are several orders of magnitude smaller than observations. In this paper, we do not discuss how ScQL should be mapped to a physical representation and therefore we cannot discuss its physical optimization.\n\nHowever, we define the metadata-first optimization, a representation independent optimization based on the simple idea of anticipating the computation of metadata over observations whenever possible. The metadata-first optimization is fully original, it emphasizes the use of metadata in order to simplify the queries in a way that can give dramatic advantages and it is formally defined and proved correct. We believe that the meta-first optimization may inspire a class of optimization methods based on similar abstractions.\n\nA scientific database is based on the notions of datasets and samples. Datasets are collections of samples, and each sample consists of two parts: the observations, which describe specific scientific facts or events, and the metadata, which describe general properties of the sample.", "title": "Metadata management for scientific databases"}, "S0921889015001542": {"highlights": ["Introduction of architecture and components of the ROS\u2013TMS.", "Integration of various data from distributed sensors for service robot system.", "Object detection system (ODS) using RGB-D camera.", "Motion planning for a fetch-and-give task using a wagon and a humanoid robot.", "Handing over an object to a human using manipulability of both a robot and a human."], "abstract": "Daily life assistance is one of the most important applications for service robots. For comfortable assistance, service robots must recognize the surrounding conditions correctly, including human motion, the position of objects, and obstacles. However, since the everyday environment is complex and unpredictable, it is almost impossible to sense all of the necessary information using only a robot and sensors attached to it. In order to realize a service robot for daily life assistance, we have been developing an informationally structured environment using distributed sensors embedded in the environment. The present paper introduces a service robot system with an informationally structured environment referred to the ROS\u2013TMS. This system enables the integration of various data from distributed sensors, as well as storage of these data in an on-line database and the planning of the service motion of a robot using real-time information about the surroundings. In addition, we discuss experiments such as detection and fetch-and-give tasks using the developed real environment and robot.", "title": "Service robot system with an informationally structured environment"}, "S0957417415003759": {"highlights": ["Idiom-based features significantly improve sentiment classification results.", "This study provides resources that can support further research into sentiment analysis.", "A comprehensive collection of 580 idioms annotated with sentiment polarity.", "A set of local grammars that can be used to recognize occurrences of these idioms.", "A corpus of 2521 annotated sentences in which idioms are used in context."], "abstract": "In this paper we investigate the role of idioms in automated approaches to sentiment analysis. To estimate the degree to which the inclusion of idioms as features may potentially improve the results of traditional sentiment analysis, we compared our results to two such methods. First, to support idioms as features we collected a set of 580 idioms that are relevant to sentiment analysis, i.e. the ones that can be mapped to an emotion. These mappings were then obtained using a web-based crowdsourcing approach. The quality of the crowdsourced information is demonstrated with high agreement among five independent annotators calculated using Krippendorff\u2019s alpha coefficient (\u03b1\n                     =0.662). Second, to evaluate the results of sentiment analysis, we assembled a corpus of sentences in which idioms are used in context. Each sentence was annotated with an emotion, which formed the basis for the gold standard used for the comparison against two baseline methods. The performance was evaluated in terms of three measures \u2013 precision, recall and F-measure. Overall, our approach achieved 64% and 61% for these three measures in two experiments improving the baseline results by 20 and 15 percent points respectively. F-measure was significantly improved over all three sentiment polarity classes: Positive, Negative and Other. Most notable improvement was recorded in classification of positive sentiments, where recall was improved by 45 percent points in both experiments without compromising the precision. The statistical significance of these improvements was confirmed by McNemar\u2019s test.", "title": "The role of idioms in sentiment analysis"}, "S0888613X1400084X": {"highlights": ["New models from the class of continuous time Bayesian network classifiers (CTBNCs).", "Derivation of conditional log-likelihood scoring function for CTBNCs.", "Algorithm, based on conditional log-likelihood score function, for learning CTBNCs.", "Performance comparison between DBNs and CTBNCs learned with different score functions.", "Performance analysis of CTBNCs on the problem of post-stroke rehabilitation."], "abstract": "Streaming data are relevant to finance, computer science, and engineering while they are becoming increasingly important to medicine and biology. Continuous time Bayesian network classifiers are designed for analyzing multivariate streaming data when time duration of event matters. Structural and parametric learning for the class of continuous time Bayesian network classifiers are considered in the case where complete data is available. Conditional log-likelihood scoring is developed for structural learning on continuous time Bayesian network classifiers. Performance of continuous time Bayesian network classifiers learned when combining conditional log-likelihood scoring and Bayesian parameter estimation are compared with that achieved by continuous time Bayesian network classifiers when learning is based on marginal log-likelihood scoring and to that achieved by dynamic Bayesian network classifiers. Classifiers are compared in terms of accuracy and computation time. Comparison is based on numerical experiments where synthetic and real data are used. Results show that conditional log-likelihood scoring combined with Bayesian parameter estimation outperforms marginal log-likelihood scoring. Conditional log-likelihood scoring becomes even more effective when the amount of available data is limited. Continuous time Bayesian network classifiers outperform in terms of computation time and accuracy dynamic Bayesian network on synthetic and real data sets.", "title": "Learning continuous time Bayesian network classifiers"}, "S107158191730126X": {"highlights": ["Motives for contributing content are argued to differ for participants at different stages.", "A stage theory that distinguishes three sets of motivations for participation is proposed.", "The theory is tested with a data set from the Wikimedia Editor Survey.", "Results support the premise that motives are not unitary but differ by stage."], "abstract": "User-generated content (UGC) projects involve large numbers of mostly unpaid contributors collaborating to create content. Motivation for such contributions has been an active area of research. In prior research, motivation for contribution to UGC has been considered a single, static and individual phenomenon. In this paper, we argue that it is instead three separate but interrelated phenomena. Using the theory of helping behaviour as a framework and integrating social movement theory, we propose a stage theory that distinguishes three separate sets (initial, sustained and meta) of motivations for participation in UGC. We test this theory using a data set from a Wikimedia Editor Survey (Wikimedia Foundation, 2011). The results suggest several opportunities for further refinement of the theory but provide support for the main hypothesis, that different stages of contribution have distinct motives. The theory has implications for both researchers and practitioners who manage UGC projects.\n               \n            \n\n\n                  \n                     \u201cI've always been only a Wikipedia reader, never a Wikipedia editor. Over the years, Wikipedia has greatly benefitted me with scads of information about every topic under the sun. However, the prospect of editing the thing seemed scary and mysterious\u2014I mean, who are these people anyway? How does one become an encyclopedia editor? \u2014but there it was, a big honkin\u2019 typo staring at me. I was suddenly seized by the responsibility\u2014obligation, really\u2014to fix it. So I took the plunge and hit that edit button.\n                  \n                  \n                     So began my love affair with editing Wikipedia. It turns out editing an article isn't scary at all. It's easy, surprisingly satisfying and can become obsessively addictive.\u201d\n                  \n                  \n                     Gina Trapani, editor of Lifehacker\n                           1\n                        \n                        \n                           1\n                           From http://lifehacker.com/133747. Included with permission from the author.", "title": "Stages of motivation for contributing user-generated content: A theory and empirical test"}, "S1071581918300636": {"highlights": ["A cognitive assistant for e-learning is proposed.", "The architecture has been evaluated with a prototype for students learning Java.", "The developed agent is compared with a classical QA agent.", "The evaluation has been carried out with balanced groups."], "abstract": "The application of natural language to improve the interaction of human users with information systems is a growing trend in the recent years. Advances in cognitive computing enable a new way of interaction that accelerates insight from existing information sources. In this paper, we propose a modular cognitive agent architecture for question answering featuring social dialogue improved for a specific knowledge domain. The proposed system has been implemented as a personal agent to assist students learning Java programming language. The developed prototype has been evaluated to analyze how users perceive the interaction with the system. We claim that including social dialogue in QA systems increases users satisfaction and makes them easily engage with the system. Finally, we present the evaluation results that support our hypotheses.", "title": "A cognitive assistant for learning java featuring social dialogue"}, "S0888613X14000358": {"highlights": ["Prediction of multivariate interval-valued time series.", "Evolutionary algorithm for learning Fuzzy Grey Cognitive Maps (FGCMs).", "Application of FGCMs to the prediction of climatological time series."], "abstract": "Time series are built as a result of real-valued observations ordered in time; however, in some cases, the values of the observed variables change significantly, and those changes do not produce useful information. Therefore, within defined periods of time, only those bounds in which the variables change are considered. The temporal sequence of vectors with the interval-valued elements is called a \u2018multivariate interval-valued time series.\u2019 In this paper, the problem of forecasting such data is addressed. It is proposed to use fuzzy grey cognitive maps (FGCMs) as a nonlinear predictive model. Using interval arithmetic, an evolutionary algorithm for learning FGCMs is developed, and it is shown how the new algorithm can be applied to learn FGCMs on the basis of historical time series data. Experiments with real meteorological data provided evidence that, for properly-adjusted learning and prediction horizons, the proposed approach can be used effectively to the forecasting of multivariate, interval-valued time series. The domain-specific interpretability of the FGCM-based model that was obtained also is confirmed.", "title": "Evolutionary learning of fuzzy grey cognitive maps for the forecasting of multivariate, interval-valued time series"}, "S0306437913000768": {"highlights": ["We propose a modeling approach and a visual modeling notation for social collaboration processes.", "We consider collaboration processes as the evolution of a network of documents and people.", "The visual modeling notation is a fusion of statecharts and graph query languages.", "The approach is supported by a formal definition to enable automatic reasoning and verification.", "We present sensitive use cases to demonstrate expressiveness and usefulness of our approach."], "abstract": "Modeling collaboration processes is a challenging task. Existing modeling approaches are not capable of expressing the unpredictable, non-routine nature of human collaboration, which is influenced by the social context of involved collaborators. We propose a modeling approach which considers collaboration processes as the evolution of a network of collaborative documents along with a social network of collaborators. Our modeling approach, accompanied by a graphical notation and formalization, allows to capture the influence of complex social structures formed by collaborators, and therefore facilitates such activities as the discovery of socially coherent teams, social hubs, or unbiased experts. We demonstrate the applicability and expressiveness of our approach and notation, and discuss their strengths and weaknesses.", "title": "On modeling context-aware social collaboration processes"}, "S0888613X15000262": {"highlights": ["Novel approach fusing information from multiple keypoint descriptors using the Dempster\u2013Shafer Theory of evidence.", "Descriptors matches are transformed in evidence distributions assigning a confidence factor using Shannon's entropy.", "Results on the Oxford keypoint dataset show improvements of up to 10% compared to the best keypoint descriptor."], "abstract": "Keypoint matching is the task of accurately finding the location of a scene point in two images. Many keypoint descriptors have been proposed in the literature aiming at providing robustness against scale, translation and rotation transformations, each having advantages and disadvantages. This paper proposes a novel approach to fuse the information from multiple keypoint descriptors using Dempster\u2013Shafer theory of evidence [1], which has proven particularly efficient in combining sources of information providing incomplete, imprecise, biased, and conflictive knowledge. The matching results of each descriptor are transformed into an evidence distribution on which a confidence factor is computed making use of its entropy. Then, the evidence distributions are fused using Dempster\u2013Shafer Theory (DST), considering its confidence. As a result of the fusion, a new evidence distribution that improves the result of the best descriptor is obtained. Our method has been tested with SIFT, SURF, ORB, BRISK and FREAK descriptors using all possible their combinations. Results on the Oxford keypoint dataset [2] show that the proposed approach obtains an improvement of up to \n                        10\n                        %\n                      compared to the best one (FREAK).", "title": "Keypoint descriptor fusion with Dempster\u2013Shafer theory"}, "S0888613X13002119": {"highlights": ["We examine imprecise models for estimating multinomial probabilities.", "The selection of the equivalent sample size in a Dirichlet density is not simple.", "An imprecise model can be considered by being imprecise in the equivalent sample size.", "Imprecise sample size is useful to learn credal networks with imprecise structure."], "abstract": "This paper considers the problem of learning multinomial distributions from a sample of independent observations. The Bayesian approach usually assumes a prior Dirichlet distribution about the probabilities of the different possible values. However, there is no consensus on the parameters of this Dirichlet distribution. Here, it will be shown that this is not a simple problem, providing examples in which different selection criteria are reasonable. To solve it the Imprecise Dirichlet Model (IDM) was introduced. But this model has important drawbacks, as the problems associated to learning from indirect observations. As an alternative approach, the Imprecise Sample Size Dirichlet Model (ISSDM) is introduced and its properties are studied. The prior distribution over the parameters of a multinomial distribution is the basis to learn Bayesian networks using Bayesian scores. Here, we will show that the ISSDM can be used to learn imprecise Bayesian networks, also called credal networks when all the distributions share a common graphical structure. Some experiments are reported on the use of the ISSDM to learn the structure of a graphical model and to build supervised classifiers.", "title": "Imprecise probability models for learning multinomial distributions from data. Applications to learning credal networks"}, "S0921889017302440": {"highlights": ["RTE makes it possible for complex robots to quickly recover from damage.", "It is a trial-and-error learning approach that considers the environment.", "It does not require the robot to be reset to the same state after each trial.", "It breaks the complexity by pre-generating hundreds of possible behaviors.", "It allowed a damaged 6-legged robot to learn to walk in an arena with obstacles."], "abstract": "The high probability of hardware failures prevents many advanced robots (e.g., legged robots) from being confidently deployed in real-world situations (e.g., post-disaster rescue). Instead of attempting to diagnose the failures, robots could adapt by trial-and-error in order to be able to complete their tasks. In this situation, damage recovery can be seen as a Reinforcement Learning (RL) problem. However, the best RL algorithms for robotics require the robot and the environment to be reset to an initial state after each episode, that is, the robot is not learning autonomously. In addition, most of the RL methods for robotics do not scale well with complex robots (e.g., walking robots) and either cannot be used at all or take too long to converge to a solution (e.g., hours of learning). In this paper, we introduce a novel learning algorithm called \u201cReset-free Trial-and-Error\u201d (RTE) that (1) breaks the complexity by pre-generating hundreds of possible behaviors with a dynamics simulator of the intact robot, and (2) allows complex robots to quickly recover from damage while completing their tasks and taking the environment into account. We evaluate our algorithm on a simulated wheeled robot, a simulated six-legged robot, and a real six-legged walking robot that are damaged in several ways (e.g., a missing leg, a shortened leg, faulty motor, etc.) and whose objective is to reach a sequence of targets in an arena. Our experiments show that the robots can recover most of their locomotion abilities in an environment with obstacles, and without any human intervention.", "title": "Reset-free Trial-and-Error Learning for Robot Damage Recovery"}, "S0957417416303773": {"highlights": ["An improved hybrid ensemble method to combine any kind of classifier is proposed.", "No need for the standalone classifiers to first assess incoming cases under test.", "It is based on the statistical modeling of the baseline classifiers\u2019 behavior.", "It is applied in LTE root cause analysis.", "The method has been tested in a live network scenario."], "abstract": "The Self-Organizing Networks (SON) paradigm proposes a set of functions to automate network management in mobile communication networks. Within SON, the purpose of Self-Healing is to detect cells with service degradation, diagnose the fault cause that affects them, rapidly compensate the problem with the support of neighboring cells and repair the network by performing some recovery actions.\n                  The diagnosis phase can be designed as a classifier. In this context, hybrid ensembles of classifiers enhance the diagnosis performance of expert systems of different kinds by combining their outputs. In this paper, a novel scheme of hybrid ensemble of classifiers is proposed as a two-step procedure: a modeling stage of the baseline classifiers and an application stage, when the combination of partial diagnoses is actually performed. The use of statistical models of the baseline classifiers allows an immediate ensemble diagnosis without running and querying them individually, thus resulting in a very low computational cost in the execution stage.\n                  Results show that the performance of the proposed method compared to its standalone components is significantly better in terms of diagnosis error rate, using both simulated data and cases from a live LTE network. Furthermore, this method relies on concepts which are not linked to a particular mobile communication technology, allowing it to be applied either on well established cellular networks, like UMTS, or on recent and forthcoming technologies, like LTE-A and 5G.", "title": "Combination of multiple diagnosis systems in Self-Healing networks"}, "S0957417419304270": {"highlights": ["A significant long-term link exists between Twitter sentiment and financial markets.", "Experts are the main driver behind the link between Twitter and stock markets.", "Compared to past prices Twitter sentiment changes are effective in predicting short term stock trends.", "Continuous Twitter sentiment streams can support trend-following strategies for stock indices."], "abstract": "We examine the long-term relationship between signals derived from nine years of unstructured social media microblog text data and financial market developments in five major economic regions. Employing statistical language modeling techniques we construct directional sentiment metrics and link these to aggregate stock index returns. To address the noise in finance-related Twitter messages we identify expert users whose tweets predominantly focus on finance topics. We document that expert users are the main drivers behind an interdependence between Twitter sentiment and financial markets. The direct prediction value of expert sentiment metrics for stock index returns, however, is found to be elusive and short-lived. Yet, we detect significant predictive gains over benchmark models in times of negative market returns. In consequence, the relation between expert sentiment metrics and stock indices is sufficient to devise hypothetically profitable cross-sectional as well as time series momentum investment strategies for futures based on Twitter signals that survive basic transaction cost assumptions. In this context, our results show that expert sentiment signals can yield higher risk-adjusted returns than classical price-based signals.", "title": "Buzzwords build momentum: Global financial Twitter sentiment and the aggregate stock market"}, "S2590188519300010": {"highlights": ["We present a review of 24 ML-based approaches for identifying and classifying NFRs in requirements documents.", "The review finds 16 different ML algorithms, including both supervised and unsupervised learning; SVM is the most used algorithm.", "The review finds 7 different performance measures, of which precision and recall are most popular.", "The lack of shared datasets and a standard definition and classification of NFRs are among the open challenges.", "ML-based approaches have the potential in the classification and identification of NFRs."], "abstract": "Context\n                  Recent developments in requirements engineering (RE) methods have seen a surge in using machine-learning (ML) algorithms to solve some difficult RE problems. One such problem is identification and classification of non-functional requirements (NFRs) in requirements documents. ML-based approaches to this problem have shown to produce promising results, better than those produced by traditional natural language processing (NLP) approaches. Yet, a systematic understanding of these ML approaches is still lacking.\n               \n               \n                  Method\n                  This article reports on a systematic review of 24 ML-based approaches for identifying and classifying NFRs. Directed by three research questions, this article aims to understand what ML algorithms are used in these approaches, how these algorithms work and how they are evaluated.\n               \n               \n                  Results\n                  (1) 16 different ML algorithms are found in these approaches; of which supervised learning algorithms are most popular. (2) All 24 approaches have followed a standard process in identifying and classifying NFRs. (3) Precision and recall are the most used matrices to measure the performance of these approaches.\n               \n               \n                  Finding\n                  The review finds that while ML-based approaches have the potential in the classification and identification of NFRs, they face some open challenges that will affect their performance and practical application.\n               \n               \n                  Impact\n                  The review calls for the close collaboration between RE and ML researchers, to address open challenges facing the development of real-world ML systems.\n               \n               \n                  Significance\n                  The use of ML in RE opens up exciting opportunities to develop novel expert and intelligent systems to support RE tasks and processes. This implies that RE is being transformed into an application of modern expert systems.", "title": "A review of machine learning algorithms for identification and classification of non-functional requirements"}, "S0306437919304910": {"highlights": ["Responsible EAI development based on formalized Enterprise Integration Patterns (EIP).", "EIP formalization as timed db nets, fully equipped with execution semantics.", "Correctness criterion and checks for EIP executions.", "Prototype support for testing correctness for EIP realizations based on simulations.", "Case studies (e.g., predictive maintenance) from SAP Cloud Integration."], "abstract": "Enterprise Application Integration (EAI) constitutes the cornerstone in enterprise IT landscapes that are characterized by heterogeneity and distribution. Starting from established Enterprise Integration Patterns (EIPs) such as Content-based Router and Aggregator, EIP compositions are built to describe, implement, and execute integration scenarios. The EIPs and their compositions must be correct at design and runtime in order to avoid functional errors or incomplete functionalities. However, current EAI system vendors use many of the EIPs as part of their proprietary integration scenario modeling languages that are not grounded on any formalism. This renders correctness guarantees for EIPs and their composition impossible. Thus this work advocates responsible EAI based on the formalization, implementation, and correctness of EIPs. For this, requirements on an EIP formalization are collected and based on these requirements an extension of db-net, i.e.,\u00a0timed db-net , is proposed, fully equipped with execution semantics. It is shown how EIPs can be realized based on timed db-nets and how the correctness of these realizations can be shown. Moreover, the simulation of EIP realizations based on timed db-nets is enabled which is essential for later implementation. The concepts are evaluated in many ways, including a proof-of-concept implementation and case studies. The EIP formalization based on timed db-nets constitutes the first step towards responsible EAI.", "title": "Formal foundations for responsible application integration"}, "S0921889017300374": {"highlights": ["Introducing a generic experimental method to verify finger design automation approaches.", "Proposing methods to examine stability and performance of fingers.", "The proposed experimental method is applied on fingers designed by existing finger design automation methods.", "Results are comprehensively analyzed and compared."], "abstract": "Design automation of industrial grippers is a hot research topic for robot industries. However, literature lacks a standard experimental method to enable researchers to validate their approaches. Thus, this paper proposes a generic experimental method to verify existing finger design approaches. The introduced method is utilized to validate the methods Generic Automated Finger Design (GAFD), Manually Designed Fingers (MDF) and the eGrip tool. Experimental results are compared and the strengths and weaknesses of each method are presented.", "title": "Experimental verification of design automation methods for robotic finger"}, "S1875952117300095": {"highlights": ["We performed an analysis on approaches aimed to adapt the flow to a game AI context.", "We defined a generic framework of flow for game AI (FlowAI).", "From the FlowAI framework standpoint, we proceed to survey the game AI area.", "This survey overviews current trends and challenges in each game AI subarea.", "We identify desirable features to design effective modules for flow based games."], "abstract": "Player-centered approaches that aim to maximize player enjoyment have been steady, but with poor heuristics that do not rely on any particular theory of entertainment. Certainly, the Theory of Flow is the most referred in the game AI area and, still, it is unclear how to effectively design and implement adaptive game modules or understanding which game features drive players to a flow state. Therefore, in this document we perform a systematic analysis of literature aimed to enhance our knowledge about how to adapt flow heuristics to a video game context. This analysis endows us with the knowledge needed to define a flow framework for game AI. Our framework, FlowAI, describes which modules and what gameplay features can be adapted to design an effective video game intended to facilitate the achievement of flow in players. Furthermore, from our framework standpoint, we identify and review existing work that could be adjusted to foster flow. Our aim with this analysis is to identify current challenges, and motivate new directions in the player-centered research area.", "title": "Player-centered game AI from a flow perspective: Towards a better understanding of past trends and future directions"}, "S2589721719300042": {"highlights": ["Applied machine learning system for separation the alive the dead fish eggs was proposed.", "The results for fish egg classification showed that MLP and SVM classifiers had equally high capability.", "The proposed method can play an effective role in separating the alive and dead fish eggs."], "abstract": "In this study a visual machine technology-based intelligent system was developed and evaluated for separation and recognizing the alive and dead eggs of rainbow trout fish. The features derived from imagery processing of alive and dead eggs were used as the decision-making variables in the classifier. Multi-layer Perceptron neural network (MLP) and Support Vector Machine (SVM) models were used as the classifiers. With paired t-test, 10 effective features were selected from 15 features for classification. The k-fold cross validation method was used for better evaluation the classifiers. By changing the size of the training data set from 80% to 20%, the classifier ability and stability were evaluated. The results showed that in the training phase, all the mean values of the statistical indices for MLP and SVM classifications were complete for all categories (100% of the classification was predicted correctly). Also, in the test phase, the performance indicators of both classifiers were very satisfactory (the average accuracy was 99.45%). Therefore, it is possible to use both classifiers with certainty for separation the rainbow trout fish eggs.\n               \n            \n\nMulti-layer Perceptron\n\nSupport Vector Machine\n\nGray-Level Co-Occurrence Matrix\n\nmean of the squared error\n\nBayesian regularization back-propagation\n\nLevenberg\u2013Marquardt back-propagation\n\nArtificial Neural Network\n\nBayesian Network\n\nDecision Trees\n\nk-Nearest Neighbors\n\nSupport Vector Machine Data Description\n\nconfidence interval", "title": "Application of artificial intelligence for separation of live and dead rainbow trout fish eggs"}, "S0957417417300933": {"highlights": ["An anomaly detection algorithm to identify AIS on-off switching is proposed.", "The algorithm exploits the AIS message Received Signal Strength Indicator.", "Machine Learning algorithms are used to build normality models.", "AIS reception is characterized by using real word data.", "The methodology is scalable from one station to a network of receivers."], "abstract": "The Automatic Identification System (AIS) is a ship reporting system based on messages broadcast by vessels carrying an AIS transponder. The recent increase of terrestrial networks and satellite constellations of receivers is making AIS one of the main sources of information for Maritime Situational Awareness activities. Nevertheless, AIS is subject to reliability and manipulation issues; indeed, the received reports can be unintentionally incorrect, jammed or deliberately spoofed. Moreover, the system can be switched off to cover illicit operations, causing the interruption of AIS reception. This paper addresses the problem of detecting whether a shortage of AIS messages represents an alerting situation or not, by exploiting the Received Signal Strength Indicator available at the AIS Base Stations (BS). In designing such an anomaly detector, the electromagnetic propagation conditions that characterize the channel between ship AIS transponders and BS have to be taken into consideration. The first part of this work is thus focused on the experimental investigation and characterisation of coverage patterns extracted from the real historical AIS data. In addition, the paper proposes an anomaly detection algorithm to identify intentional AIS on-off switching. The presented methodology is then illustrated and assessed on a real-world dataset.", "title": "A novel anomaly detection approach to identify intentional AIS on-off switching"}, "S0893608014002378": {"highlights": ["A novel supervised nonnegative matrix factorization method is proposed.", "Within-class and between-class pairs are defined by class labels.", "The maximum within-class distance is minimized in NMF space.", "The minimum between-class distance is maximized in NMF space.", "Experiment results show its outperformance over other supervised NMF methods."], "abstract": "Nonnegative Matrix Factorization (NMF) has been a popular representation method for pattern classification problems. It tries to decompose a nonnegative matrix of data samples as the product of a nonnegative basis matrix and a nonnegative coefficient matrix. The columns of the coefficient matrix can be used as new representations of these data samples. However, traditional NMF methods ignore class labels of the data samples. In this paper, we propose a novel supervised NMF algorithm to improve the discriminative ability of the new representation by using the class labels. Using the class labels, we separate all the data sample pairs into within-class pairs and between-class pairs. To improve the discriminative ability of the new NMF representations, we propose to minimize the maximum distance of the within-class pairs in the new NMF space, and meanwhile to maximize the minimum distance of the between-class pairs. With this criterion, we construct an objective function and optimize it with regard to basis and coefficient matrices, and slack variables alternatively, resulting in an iterative algorithm. The proposed algorithm is evaluated on three pattern classification problems and experiment results show that it outperforms the state-of-the-art supervised NMF methods.", "title": "Max\u2013min distance nonnegative matrix factorization"}, "S0952197619300788": {"highlights": ["Automated online least-squares policy iteration applicable to continuous state\u2013action domains.", "Efficient sparsification and incremental dictionary expansions.", "Similarity-based information extrapolation for temporal difference update."], "abstract": "Reinforcement learning (RL) is a general framework to acquire intelligent behavior by trial-and-error and many successful applications and impressive results have been reported in the field of robotics. In robot control problem settings, it is oftentimes characteristic that the algorithms have to learn online through interaction with the system while it is operating, and that both state and action spaces are continuous. Least-squares policy iteration (LSPI) based approaches are therefore particularly hard to employ in practice, and parameter tuning is a tedious and costly enterprise. In order to mitigate this problem, we derive an automatic online LSPI algorithm that operates over continuous action spaces and does not require an a-priori, hand-tuned value function approximation architecture. To this end, we first show how the kernel least-squares policy iteration algorithm can be modified to handle data online by recursive dictionary and learning update rules. Next, borrowing sparsification methods from kernel adaptive filtering, the continuous action-space approximation in the online least-squares policy iteration algorithm can be efficiently automated as well. We then propose a similarity-based information extrapolation for the recursive temporal difference update in order to perform the dictionary expansion step efficiently in both algorithms. The performance of the proposed algorithms is compared with respect to their batch or hand-tuned counterparts in a simulation study. The novel algorithms require less prior tuning and data is processed completely on the fly, yet the results indicate that similar performance can be obtained as by careful hand-tuning. Therefore, engineers from both robotics and AI can benefit from the proposed algorithms when an LSPI algorithm is faced with online data collection and tuning by experiment is costly.", "title": "Least-squares policy iteration algorithms for robotics: Online, continuous, and automatic"}, "S095741741830407X": {"highlights": ["MCRDR KB inference system is extended to maintain conversational context.", "Post-inference embedded queries resolved by detected conversational context.", "System developed with ASR Chatbot interface and STT input and TTS output.", "System evaluated by usability study of pedagogical domain by undergraduate students."], "abstract": "We introduce an extension to Multiple Classification Ripple Down Rules (MCRDR), called Contextual MCRDR (C-MCRDR). We apply C-MCRDR knowledge-base systems (KBS) to the Textual Question Answering (TQA) and Natural Language Interface to Databases (NLIDB) paradigms in restricted domains as a type of spoken dialog system (SDS) or conversational agent (CA). C-MCRDR implicitly maintains topical conversational context, and intra-dialog context is retained allowing explicit referencing in KB rule conditions and classifications. To facilitate NLIDB, post-inference C-MCRDR classifications can include generic query referencing \u2013 query specificity is achieved by the binding of pre-identified context. In contrast to other scripted, or syntactically complex systems, the KB of the live system can easily be maintained courtesy of the RDR knowledge engineering approach. For evaluation, we applied this system to a pedagogical domain that uses a production database for the generation of offline course-related documents. Our system complemented the domain by providing a spoken or textual question-answering alternative for undergraduates based on the same production database. The developed system incorporates a speech-enabled chatbot interface via Automatic Speech Recognition (ASR) and experimental results from a live, integrated feedback rating system showed significant user acceptance, indicating the approach is promising, feasible and further work is warranted. Evaluation of the prototype\u2019s viability found the system responded appropriately for 80.3% of participant requests in the tested domain, and it responded inappropriately for 19.7% of requests due to incorrect dialog classifications (4.4%) or out of scope requests (15.3%). Although the semantic range of the evaluated domain was relatively shallow, we conjecture that the developed system is readily adoptable as a CA NLIDB tool in other more semantically-rich domains and it shows promise in single or multi-domain environments.", "title": "Intelligent conversation system using multiple classification ripple down rules and conversational context"}, "S0957417418304986": {"highlights": ["To introduce an Integrated Fuzzy Clustering Cooperative Game DEA.", "To provide a clustering technique to deal with lack of homogeneity among DMUs.", "To provide a framework for measuring hospitals in different provinces.", "Use of Core and Shapley values for ranking efficient DMUs in DEA."], "abstract": "Hospitals are the main sub-section of health care systems and evaluation of hospitals is one of the most important issue for health policy makers. Data Envelopment Analysis (DEA) is a nonparametric method that has recently been used for measuring efficiency and productivity of Decision Making Units (DMUs) and commonly applied for comparison of hospitals. However, one of the important assumption in DEA is that DMUs must be homogenous. The crucial issue in hospital efficiency is that hospitals are providing different services and so may not be comparable. In this paper, we propose an integrated fuzzy clustering cooperative game DEA approach. In fact, due to the lack of homogeneity among DMUs, we first propose to use a fuzzy C-means technique to cluster the DMUs. Then we apply DEA combined with the game theory where each DMU is considered as a player, using Core and Shapley value approaches within each cluster. The procedure has successfully been applied for performances measurement of 288 hospitals in 31 provinces of Iran. Finally, since the classical DEA model is not capable to distinguish between efficient DMUs, efficient hospitals within each cluster, are ranked using combined DEA model and cooperative game approach. The results show that the Core and Shapley values are suitable for fully ranking of efficient hospitals in the healthcare systems.", "title": "An integrated fuzzy clustering cooperative game data envelopment analysis model with application in hospital efficiency"}, "S0888613X1400098X": {"highlights": ["A matrix based incremental approach in dynamic incomplete information systems is presented.", "A rough set-based incremental model for learning knowledge under four binary relations is outlined.", "Two incremental learning algorithms under the variation of objects in dynamic incomplete information systems are developed."], "abstract": "With the rapid growth of data sets nowadays, the object sets in an information system may evolve in time when new information arrives. In order to deal with the missing data and incomplete information in real decision problems, this paper presents a matrix based incremental approach in dynamic incomplete information systems. Three matrices (support matrix, accuracy matrix and coverage matrix) under four different extended relations (tolerance relation, similarity relation, limited tolerance relation and characteristic relation), are introduced to incomplete information systems for inducing knowledge dynamically. An illustration shows the procedure of the proposed method for knowledge updating. Extensive experimental evaluations on nine UCI datasets and a big dataset with millions of records validate the feasibility of our proposed approach.", "title": "A rough set-based incremental approach for learning knowledge in dynamic incomplete information systems"}, "S0888613X13001710": {"highlights": ["We use spanning subgraphs of an argument graph as sample space for assigning probability of attack.", "We show subsumption of a variety of argumentation systems that incorporate preferences or weights.", "We show how to use approach for modelling the uncertainty in enthymemes."], "abstract": "An argument graph is a graph where each node denotes an argument, and each arc denotes an attack by one argument on another. It offers a valuable starting point for theoretical analysis of argumentation following the proposals by Dung. However, the definition of an argument graph does not take into account the belief in the attacks. In particular, when constructing an argument graph from informal arguments, where each argument is described in free text, it is often evident that there is uncertainty about whether some of the attacks hold. This might be because there is some expressed doubt that an attack holds or because there is some imprecision in the language used in the arguments. In this paper, we use the set of spanning subgraphs of an argument graph as a sample space. A spanning subgraph contains all the arguments, and a subset of the attacks, of the argument graph. We assign a probability value to each spanning subgraph such that the sum of the assignments is 1. This means we can reflect the uncertainty over which is the actual subgraph using this probability distribution. Using the probability distribution over subgraphs, we can then determine the probability that a set of arguments is admissible or an extension. We can also obtain the probability of an attack relationship in the original argument graph as a marginal distribution (i.e. it is the sum of the probability assigned to each subgraph containing that attack relationship). We investigate some of the features of this proposal, and we consider the utility of our framework for capturing some practical argumentation scenarios.", "title": "Probabilistic qualification of attack in abstract argumentation"}, "S2589721719300182": {"highlights": ["Authors have studied different expert and wireless systems employed in agricultural sector.", "Penetration of Artificial intelligence and machine learning is necessary for sustainable development in farming sector.", "The designed system makes the use of deep learning and IOT to classify plants and flowers."], "abstract": "Agriculture automation is the main concern and emerging subject for every country. The world population is increasing at a very fast rate and with increase in population the need for food increases briskly. Traditional methods used by farmers aren't sufficient enough to serve the increasing demand and so they have to hamper the soil by using harmful pesticides in an intensified manner. This affects the agricultural practice a lot and in the end the land remains barren with no fertility. This paper talks about different automation practices like IOT, Wireless Communications, Machine learning and Artificial Intelligence, Deep learning. There are some areas which are causing the problems to agriculture field like crop diseases, lack of storage management, pesticide control, weed management, lack of irrigation and water management and all this problems can be solved by above mentioned different techniques. Today, there is an urgent need to decipher the issues like use of harmful pesticides, controlled irrigation, control on pollution and effects of environment in agricultural practice. Automation of farming practices has proved to increase the gain from the soil and also has strengthened the soil fertility. This paper surveys the work of many researchers to get a brief overview about the current implementation of automation in agriculture. The paper also discusses a proposed system which can be implemented in botanical farm for flower and leaf identification and watering using IOT.", "title": "A comprehensive review on automation in agriculture using artificial intelligence"}, "S1071581918305366": {"highlights": ["A comparative framework allows for an in-depth analysis of shoulder surfing.", "Novel hybrid authentication method based on associations is introduced.", "Empirical evidence shows graphical passwords are more vulnerable to shoulder surfing.", "Other factors also affect the probability of shoulder attacks being successful."], "abstract": "Shoulder surfing is an attack vector widely recognized as a real threat - enough to warrant researchers dedicating a considerable effort toward designing novel authentication methods to be shoulder surfing resistant. Despite a multitude of proposed solutions over the years, few have employed empirical evaluations and comparisons between different methods, and our understanding of the shoulder surfing phenomenon remains limited. Barring the challenges in experimental design, the reason for that can be primarily attributed to the lack of objective and comparable vulnerability measures. In this paper, we develop an ensemble of vulnerability metrics, a first endeavour toward a comprehensive assessment of a given method\u2019s susceptibility to observational attacks. In the largest on-site shoulder surfing experiment (n = 274) to date, we verify the model on four conceptually different authentication methods in two observation scenarios. On the example of a novel hybrid authentication method based on associations, we explore the effect of input type on the adversary\u2019s effectiveness. We provide first empirical evidence that graphical passwords are easier to observe; however, that does not necessarily mean that the observed information will allow the attacker to guess the victim\u2019s password easier. An in-depth analysis of individual metrics within the clusters offers insight into many additional aspects of the shoulder surfing attack not explored before. Our comparative framework makes an advancement in evaluation of shoulder surfing and furthers our understanding of observational attacks. The results have important implications for future shoulder surfing studies and the field of Password Security as a whole.", "title": "Shoulder surfing: From an experimental study to a comparative framework"}, "S0888613X14000589": {"highlights": ["This paper investigated the sum-based merging operator for incommensurable ranked belief bases.", "We propose a characterization of the merging result in terms of compatible scales and in terms of a Pareto-ordering.", "We analyze in details different classes of compatible scales.", "We analyze the behavior of the different operators regarding postulates satisfaction and cautiousness properties.", "We propose a new suitable postulate of consensuality and an impossibility result."], "abstract": "Different methods have been proposed for merging multiple and potentially conflicting information. The merging process based on the so-called \u201cSum\u201d operation offers a natural method for merging commensurable prioritized belief bases. Their popularity is due to the fact that they satisfy the majority property and they adopt a non-cautious attitude in deriving plausible conclusions.\n                  This paper analyzes the sum-based merging operator when sources to merge are incommensurable, namely when they do not share the same meaning of uncertainty scales. We first show that the obtained merging operator can be equivalently characterized either in terms of an infinite set of compatible scales, or by a well-known Pareto ordering on a set of propositional logic interpretations. We also study some restrictions on compatible scales based on different commensurability hypothesis.\n                  Moreover, this paper provides a postulate-based analysis of our merging operators. We show that when prioritized bases to merge are not commensurable, the majority property is no longer satisfied. We provide conditions to recovering it. We also analyze the fairness postulate, which represents the unique postulate unsatisfied when belief bases to merge are commensurable and we propose a new postulate of consensuality. This postulate states that the result of the merging process must be consensual. It obtains the consent of all parties by integrating a piece of belief of each base.\n                  Finally, in the incommensurable case, we show that the fairness and consensuality postulates are satisfied when all compatible scales are considered. However, we provide an impossibility theorem stating that there is no way to satisfy fairness and consensuality postulates if only one canonical compatible scale is considered.", "title": "Sum-based weighted belief base merging: From commensurable to incommensurable framework"}, "S1474034614000391": {"highlights": ["We discuss topological operators as part of a query language for Building Information Models.", "We present novel boundary representation based algorithms implementing these operators.", "We achieve efficient processing of spatial queries by combining the developed BRep methods with spatial indexing.", "The methods are designed for processing complex data sets with high element counts and detailed geometry."], "abstract": "Building Information Models (BIM) are comprehensive digital representations of buildings, which provide a large set of information originating from the different disciplines involved in the design, construction and operation processes. Moreover, accessing the data needed for a specific downstream application scenario is a challenging task in large-scale BIM projects. Several researchers recently proposed using formal query languages for specifying the desired information in a concise, well-defined manner. One of the main limitations of the languages introduced so far, however, is the inadequate treatment of geometric information. This is a significant drawback, as buildings are inherently spatial objects and qualitative spatial relationships accordingly play an important role in the analysis and verification of building models. In addition, the filters needed in specific data exchange scenarios for selecting the information required can be built by spatial objects and their relations. The lack of spatial functionality in BIM query languages is filled by the Query Language for Building Information Models (QL4BIM) which provides metric, directional and topological operators for defining filter expressions with qualitative spatial semantics. This paper focuses on the topological operators provided by the language. In particular, it presents a new implementation method based on the boundary representation of the operands which outperforms the previously presented octree-based approaches. The paper discusses the developed algorithms in detail and presents extensive performance tests.", "title": "Processing of Topological BIM Queries using Boundary Representation Based Methods"}, "S0921889018303245": {"highlights": ["Learning of cloth manipulation by Deep Reinforcement Learning by a dual-arm robot.", "Combine smooth policy update with feature extraction in deep neural networks.", "Propose new Deep Reinforcement Learning based on Dynamic Policy Programming.", "Achieved better sample efficiency than comparisons by smooth policy update."], "abstract": "Deep Reinforcement Learning (DRL), which can learn complex policies with high-dimensional observations as inputs, e.g., images, has been successfully applied to various tasks. Therefore, it may be suitable to apply them for robots to learn and perform daily activities like washing and folding clothes, cooking, and cleaning since such tasks are difficult for non-DRL methods that often require either (1) direct access to state variables or (2) well-designed hand-engineered features extracted from sensory inputs. However, applying DRL to real robots remains very challenging because conventional DRL algorithms require a huge number of training samples for learning, which is arduous in real robots. To alleviate this dilemma, in this paper, we propose two sample efficient DRL algorithms: Deep P-Network (DPN) and Dueling Deep P-Network (DDPN). The core idea is to combine the nature of smooth policy update with the capability of automatic feature extraction in deep neural networks to enhance the sample efficiency and learning stability with fewer samples. The proposed methods were first investigated by a robot-arm reaching task in the simulation that compared previous DRL methods and applied to two real robotic cloth manipulation tasks: (1) flipping a handkerchief and (2) folding a t-shirt with a limited number of samples. All the results suggest that our method outperformed the previous DRL methods.", "title": "Deep reinforcement learning with smooth policy update: Application to robotic cloth manipulation"}, "S0957417417307133": {"highlights": ["Apply reliability and multiple criteria decision analysis techniques to a case study of a disaster.", "Classify hybrid approaches to modelling.", "Value of hybrid modelling is identified and applied to a case study.", "Integration of AHP and FMEA is of value."], "abstract": "In this paper we propose the usage of a hybrid of techniques as complementary tools in decision analysis for learning from failures and the reason behind systems failure. We demonstrate the applicability of these tools through an aviation case study, where an accident investigation report was obtained from the Directorate of Accident Investigation in the Ministry of Transport and Communications in Botswana to provide as a basis for the application of the model. The report included all the factual information required to carry out the investigation using the hybrid of FTA, RBD, AHP, HoQ and the DMG tools.\n                  We discuss the steps followed in applying the tools in the process of learning from failure. It also shows the importance of such tools in accident investigations by showing the importance of prioritising the available options in order of their importance to the accident under investigation.\n                  Most of the available research in learning from failure focuses mostly on the direct causal factors of the failure event. Here we provide a holistic approach to learning from failure by focusing on both direct and indirect causes of a failure event through the use of Reliability Engineering tools, Multi Criteria Decision Making tools and House of Quality.", "title": "A hybrid model for learning from failures"}, "S0933365717306140": {"highlights": ["We devised a novel model to detect mental fatigue of younger and older adults in natural viewing situations.", "We collected eye-tracking data from younger and older adults who watched video clips before and after performing cognitive tasks.", "Our model improved accuracy by up to 13.9% compared with a model based on the previous studies, and it achieved 91.0% accuracy (chance 50%), despite there being age-related changes in the eye-tracking measures."], "abstract": "Health monitoring technology in everyday situations is expected to improve quality of life and support aging populations. Mental fatigue among health indicators of individuals has become important due to its association with cognitive performance and health outcomes, especially in older adults. Previous models using eye-tracking measures allow inference of fatigue during cognitive tasks, such as driving, but they require us to engage in specific cognitive tasks. In addition, previous models were mainly tested by user groups that did not include older adults, although age-related changes in eye-tracking measures have been reported especially in older adults. Here, we propose a model to detect mental fatigue of younger and older adults in natural viewing situations. Our model includes two unique aspects: (i) novel feature sets to better capture fatigue in natural-viewing situations and (ii) an automated feature selection method to select a feature subset enabling the model to be robust to the target's age. To test our model, we collected eye-tracking data from younger and older adults as they watched video clips before and after performing cognitive tasks. Our model improved detection accuracy by up to 13.9% compared with a model based on the previous studies, achieving 91.0% accuracy (chance 50%).", "title": "Detecting mental fatigue from eye-tracking data gathered while watching video: Evaluation in younger and older adults"}, "S0004370215000259": {"highlights": ["We model a virtual player for \u201cWho Wants to be a Millionaire\u201d game.", "The virtual player uses Question Answering over Wikipedia and DBpedia knowledge.", "We performed experiments on the Italian and the English version of the game.", "The virtual player outperforms human players to correctly answer to questions of the game.", "The virtual player outperforms human players to play real games both in terms of level of the game reached and average income."], "abstract": "This paper describes the techniques used to build a virtual player for the popular TV game \u201cWho Wants to Be a Millionaire?\u201d. The player must answer a series of multiple-choice questions posed in natural language by selecting the correct answer among four different choices. The architecture of the virtual player consists of 1) a Question Answering (QA) module, which leverages Wikipedia and DBpedia datasources to retrieve the most relevant passages of text useful to identify the correct answer to a question, 2) an Answer Scoring (AS) module, which assigns a score to each candidate answer according to different criteria based on the passages of text retrieved by the Question Answering module, and 3) a Decision Making (DM) module, which chooses the strategy for playing the game according to specific rules as well as to the scores assigned to the candidate answers.\n                  We have evaluated both the accuracy of the virtual player to correctly answer to questions of the game, and its ability to play real games in order to earn money. The experiments have been carried out on questions coming from the official Italian and English boardgames. The average accuracy of the virtual player for Italian is \n                        79.64\n                        %\n                     , which is significantly better than the performance of human players, which is equal to \n                        51.33\n                        %\n                     . The average accuracy of the virtual player for English is \n                        76.41\n                        %\n                     . The comparison with human players is not carried out for English since, playing successfully the game heavily depends on the players' knowledge about popular culture, and in this experiment we have only involved a sample of Italian players. As regards the ability to play real games, which involves the definition of a proper strategy for the usage of lifelines in order to decide whether to answer to a question even in a condition of uncertainty or to retire from the game by taking the earned money, the virtual player earns \u20ac 114,531 on average for Italian, and \u20ac 88,878 for English, which exceeds the average amount earned by the human players to a greater extent (\u20ac 5926 for Italian).", "title": "Playing with knowledge: A virtual player for \u201cWho Wants to Be a Millionaire?\u201d that leverages question answering techniques"}, "S1071581913001407": {"highlights": ["It demonstrates the use of information resources as a modelling concept.", "It shows how resources can be used to focus analysis on plausible sequences.", "It illustrates the technique by contrasting two real-world examples.", "It specifies and applies precise notions of consistency within activities."], "abstract": "Analysis of the usability of an interactive system requires both an understanding of how the system is to be used and a means of assessing the system against that understanding. Such analytic assessments are particularly important in safety-critical systems as latent vulnerabilities may exist which have negative consequences only in certain circumstances. Many existing approaches to assessment use tasks or scenarios to provide explicit representation of their understanding of use. These normative user behaviours have the advantage that they clarify assumptions about how the system will be used but have the disadvantage that they may exclude many plausible deviations from these norms. Assessments of how a design fails to support these user behaviours can be a matter of judgement based on individual experience rather than evidence. We present a systematic formal method for analysing interactive systems that is based on constraints rather than prescribed behaviour. These constraints capture precise assumptions about what information resources are used to perform action. These resources may either reside in the system itself or be external to the system. The approach is applied to two different medical device designs, comparing two infusion pumps currently in common use in hospitals. Comparison of the two devices is based on these resource assumptions to assess consistency of interaction within the design of each device.", "title": "Analysing interactive devices based on information resource constraints"}, "S2589721719300054": {"highlights": ["Recent advances in emerging techniques for seed viability were reviewed.", "Analytical methods in seed quality and vigor evaluation were briefly described.", "Multivariate regression methods for data processing were compared.", "Technical challenges and future outlook for emerging techniques were presented."], "abstract": "Over the past decades, imaging and spectroscopy techniques have been developed rapidly with widespread applications in non-destructive agro-food quality determination. Seeds are one of the most fundamental elements of agriculture and forestry. Seed viability is of great significance in seed quality characteristics reflecting potential seed germination, and there is a great need for a quick and effective method to determine the germination condition and viability of seeds prior to cultivate, sale and plant. Some researches based on spectra and/or image processing and analysis have been explored in terms of the external and internal quality of a variety of seeds. Many attempts have been made in image segmentation and spectra correction methods to predict seed quality using various traditional and novel methods. This review focuses on the comparative introduction, development and applications of emerging techniques in the analysis of seed viability, in particular, near infrared spectroscopy, hyperspectral and multispectral imaging, Raman spectroscopy, infrared thermography, and soft X-ray imaging methods. The basic theories, principle components, relative chemometric processing, analytical methods and prediction accuracies are reported and compared. Additionally, on the foundation of the observed applications, the technical challenges and future outlook for these emerging techniques are also discussed.", "title": "Recent advances in emerging techniques for non-destructive detection of seed viability: A review"}, "S1474034614000494": {"highlights": ["Identifies information requirements for the representation of service elements of PSS from literature.", "Proposes a representation scheme for PSS that addresses these requirements.", "Validates the scheme through population with case study data and application in a PSS definition system.", "Defines a benchmark PSS for the evaluation of PSS representation schemes.", "Uses the benchmark to compare the scheme in this paper with previously published PSS meta-models and ontologies."], "abstract": "The growing trend for delivering physical products to customers as parts of product service systems (PSS) is creating a need for a new generation of Computer Aided Design (CAD) system to support the design of PSS: so-called \u201cPSS-CAD\u201d. Key research issues in the development of such systems include building understanding of the kinds of applications that designers of PSS might need and the establishment of well-founded representation schemes to underpin and support communication between PSS-CAD systems. Recent literature includes numerous descriptions of integrated PSS development processes, PSS-CAD tools to support these processes and early meta-models to provide information support. This paper complements this work by proposing a representation scheme that is a key prerequisite to achieving the interoperability between PSS-CAD systems which would be necessary to support the deployment of integrated PSS development processes in industry.\n                  The representation scheme, a form of meta-model, draws on learning from the product definition community that emerged in the 1970s in response to a need for interoperability between the different shape-based CAD systems that were being developed at the time. The initial focus on shape representation has developed to digital product definitions that define the design of a product coupled with meta-data recording details of processes by which the design was created and, more recently, supported through-life. Similarly, PSS-related information includes both PSS definitions, to support the lifecycles of physical products and associated services, and meta-data needed to support the management of PSS development processes.\n                  This paper focuses on information requirements for the definition of service elements of PSS and relationships with product elements and service actors. These requirements are derived from earlier work on the use of service blueprinting for the visualisation and mapping of service activities to deliver different types of service contract. Key information requirements addressed include the need to represent service process flow and breakdown structures, relationships between service and product elements, substitution relationships, and service variants. A representation scheme is proposed and demonstrated through application to a PSS case study. The representation scheme is built on a generic information architecture that has already been applied to problems of product definition; as such there is an underlying compatibility that offers real promise in the future realisation of integrated PSS development processes.", "title": "A representation scheme for digital product service system definitions"}, "S0933365715000780": {"highlights": ["We investigate drug NER using limited or no manually annotated data.", "We propose an algorithm for combining methods based on annotations and dictionaries.", "We improved drug NER recall using suffix patterns evolved by genetic programming.", "We improved drug NER performance by aggregating heterogenous drug NER methods.", "We conclude that drug NER can be performed competitively without manual annotations."], "abstract": "Objective\n                  Drug named entity recognition (NER) is a critical step for complex biomedical NLP tasks such as the extraction of pharmacogenomic, pharmacodynamic and pharmacokinetic parameters. Large quantities of high quality training data are almost always a prerequisite for employing supervised machine-learning techniques to achieve high classification performance. However, the human labour needed to produce and maintain such resources is a significant limitation. In this study, we improve the performance of drug NER without relying exclusively on manual annotations.\n               \n               \n                  Methods\n                  We perform drug NER using either a small gold-standard corpus (120 abstracts) or no corpus at all. In our approach, we develop a voting system to combine a number of heterogeneous models, based on dictionary knowledge, gold-standard corpora and silver annotations, to enhance performance. To improve recall, we employed genetic programming to evolve 11 regular-expression patterns that capture common drug suffixes and used them as an extra means for recognition.\n               \n               \n                  Materials\n                  Our approach uses a dictionary of drug names, i.e. DrugBank, a small manually annotated corpus, i.e. the pharmacokinetic corpus, and a part of the UKPMC database, as raw biomedical text. Gold-standard and silver annotated data are used to train maximum entropy and multinomial logistic regression classifiers.\n               \n               \n                  Results\n                  Aggregating drug NER methods, based on gold-standard annotations, dictionary knowledge and patterns, improved the performance on models trained on gold-standard annotations, only, achieving a maximum F-score of 95%. In addition, combining models trained on silver annotations, dictionary knowledge and patterns are shown to achieve comparable performance to models trained exclusively on gold-standard data. The main reason appears to be the morphological similarities shared among drug names.\n               \n               \n                  Conclusion\n                  We conclude that gold-standard data are not a hard requirement for drug NER. Combining heterogeneous models build on dictionary knowledge can achieve similar or comparable classification performance with that of the best performing model trained on gold-standard annotations.", "title": "Boosting drug named entity recognition using an aggregate classifier"}, "S092188901500216X": {"highlights": ["This paper proposes a framework for real-time unsupervised segmentation of human motions and automatic symbolization of the motions.", "The segmentation is based on prediction uncertainty and symbolization is based on competitive learning of human motion.", "Their integration was verified on the human motion datasets."], "abstract": "An interactive loop between motion recognition and motion generation is a fundamental mechanism for humans and humanoid robots. We have been developing an intelligent framework for motion recognition and generation based on symbolizing motion primitives. The motion primitives are encoded into Hidden Markov Models (HMMs), which we call \u201cmotion symbols\u201d. However, to determine the motion primitives to use as training data for the HMMs, this framework requires a manual segmentation of human motions. Essentially, a humanoid robot is expected to participate in daily life and must learn many motion symbols to adapt to various situations. For this use, manual segmentation is cumbersome and impractical for humanoid robots. In this study, we propose a novel approach to segmentation, the Real-time Unsupervised Segmentation (RUS) method, which comprises three phases. In the first phase, short human movements are encoded into feature HMMs. Seamless human motion can be converted to a sequence of these feature HMMs. In the second phase, the causality between the feature HMMs is extracted. The causality data make it possible to predict movement from observation. In the third phase, movements having a large prediction uncertainty are designated as the boundaries of motion primitives. In this way, human whole-body motion can be segmented into a sequence of motion primitives. This paper also describes an application of RUS to AUtonomous Symbolization of motion primitives (AUS). Each derived motion primitive is classified into an HMM for a motion symbol, and parameters of the HMMs are optimized by using the motion primitives as training data in competitive learning. The HMMs are gradually optimized in such a way that the HMMs can abstract similar motion primitives. We tested the RUS and AUS frameworks on captured human whole-body motions and demonstrated the validity of the proposed framework.", "title": "Real-time Unsupervised Segmentation of human whole-body motion and its application to humanoid robot acquisition of motion symbols"}, "S0888613X15000894": {"highlights": ["We design, develop, and construct a granular fuzzy model that produces granular results instead of numeric values.", "Our method captures the diversity of data and handles the lack of numeric precision to be more reflective of reality.", "The model is formed by means of a fuzzy clustering algorithm known as conditional Fuzzy C-Means.", "The model is optimized by using Differential Evolution along with coverage criteria.", "The optimized model can be interpreted as a collection of \u201cif\u2013then\u201d rules formed from the architecture."], "abstract": "The study is concerned with a design of granular fuzzy models. We exploit a concept of information granularity by developing a model coming as a network of intuitively structured collection of interval information granules described in the output space and a family of induced information granules (in the form of fuzzy sets) formed in the input space. In contrast to most fuzzy models encountered in the literature, the results produced by granular models are information granules rather than plain numeric entities. The design of the model concentrates on a construction of information granules that form a backbone of the overall construct. Interval information granules positioned in the output space are built by considering intervals of equal length, equal probability, and developing an optimized version of the intervals. The induced fuzzy information granules localized in the input space are realized by running a conditional Fuzzy C-Means (FCM). The performance of the model is assessed by considering criteria of coverage and information specificity (information granularity). Further optimization of the model is proposed along the line of an optimal re-distribution of input information granules induced by the individual interval information granules located in the output space. Experimental results involve some synthetic low-dimensional data and publicly available benchmark data sets.\n               \n            \n\nIn spite of the truly remarkable diversity of architectures of fuzzy models and ensuing design approaches [8,13,17\u201322,25,35,51], the models share one common feature. Fuzzy models, regardless of the use of the technology of fuzzy sets, produce numeric results. In contrast, linguistic models [5,10\u201312,15,40,42,43,52,53,59] form an interesting conceptual and design alternative in the plethora of fuzzy models in the sense their structure is intuitively appealing and the results are inherently coming as information granules (fuzzy sets). In the construction of fuzzy models, various clustering techniques are often used, in particular Fuzzy C-Means (FCM) [9]. In [57], a modified FCM algorithm, combined with a back-propagation algorithm, was implemented to construct detailed fuzzy models by using a weighted FCM algorithm. In [58], FCM was used to generate discrete interval-valued type-2 fuzzy models. A fuzzy C-Regression model is proposed in [27] to automatically determine a suitable number of rules from a given fuzzy model. In [26], a fuzzy clustering technique was developed to generate hyperplane-like clusters, which helped improve the estimation of Takagi\u2013Sugeno (T\u2013S) fuzzy models. Another clustering technique, based on a combination of FCM and switching regression algorithms [10] was used to construct enhanced fuzzy models with an improved fuzzy clustering and better structure identification. A different clustering approach helps identify T\u2013S fuzzy models from clusters obtained with a modified Gath\u2013Geva algorithm [6]. In this approach, the best number of clusters is determined by using a validity measure. A face recognition approach [29] used partition matrices obtained with the FCM algorithm as input patterns to train artificial neural networks (ANNs). Other architectures that are similar to ANNs, are the neural fuzzy controller (NEFCON) [30\u201332] and neuro-fuzzy classification (NEFCLASS) model [33]. These structures use fuzzy sets as weights, and can be interpreted as linguistic \u201cif\u2013then\u201d rules. The obtained results are defuzzified (decoded) producing numeric values. In contrast to our model, these architectures do not induce fuzzy classification rules by granulating the data; instead the fuzzy partition predefined in each input dimension is adjusted by a training mechanism.\n\nIn linguistic models clustering is used more intensively, leading to the formation of information granules in the output space and subsequently producing induced information granules positioned in the input space. One of the earliest models falling under this category was proposed in [50], where the FCM algorithm was used to identify the structure of a fuzzy model in many-input single-output systems. In this approach, the ordinary fuzzy partition of the input space is avoided. Instead, the output data is clustered and the clusters (prototypes) are projected onto the individual input coordinates. This produces fuzzy rules that can be defuzzified into numeric entities. In our approach, since the output space is granulated with the optimized interval-based information granules, the results are produced in the form of intervals. Similar interval-based clusters were proposed in [28] to granulate time-series and improve the forecasting accuracy of a model. These intervals are optimized by gradually adjusting their widths until they become more reasonable and informative. In our study, an optimization mechanism is used to adjust the widths of the intervals to improve performance of the granular model. In other studies [1,3,54,56], the information granules are induced by projecting hyperbox clusters from the multidimensional input space onto each input coordinate spaces. While this approach exhibits some similarity to the approach pursued here, it differs in the way the input clusters are induced, which is done from information granules located in the output space. In more comparable approaches, a set of intervals formed in the output space is used as classes to turn an approximation problem into a classification task, and to induce the formation of hyperboxes [2] and hyper-ellipsoids [55] in the input space, nonetheless the values at the end are defuzzified into numeric values. In [45], information granulation is used to induce consistent granular structures, which help build a knowledge distance that is used to form a lattice model that reveals the essence of information granularity. Lattice computing is used in several studies to enhance fuzzy models, where intervals are used to represent fuzzy sets, either described as \u03b1-cuts [39], or as fuzzy membership functions. Since these intervals are partially-ordered, they are considered as a lattice, hence mathematical lattice theory can be applied to build tunable fuzzy models [19\u201321,34]. In [46] and [47], the objective function of the clustering algorithm was modified to introduce a directionality component to the formation of the prototypes, the resulting information granules are used to form \u201cif\u2013then\u201d rules. Redundant rules were merged and conflicting rules were eliminated to increase the coverage of important regions in the data. Also in [38] particle swarm optimization (PSO) was used to construct interval-based cluster centers (prototypes), where the widths of the intervals are adjusted through a granulation\u2013degranulation scheme. In this way, a granular version of the original data was formed. By using a coverage criterion as an objective function, it was possible to allocate the granularity of the data.\n\nTo put the subject matter in a more general setting, granular fuzzy models are essentially about building models at the level of information granules, not numeric evidence. Since experimental numeric data lead to information granules, these are structured in the form of information granules. Subsequently, these information granules are linked together by developing a backbone (blueprint) of the model. In the design of such linkages it has to be acknowledged that in most situations models are direction-oriented constructs. Clustering itself produces direction-free building blocks. To bring a directionality component onto the granular fuzzy models, the formation of information granules is realized in two phases. First, information granules are constructed in the output space. Second, for a given information granule in the output space, a collection of induced information granules is built by engaging some clustering mechanism. In this sense, information granules emerging in the input space are directly implied by the structure already established in the output space. Furthermore the associations among information granules in the input and output spaces are transparent and in this way we can easily form the linkages of the model.\n\nThe objective of this study is to design and develop a granular fuzzy model that takes the input and target data to form an information granule. Having these granules available, the main goal is to build a model at the level of information granules. The design process consists of several main phases: 1) defining and refining intervals in the output space; 2) completing conditional fuzzy clustering on the input data induced by the intervals constructed; and 3) optimizing the intervals and alternatively, the number of clusters in each interval. We are also interested in studying the impact the number of intervals, size of each interval, number of clusters per interval, and the fuzzification factor of the clustering method have in the construction of these information granules. Throughout the study, we demonstrate that in granular modeling, information granules play an important and multifaceted role:\n                        \n                           \u2022\n                           The model is built as a network of associations among information granules. This supports interpretability of the model, which becomes easily translated into a collection of rules with condition and conclusion parts being formed by the constructed information granules.\n\nInformation granules form conceptual sound building blocks (supported by data) and in light of their functionality, can be used in the formation of a variety of relationships among input and output variables.\n\nInformation granules serve as sound descriptors of data. Each information granule comes with its own well-defined semantics and as such the granules can be associated with a certain linguistically sound meaning. In this way one can produce a general sound view at the data.\n\nIn comparison with the earlier studies on linguistic models reported in [16,24,25,40\u201342], the research discussed here exhibits several novel facets and raises and addresses new interesting issues. The question of optimization of input information granules is of paramount relevance and this is addressed here. The optimization criteria, both coverage and specificity are also studied here. The ensuing Differential Evolution (DE) [44,48,49] is invoked to serve as a key optimization vehicle. A number of vital design issues concerning parameters of the information granules are also raised and discussed.\n\nThe study is structured as follows. In Section 2, the architecture of the model is briefly described. Since the model heavily relies on information granules, it is essential to focus on its design. The details of the construction of the information granules and their optimization are presented in Section 3, where we focus on a specialized fuzzy clustering algorithm, namely a context-based FCM. A series of numeric experiments are presented in Section 4 and they show the performance of the model. In the experiments, we use synthetic data and selected data coming from publicly available machine-learning repositories. The model is further refined by applying Differential Evolution (DE) as being explained in Section 5. We also provide more numerical experiments. The concluding comments are covered in Section 6.\n\nThe model proposed in this study is inherently structured around information granules and from an architectural perspective it arises as a network of connected information granules. The general topology of the model is shown in Fig. 1\n                     ; see also [42]. It becomes beneficial to analyze to this figure in more detail to gain a better view at the topology and the ensuing design of the model.\n\nAs visualized there, we encounter a collection of connected information granules. There is a collection of information granules in the form of intervals \n                        \n                           \n                              B\n                           \n                           \n                              1\n                           \n                        \n                        ,\n                        \n                           \n                              B\n                           \n                           \n                              2\n                           \n                        \n                        ,\n                        \u2026\n                        ,\n                        \n                           \n                              B\n                           \n                           \n                              p\n                           \n                        \n                      positioned in the output space. Let \n                        \n                           \n                              B\n                           \n                           \n                              h\n                           \n                        \n                        =\n                        [\n                        \n                           \n                              b\n                           \n                           \n                              h\n                           \n                           \n                              \u2212\n                           \n                        \n                        ,\n                        \n                           \n                              b\n                           \n                           \n                              h\n                           \n                           \n                              +\n                           \n                        \n                        ]\n                     , \n                        h\n                        =\n                        1\n                        ,\n                        2\n                        ,\n                        \u2026\n                        ,\n                        p\n                      denote the lower and upper bounds of the hth interval, while p is the number of intervals. These intervals form a partition of the output space (meaning that those intervals are pairwise disjoint and cover the entire output space). Each \n                        \n                           \n                              B\n                           \n                           \n                              h\n                           \n                        \n                      is projected onto the input space and reflected there through a collection of information granules (fuzzy sets) in \n                        \n                           \n                              R\n                           \n                           \n                              n\n                           \n                        \n                      located at the first layer of the structure of the model, where \n                        R\n                      is the set of real numbers and n is the dimensionality of the input data (input space). In general, for each \n                        \n                           \n                              B\n                           \n                           \n                              h\n                           \n                        \n                     , there could be a certain number of clusters formed, say \n                        \n                           \n                              c\n                           \n                           \n                              1\n                           \n                        \n                        ,\n                        \n                           \n                              c\n                           \n                           \n                              2\n                           \n                        \n                        ,\n                        \u2026\n                     \u2009, and \n                        \n                           \n                              c\n                           \n                           \n                              p\n                           \n                        \n                     , respectively.\n\nThere are two essential key features of the model. First, we build as a collection of information granules (both in the input and output space) and those in the input space are directly induced by the output information granules (see Fig. 2\n                     ). Second, the results produced by the model are granular rather than numeric ones. This becomes apparent by looking at the computing realized by the model.\n\nAny numeric input datum \n                        \n                           \n                              x\n                           \n                           \n                              k\n                           \n                        \n                     , \n                        k\n                        =\n                        1\n                        ,\n                        2\n                        ,\n                        \u2026\n                        ,\n                        N\n                      \u201cactivates\u201d the input information granules and produces the corresponding degrees of membership, where N is the number of data. Those being produced by the fuzzy sets implied by the same output interval are then aggregated (summed) as \n                        \n                           \n                              z\n                           \n                           \n                              h\n                           \n                        \n                        (\n                        \n                           \n                              x\n                           \n                           \n                              k\n                           \n                        \n                        )\n                        =\n                        \n                           \n                              \u2211\n                           \n                           \n                              i\n                              =\n                              1\n                           \n                           \n                              c\n                           \n                        \n                        \n                           \n                              u\n                           \n                           \n                              h\n                              i\n                              k\n                           \n                        \n                     , where \n                        \n                           \n                              u\n                           \n                           \n                              h\n                              i\n                              k\n                           \n                        \n                      is the ith membership degree in the hth context for the kth input datum, thus giving rise to the overall activation level \n                        \n                           \n                              z\n                           \n                           \n                              h\n                           \n                        \n                        (\n                        \n                           \n                              x\n                           \n                           \n                              k\n                           \n                        \n                        )\n                      for the hth interval. In the sequel, the summation of the partial results is performed as follows:\n                        \n                           (1)\n                           \n                              \n                                 \n                                    Y\n                                 \n                                 \n                                    k\n                                 \n                              \n                              =\n                              \n                                 \u2211\n                                 \n                                    h\n                                    =\n                                    1\n                                 \n                                 p\n                              \n                              \n                                 (\n                                 \n                                    \n                                       z\n                                    \n                                    \n                                       h\n                                    \n                                 \n                                 (\n                                 \n                                    \n                                       x\n                                    \n                                    \n                                       k\n                                    \n                                 \n                                 )\n                                 \u2297\n                                 \n                                    \n                                       B\n                                    \n                                    \n                                       h\n                                    \n                                 \n                                 (\n                                 \n                                    \n                                       x\n                                    \n                                    \n                                       k\n                                    \n                                 \n                                 )\n                                 )\n                              \n                           \n                        \n                      where \n                        \n                           \n                              z\n                           \n                           \n                              h\n                           \n                        \n                        (\n                        \n                           \n                              x\n                           \n                           \n                              k\n                           \n                        \n                        )\n                      and \n                        \n                           \n                              B\n                           \n                           \n                              h\n                           \n                        \n                        (\n                        \n                           \n                              x\n                           \n                           \n                              k\n                           \n                        \n                        )\n                      indicate that these variables are dependent of the input datum \n                        \n                           \n                              x\n                           \n                           \n                              k\n                           \n                        \n                     . We denote the algebraic operation by \u2297 to emphasize that the underlying computing operates on a collection of intervals, e.g. \n                        a\n                        \u2297\n                        R\n                        =\n                        [\n                        a\n                        \u204e\n                        \n                           \n                              r\n                           \n                           \n                              \u2212\n                           \n                        \n                        ,\n                        a\n                        \u204e\n                        \n                           \n                              r\n                           \n                           \n                              +\n                           \n                        \n                        ]\n                     , note that \n                        R\n                        =\n                        [\n                        \n                           \n                              r\n                           \n                           \n                              \u2212\n                           \n                        \n                        ,\n                        \n                           \n                              r\n                           \n                           \n                              +\n                           \n                        \n                        ]\n                      and the symbol \u204e is used as the \u201cconventional\u201d multiplication. Following calculations known in interval mathematics [23], the final result is an interval with bounds determined on a basis of the bounds of the individual intervals and their associated activation levels, namely:\n                        \n                           (2)\n                           \n                              \n                                 \n                                    \n                                       Y\n                                    \n                                    \n                                       k\n                                    \n                                 \n                                 =\n                                 \n                                    [\n                                    \n                                       \n                                          y\n                                       \n                                       \n                                          k\n                                       \n                                       \n                                          \u2212\n                                       \n                                    \n                                    ,\n                                    \n                                       \n                                          y\n                                       \n                                       \n                                          k\n                                       \n                                       \n                                          +\n                                       \n                                    \n                                    ]\n                                 \n                                 =\n                                 \n                                    \u2211\n                                    \n                                       h\n                                       =\n                                       1\n                                    \n                                    p\n                                 \n                                 \n                                    (\n                                    \n                                       \n                                          z\n                                       \n                                       \n                                          h\n                                       \n                                    \n                                    (\n                                    \n                                       \n                                          x\n                                       \n                                       \n                                          k\n                                       \n                                    \n                                    )\n                                    \u204e\n                                    \n                                       [\n                                       \n                                          \n                                             b\n                                          \n                                          \n                                             h\n                                          \n                                          \n                                             \u2212\n                                          \n                                       \n                                       (\n                                       \n                                          \n                                             x\n                                          \n                                          \n                                             k\n                                          \n                                       \n                                       )\n                                       ,\n                                       \n                                          \n                                             b\n                                          \n                                          \n                                             h\n                                          \n                                          \n                                             +\n                                          \n                                       \n                                       (\n                                       \n                                          \n                                             x\n                                          \n                                          \n                                             k\n                                          \n                                       \n                                       )\n                                       ]\n                                    \n                                    )\n                                 \n                              \n                           \n                           \n                              \n                                 \n                                    \n                                       y\n                                    \n                                    \n                                       k\n                                    \n                                    \n                                       \u2212\n                                    \n                                 \n                                 =\n                                 \n                                    (\n                                    \n                                       \n                                          z\n                                       \n                                       \n                                          1\n                                       \n                                    \n                                    (\n                                    \n                                       \n                                          x\n                                       \n                                       \n                                          k\n                                       \n                                    \n                                    )\n                                    \u204e\n                                    \n                                       \n                                          b\n                                       \n                                       \n                                          1\n                                       \n                                       \n                                          \u2212\n                                       \n                                    \n                                    (\n                                    \n                                       \n                                          x\n                                       \n                                       \n                                          k\n                                       \n                                    \n                                    )\n                                    )\n                                 \n                                 +\n                                 \n                                    (\n                                    \n                                       \n                                          z\n                                       \n                                       \n                                          2\n                                       \n                                    \n                                    (\n                                    \n                                       \n                                          x\n                                       \n                                       \n                                          k\n                                       \n                                    \n                                    )\n                                    \u204e\n                                    \n                                       \n                                          b\n                                       \n                                       \n                                          2\n                                       \n                                       \n                                          \u2212\n                                       \n                                    \n                                    (\n                                    \n                                       \n                                          x\n                                       \n                                       \n                                          k\n                                       \n                                    \n                                    )\n                                    )\n                                 \n                                 +\n                                 \u22ef\n                                 +\n                                 \n                                    (\n                                    \n                                       \n                                          z\n                                       \n                                       \n                                          p\n                                       \n                                    \n                                    (\n                                    \n                                       \n                                          x\n                                       \n                                       \n                                          k\n                                       \n                                    \n                                    )\n                                    \u204e\n                                    \n                                       \n                                          b\n                                       \n                                       \n                                          p\n                                       \n                                       \n                                          \u2212\n                                       \n                                    \n                                    (\n                                    \n                                       \n                                          x\n                                       \n                                       \n                                          k\n                                       \n                                    \n                                    )\n                                    )\n                                 \n                              \n                           \n                           \n                              \n                                 \n                                    \n                                       y\n                                    \n                                    \n                                       k\n                                    \n                                    \n                                       +\n                                    \n                                 \n                                 =\n                                 \n                                    (\n                                    \n                                       \n                                          z\n                                       \n                                       \n                                          1\n                                       \n                                    \n                                    (\n                                    \n                                       \n                                          x\n                                       \n                                       \n                                          k\n                                       \n                                    \n                                    )\n                                    \u204e\n                                    \n                                       \n                                          b\n                                       \n                                       \n                                          1\n                                       \n                                       \n                                          +\n                                       \n                                    \n                                    (\n                                    \n                                       \n                                          x\n                                       \n                                       \n                                          k\n                                       \n                                    \n                                    )\n                                    )\n                                 \n                                 +\n                                 \n                                    (\n                                    \n                                       \n                                          z\n                                       \n                                       \n                                          2\n                                       \n                                    \n                                    (\n                                    \n                                       \n                                          x\n                                       \n                                       \n                                          k\n                                       \n                                    \n                                    )\n                                    \u204e\n                                    \n                                       \n                                          b\n                                       \n                                       \n                                          2\n                                       \n                                       \n                                          +\n                                       \n                                    \n                                    (\n                                    \n                                       \n                                          x\n                                       \n                                       \n                                          k\n                                       \n                                    \n                                    )\n                                    )\n                                 \n                                 +\n                                 \u22ef\n                                 +\n                                 \n                                    (\n                                    \n                                       \n                                          z\n                                       \n                                       \n                                          p\n                                       \n                                    \n                                    (\n                                    \n                                       \n                                          x\n                                       \n                                       \n                                          k\n                                       \n                                    \n                                    )\n                                    \u204e\n                                    \n                                       \n                                          b\n                                       \n                                       \n                                          p\n                                       \n                                       \n                                          +\n                                       \n                                    \n                                    (\n                                    \n                                       \n                                          x\n                                       \n                                       \n                                          k\n                                       \n                                    \n                                    )\n                                    )\n                                 \n                              \n                           \n                        \n                     \n                  \n\nAs usual in system modeling, a granular fuzzy model is constructed on a basis of certain data which come in the form of a collection of input\u2013output data pairs \n                        (\n                        \n                           \n                              x\n                           \n                           \n                              k\n                           \n                        \n                        ,\n                        \n                           \n                              t\n                           \n                           \n                              k\n                           \n                        \n                        )\n                     , where \n                        \n                           \n                              x\n                           \n                           \n                              k\n                           \n                        \n                        \u2208\n                        \n                           \n                              R\n                           \n                           \n                              n\n                           \n                        \n                      and \n                        \n                           \n                              t\n                           \n                           \n                              k\n                           \n                        \n                        \u2208\n                        R\n                     . The formation of information granules in the output space is guided by some optimization criterion. Once they have been constructed, they induce a family of information granules in the input space.\n\nConsidering the architecture of the granular model portrayed in Fig. 1, it can be translated into a series of rules in a straightforward fashion as the condition and conclusion components are shown explicitly in the structure. The clusters (described by their prototypes) form the condition part of the rules while the intervals in the output space are located in the conclusion part of the rule. For the hth interval \n                        \n                           \n                              B\n                           \n                           \n                              h\n                           \n                        \n                     , we have c clusters positioned in the input space and consequently a union of the input fuzzy sets, thus giving rise to the rule of the following format:\n                        \n                           (3)\n                           \n                              if \n                              \n                                 \n                                    A\n                                 \n                                 \n                                    h\n                                    1\n                                 \n                              \n                               or \n                              \n                                 \n                                    A\n                                 \n                                 \n                                    h\n                                    2\n                                 \n                              \n                               or \n                              \u2026\n                               or \n                              \n                                 \n                                    A\n                                 \n                                 \n                                    h\n                                    c\n                                 \n                              \n                               then \n                              \n                                 \n                                    B\n                                 \n                                 \n                                    h\n                                 \n                              \n                           \n                        \n                      where \n                        \n                           \n                              A\n                           \n                           \n                              h\n                              1\n                           \n                        \n                        ,\n                        \n                           \n                              A\n                           \n                           \n                              h\n                              2\n                           \n                        \n                        ,\n                        \u2026\n                        ,\n                        \n                           \n                              A\n                           \n                           \n                              h\n                              c\n                           \n                        \n                      are the fuzzy sets in \n                        \n                           \n                              R\n                           \n                           \n                              n\n                           \n                        \n                      with the membership functions computed on a basis of a set of prototypes \n                        {\n                        \n                           \n                              v\n                           \n                           \n                              h\n                              1\n                           \n                        \n                        ,\n                        \n                           \n                              v\n                           \n                           \n                              h\n                              2\n                           \n                        \n                        ,\n                        \u2026\n                        ,\n                        \n                           \n                              v\n                           \n                           \n                              h\n                              c\n                           \n                        \n                        }\n                      respectively, where \n                        \n                           \n                              v\n                           \n                           \n                              h\n                              i\n                           \n                        \n                     , \n                        i\n                        =\n                        1\n                        ,\n                        2\n                        ,\n                        \u2026\n                        ,\n                        c\n                     , describes the coordinates of the ith cluster center of the hth context computed in the clustering stage. In the sequel, if more detailed interpretability is required, the prototypes can be projected onto the individual input variables and then the condition part can be read as a Cartesian product of fuzzy sets defined in the individual input spaces, say \n                        \n                           \n                              A\n                           \n                           \n                              h\n                              i\n                           \n                        \n                        =\n                        \n                           \n                              A\n                           \n                           \n                              h\n                              i\n                           \n                        \n                        (\n                        1\n                        )\n                        \u00d7\n                        \n                           \n                              A\n                           \n                           \n                              h\n                              i\n                           \n                        \n                        (\n                        2\n                        )\n                        \u00d7\n                        \n                           \n                              A\n                           \n                           \n                              h\n                              i\n                           \n                        \n                        (\n                        n\n                        )\n                     , that reads as\n                        \n                           (4)\n                           \n                              \n                                 \n                                    A\n                                 \n                                 \n                                    h\n                                    i\n                                 \n                              \n                              (\n                              1\n                              )\n                               and \n                              \n                                 \n                                    A\n                                 \n                                 \n                                    h\n                                    i\n                                 \n                              \n                              (\n                              2\n                              )\n                               and \n                              \u2026\n                               and \n                              \n                                 \n                                    A\n                                 \n                                 \n                                    h\n                                    i\n                                 \n                              \n                              (\n                              n\n                              )\n                           \n                        \n                     \n                  \n\nAs portrayed in Fig. 2\n                     c, a two-dimensional synthetic dataset consisting of 1000 points around five points is randomly generated by using a normal distribution. This leads to five clouds of overlapping data. A symmetric function is then used to calculate a target output value described as \n                        t\n                        =\n                        \n                           \n                              x\n                           \n                           \n                              1\n                           \n                        \n                        \u204e\n                        \n                           \n                              x\n                           \n                           \n                              2\n                           \n                        \n                        \u204e\n                        exp\n                        \u2061\n                        (\n                        \u2212\n                        \n                           \n                              x\n                           \n                           \n                              1\n                           \n                           \n                              2\n                           \n                        \n                        \u2212\n                        \n                           \n                              x\n                           \n                           \n                              2\n                           \n                           \n                              2\n                           \n                        \n                        )\n                     . Furthermore, the output space is divided into four intervals \n                        \n                           \n                              B\n                           \n                           \n                              1\n                           \n                        \n                        ,\n                        \n                           \n                              B\n                           \n                           \n                              2\n                           \n                        \n                        ,\n                        \n                           \n                              B\n                           \n                           \n                              3\n                           \n                        \n                        ,\n                         and\n                        ,\n                        \n                        \n                           \n                              B\n                           \n                           \n                              4\n                           \n                        \n                     , with a different size and position of the cutoff points (Fig. 2\n                     a and b), in order to construct five clusters in each induced input space. As depicted there, these clusters have a direct influence on the data and on the distribution of the prototypes (black dots) induced in the input space. Henceforth, the formation of the output information granules is crucial and several strategies of their development are to be investigated. The input information granules are constructed for the individual output information granules and those are built by using an augmented version of Fuzzy C-Means (FCM) [9], known as a so-called conditional or context-based FCM [36,37]. The detailed construction of all information granules is covered in the ensuing sections.\n\nIn this section, we discuss the main design phases of the model. Information granules are viewed as key conceptual components and those will be looked at in great detail. Here we engage a certain optimization process.\n\nAs previously discussed, the interval information granules formed in the output space are critical to the functioning of the overall model as subsequently they shape up a collection of information granules emerging in the input space. Several intuitively appealing ways of building a collection of intervals are sought:\n\n\n                           Equal size intervals. We make the intervals of the same length by splitting the range of the output space into intervals (bins) of equal size. The method is simple however the intervals formed in this manner do not reflect the nature of the data: there could be a few data points for which a separate interval is formed while a large number of data (exhibiting potentially high diversity) are accommodated within the same interval (which could have a detrimental impact on the performance of the model).\n\n\n                           Equal probability (EP) intervals. The intervals are formed in such a way so that each interval includes the same number of data (a fraction \n                              p\n                              /\n                              N\n                           , to be specific). In other words, the intervals are relatively narrow if there is a large number of data in this region, and become broad if the density of data is low.\n\nIrrespectively of the way the intervals are formed, there is a common limitation associated with them \u2013 they do not reflect the nature of input data (by being exclusively focused on the output space and not taking into consideration the input\u2013output relationships).\n\n\n                           Optimization of intervals. The intervals are optimized by forming them in a way it models the input\u2013output dependencies (which are the crux of any model). With this regard, we formulate a suitable performance index and establish an optimization scheme.\n\nInformation granules in the input space are determined on a basis of the already formed intervals in the output space. The rationale here is to map the output interval to the corresponding regions of the input. The essence is to run clustering, but in contrast to the \u201cstandard\u201d FCM, here we invoke a so-called conditional FCM [36,37]. We cluster the data that are falling within a context of \n                              \n                                 \n                                    B\n                                 \n                                 \n                                    h\n                                 \n                              \n                            \u2013 in other words, the clustering is conditioned by the output interval.\n\nFor each of data set falling within \n                              \n                                 \n                                    B\n                                 \n                                 \n                                    h\n                                 \n                              \n                           , the task is to determine its structure and obtain a collection of cluster centers (prototypes) by clustering the data with FCM. For simplicity let us consider that the number of clusters c produced for each interval is equal. The FCM algorithm is realized iteratively in each context h by updating the values of the partition matrix and the prototypes. To update the entries of the partition matrix we use the following expression [9,39],\n                              \n                                 (5)\n                                 \n                                    \n                                       \n                                          u\n                                       \n                                       \n                                          h\n                                          i\n                                          k\n                                       \n                                    \n                                    =\n                                    \n                                       1\n                                       \n                                          \n                                             \n                                                \u2211\n                                             \n                                             \n                                                j\n                                                =\n                                                1\n                                             \n                                             \n                                                c\n                                             \n                                          \n                                          \n                                             \n                                                (\n                                                \n                                                   \n                                                      \u2016\n                                                      \n                                                         \n                                                            x\n                                                         \n                                                         \n                                                            h\n                                                            k\n                                                         \n                                                      \n                                                      \u2212\n                                                      \n                                                         \n                                                            v\n                                                         \n                                                         \n                                                            h\n                                                            i\n                                                         \n                                                      \n                                                      \u2016\n                                                   \n                                                   \n                                                      \u2016\n                                                      \n                                                         \n                                                            x\n                                                         \n                                                         \n                                                            h\n                                                            k\n                                                         \n                                                      \n                                                      \u2212\n                                                      \n                                                         \n                                                            v\n                                                         \n                                                         \n                                                            h\n                                                            j\n                                                         \n                                                      \n                                                      \u2016\n                                                   \n                                                \n                                                )\n                                             \n                                             \n                                                \n                                                   2\n                                                   \n                                                      m\n                                                      \u2212\n                                                      1\n                                                   \n                                                \n                                             \n                                          \n                                       \n                                    \n                                 \n                              \n                            where \n                              i\n                              =\n                              1\n                              ,\n                              2\n                              ,\n                              \u2026\n                              ,\n                              c\n                           , \n                              k\n                              =\n                              1\n                              ,\n                              2\n                              ,\n                              \u2026\n                              ,\n                              N\n                           , \n                              h\n                              =\n                              1\n                              ,\n                              2\n                              ,\n                              \u2026\n                              ,\n                              p\n                           . Furthermore, \n                              \n                                 \n                                    u\n                                 \n                                 \n                                    h\n                                    i\n                                    k\n                                 \n                              \n                            represents the element of the partition matrix induced by the ith cluster and the kth data in the hth context, \n                              \n                                 \n                                    x\n                                 \n                                 \n                                    k\n                                    h\n                                 \n                              \n                            is the kth data in the hth context, \n                              \u2016\n                              \u22c5\n                              \u2016\n                            stands for some distance function, and m (>1.0) is the fuzzification coefficient. Assuming that the Euclidean distance is used, the cluster centers (prototypes) are calculated as follows,\n                              \n                                 (6)\n                                 \n                                    \n                                       \n                                          v\n                                       \n                                       \n                                          h\n                                          i\n                                       \n                                    \n                                    =\n                                    \n                                       \n                                          \n                                             \n                                                \u2211\n                                             \n                                             \n                                                k\n                                                =\n                                                1\n                                             \n                                             \n                                                N\n                                             \n                                          \n                                          \n                                             \n                                                u\n                                             \n                                             \n                                                h\n                                                i\n                                                k\n                                             \n                                             \n                                                m\n                                             \n                                          \n                                          \n                                             \n                                                x\n                                             \n                                             \n                                                h\n                                                k\n                                             \n                                          \n                                       \n                                       \n                                          \n                                             \n                                                \u2211\n                                             \n                                             \n                                                k\n                                                =\n                                                1\n                                             \n                                             \n                                                N\n                                             \n                                          \n                                          \n                                             \n                                                u\n                                             \n                                             \n                                                h\n                                                i\n                                                k\n                                             \n                                             \n                                                m\n                                             \n                                          \n                                       \n                                    \n                                 \n                              \n                           \n                        \n\nThe value of the fuzzification coefficient m affects the shape of the membership functions (clusters) being generated. With the lower values of m, the membership functions tend to resemble characteristic functions of sets, whilst obtaining fewer elements with intermediate membership values. Higher values of m produce spiky membership functions with a profound rippling effect, the elements tend to show more local minima, and the values start to position closer to the averages of the modes. A common value found in the literature is \n                              m\n                              =\n                              2\n                           , which constitutes a reasonable compromise between set-like membership functions and membership function exhibiting excessive oscillations in the membership grades produced by high values of m.\n\nAs portrayed in Fig. 3\n                           , the prototypes obtained for each context by using (5) and (6), are combined and utilized to determine a new partition matrix for the input data, now having \n                              c\n                              \u00d7\n                              p\n                            clusters. The elements of the partition matrix that correspond to each interval are summed as \n                              \n                                 \n                                    z\n                                 \n                                 \n                                    h\n                                 \n                              \n                              (\n                              \n                                 \n                                    x\n                                 \n                                 \n                                    k\n                                 \n                              \n                              )\n                              =\n                              \n                                 \n                                    \u2211\n                                 \n                                 \n                                    i\n                                    =\n                                    1\n                                 \n                                 \n                                    c\n                                 \n                              \n                              \n                                 \n                                    u\n                                 \n                                 \n                                    h\n                                    i\n                                    k\n                                 \n                              \n                           . Since in the traditional FCM the partition matrix has to satisfy the condition \n                              \n                                 \n                                    \u2211\n                                 \n                                 \n                                    i\n                                    =\n                                    1\n                                 \n                                 \n                                    c\n                                 \n                              \n                              \n                                 \n                                    u\n                                 \n                                 \n                                    i\n                                    k\n                                 \n                              \n                              =\n                              1\n                           , then in this case the next condition has to be satisfied,\n                              \n                                 (7)\n                                 \n                                    \n                                       \u2211\n                                       \n                                          h\n                                          =\n                                          1\n                                       \n                                       p\n                                    \n                                    \n                                       \n                                          z\n                                       \n                                       \n                                          h\n                                       \n                                    \n                                    (\n                                    \n                                       \n                                          x\n                                       \n                                       \n                                          k\n                                       \n                                    \n                                    )\n                                    =\n                                    1\n                                 \n                              \n                            Each interval impacts the performance of the clustering mechanism: if \n                              \n                                 \n                                    z\n                                 \n                                 \n                                    h\n                                 \n                              \n                              >\n                              \n                                 \n                                    z\n                                 \n                                 \n                                    h\n                                    +\n                                    1\n                                 \n                              \n                            then the data placed under \n                              \n                                 \n                                    B\n                                 \n                                 \n                                    h\n                                 \n                              \n                            produces a partition matrix whose result will have a higher membership degree in its corresponding node, henceforth it produces an interval that is formed around its corresponding numeric output value.\n\nTo evaluate the granular fuzzy model, two criteria are taken into account: coverage and specificity. Here the dominant index is concerned with the coverage of the target data, and this coverage can be affected by a number of different design parameters. These include the number of intervals, the number of clusters in the input space, and the fuzzification coefficient. The selection of these initial values is problem dependent, and finding them is a matter of further optimization.\n\nThe key objective studied here is the coverage criterion expressed as follows:\n                           \n                              (8)\n                              \n                                 \n                                    \n                                       f\n                                    \n                                    \n                                       1\n                                    \n                                 \n                                 =\n                                 \n                                    1\n                                    N\n                                 \n                                 \n                                    \u2211\n                                    \n                                       k\n                                       =\n                                       1\n                                    \n                                    N\n                                 \n                                 (\n                                 \n                                    \n                                       t\n                                    \n                                    \n                                       k\n                                    \n                                 \n                                 \u2208\n                                 \n                                    \n                                       Y\n                                    \n                                    \n                                       k\n                                    \n                                 \n                                 )\n                              \n                           \n                         where the belongingness predicate returns 1 if \n                           \n                              \n                                 t\n                              \n                              \n                                 k\n                              \n                           \n                         belongs to \n                           \n                              \n                                 Y\n                              \n                              \n                                 k\n                              \n                           \n                        . For the specificity criterion, the length of the output intervals is taken into consideration. There is a compelling reason considering it: if the length is broad then the specificity of the information granule is low, and if the length of the interval decreases, the specificity starts to increase. The measure of specificity is computed as the following sum\n                           \n                              (9)\n                              \n                                 \n                                    \n                                       f\n                                    \n                                    \n                                       2\n                                    \n                                 \n                                 =\n                                 \n                                    1\n                                    N\n                                 \n                                 \n                                    \u2211\n                                    \n                                       k\n                                       =\n                                       1\n                                    \n                                    N\n                                 \n                                 \n                                    (\n                                    \n                                       \n                                          y\n                                       \n                                       \n                                          k\n                                       \n                                       \n                                          +\n                                       \n                                    \n                                    \u2212\n                                    \n                                       \n                                          y\n                                       \n                                       \n                                          k\n                                       \n                                       \n                                          \u2212\n                                       \n                                    \n                                    )\n                                 \n                              \n                           \n                        \n                     \n\nThese coverage and specificity measures are in conflict as the number of elements covered by the information granule increases, the length of the interval might increase and cause a decrease in the specificity, thus becoming less detailed. In order to resolve this conflict and to calibrate the impact of the specificity criterion we consider the following form of \n                           \n                              \n                                 f\n                              \n                              \n                                 2\n                              \n                           \n                        :\n                           \n                              (10)\n                              \n                                 \n                                    \n                                       f\n                                    \n                                    \n                                       2\n                                    \n                                 \n                                 =\n                                 \n                                    \n                                       e\n                                    \n                                    \n                                       \u2212\n                                       \u03b1\n                                       (\n                                       l\n                                       /\n                                       L\n                                       )\n                                    \n                                 \n                              \n                           \n                         where \u03b1 is a non-negative parameter, l is the total average length of the output intervals, and L is the total range of the output variable (i.e. \n                           L\n                           =\n                           \n                              \n                                 t\n                              \n                              \n                                 max\n                              \n                           \n                           \u2212\n                           \n                              \n                                 t\n                              \n                              \n                                 min\n                              \n                           \n                        ). With the modification of the second objective, we maximize the performance index as \n                           Q\n                           =\n                           \n                              \n                                 f\n                              \n                              \n                                 1\n                              \n                           \n                           \u00d7\n                           \n                              \n                                 f\n                              \n                              \n                                 2\n                              \n                           \n                        , but in this case we have to take into consideration the value of \u03b1, given that a value close to zero can have little to no impact in the specificity criterion, whereas large values of \u03b1 could have a significant impact in the final coverage. Finding a suitable value of \u03b1 may call for another optimization problem.", "title": "Granular fuzzy models: Analysis, design, and evaluation"}, "S0888613X1500002X": {"highlights": ["We investigate a generalised betting method and isolate its general form of coherence.", "We provide an operational semantics for belief and plausibility functions.", "We investigate generalised uncertainty measures on MV-algebras."], "abstract": "Betting methods, of which de Finetti's Dutch Book is by far the most well-known, are uncertainty modelling devices which accomplish a twofold aim. Whilst providing an (operational) interpretation of the relevant measure of uncertainty, they also provide a formal definition of coherence. The main purpose of this paper is to put forward a betting method for belief functions on MV-algebras of many-valued events which allows us to isolate the corresponding coherence criterion, which we term coherence in the aggregate. Our framework generalises the classical Dutch Book method.\n               \n            \n\nBetting methods, of which de Finetti's Dutch Book is by far the most well-known, are uncertainty modelling devices which accomplish a twofold aim. Whilst providing an (operational) interpretation of the relevant measure of uncertainty, they also provide the formal setting to tell apart admissible from inadmissible quantifications of uncertainty. To emphasise the logical, rather than decision-theoretic, nature of this latter aspect, the term coherence is often used.\n                        1\n                     \n                     \n                        1\n                        De Finetti, who pioneered betting methods of the kind which will be of interest in this paper, used both the notion of \u201ccoherence\u201d and that of \u201cadmissibility\u201d depending on whether he wanted to emphasise the logical or decision-theoretic aspect of his analysis, respectively. Compare, for instance, Chapter 3 of [5] with [6].\n                      The main purpose of this paper is to put forward a betting method for belief functions (on many-valued events) which allows us to isolate the corresponding coherence criterion, which we term coherence in the aggregate. Since our setting builds on (and extends) de Finetti's method, we begin by recalling his own Dutch Book.\n\nConsider two players, Bookmaker (B) and Gambler (G) and a finite set of events of interest \n                     \n                        \n                           \n                              e\n                           \n                           \n                              1\n                           \n                        \n                        ,\n                        \u2026\n                        ,\n                        \n                           \n                              e\n                           \n                           \n                              k\n                           \n                        \n                      that can only be evaluated as either true or false. De Finetti's method is best described as an interactive, sequential choice problem (or game), in which the selection of an action, for each player, reveals the player's degree of belief in the corresponding outcome. At the first stage of the game, Bookmaker publishes a book \u03b2, i.e. a complete assignment of real numbers \n                        \n                           \n                              \u03b2\n                           \n                           \n                              i\n                           \n                        \n                        \u2208\n                        [\n                        0\n                        ,\n                        1\n                        ]\n                      to each event \n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                     . The real number \n                        \n                           \n                              \u03b2\n                           \n                           \n                              i\n                           \n                        \n                      is also referred to as the \u201cbetting odds\u201d for \n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                     . Once the book has been published, Gambler chooses stakes \n                        \n                           \n                              \u03c3\n                           \n                           \n                              1\n                           \n                        \n                        ,\n                        \u2026\n                        ,\n                        \n                           \n                              \u03c3\n                           \n                           \n                              k\n                           \n                        \n                        \u2208\n                        R\n                     , one for each event \n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                     , and pays to B the amount \n                        \n                           \n                              \u2211\n                           \n                           \n                              i\n                              =\n                              1\n                           \n                           \n                              k\n                           \n                        \n                        \n                           \n                              \u03c3\n                           \n                           \n                              i\n                           \n                        \n                        \u22c5\n                        \n                           \n                              \u03b2\n                           \n                           \n                              i\n                           \n                        \n                      in Euros.\n                        2\n                     \n                     \n                        2\n                        One central condition imposed by de Finetti on the game allows Gambler to choose negative stakes, thereby unilaterally imposing a payoff swap to Bookmaker, who is forced to accept it. So if G puts a negative stake \n                              \u2212\n                              \n                                 \n                                    \u03c3\n                                 \n                                 \n                                    i\n                                 \n                              \n                            on event \n                              \n                                 \n                                    e\n                                 \n                                 \n                                    i\n                                 \n                              \n                           , she is entitled to receive \n                              \n                                 \n                                    \u03c3\n                                 \n                                 \n                                    i\n                                 \n                              \n                              \u22c5\n                              \n                                 \n                                    \u03b2\n                                 \n                                 \n                                    i\n                                 \n                              \n                            from B. This, and the remaining contractual conditions which underpin de Finetti's Dutch Book are fully analysed, in the language and notation of this paper, in [12]. There, we also emphasise the importance of the (implicit, in de Finetti's framework) assumption to the effect that, at the time of betting, B and G must be unaware of the truth values of the events involved in the game.\n                      This makes the monies owed by B to G depend on a classical valuation (or possible world) V which decides all the relevant events. That is to say, upon V deciding the events of interest, Bookmaker must pay to Gambler \n                        \n                           \n                              \u2211\n                           \n                           \n                              i\n                              =\n                              1\n                           \n                           \n                              k\n                           \n                        \n                        \n                           \n                              \u03c3\n                           \n                           \n                              i\n                           \n                        \n                        \u22c5\n                        V\n                        (\n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                        )\n                      Euros. Therefore, when all events are decided by some V, the total balance in V for B is given by the expression:\n                        \n                           (1)\n                           \n                              \n                                 \u2211\n                                 \n                                    i\n                                    =\n                                    1\n                                 \n                                 k\n                              \n                              \n                                 \n                                    \u03c3\n                                 \n                                 \n                                    i\n                                 \n                              \n                              \u22c5\n                              \n                                 \n                                    \u03b2\n                                 \n                                 \n                                    i\n                                 \n                              \n                              \u2212\n                              \n                                 \u2211\n                                 \n                                    i\n                                    =\n                                    1\n                                 \n                                 k\n                              \n                              \n                                 \n                                    \u03c3\n                                 \n                                 \n                                    i\n                                 \n                              \n                              \u22c5\n                              V\n                              (\n                              \n                                 \n                                    e\n                                 \n                                 \n                                    i\n                                 \n                              \n                              )\n                              =\n                              \n                                 \u2211\n                                 \n                                    i\n                                    =\n                                    1\n                                 \n                                 k\n                              \n                              \n                                 \n                                    \u03c3\n                                 \n                                 \n                                    i\n                                 \n                              \n                              \u22c5\n                              \n                                 (\n                                 \n                                    \n                                       \u03b2\n                                    \n                                    \n                                       i\n                                    \n                                 \n                                 \u2212\n                                 V\n                                 (\n                                 \n                                    \n                                       e\n                                    \n                                    \n                                       i\n                                    \n                                 \n                                 )\n                                 )\n                              \n                              .\n                           \n                        \n                     \n                  \n\nClearly, if the result of the above expression (1) is positive, Bookmaker made a profit (in Euros) in V, whereas if it is negative, she made a loss in V. Since it is reasonable to assume that no Bookmaker would ever aim at losing money, de Finetti's criterion of coherence arises naturally from this setting. \n                        De Finetti's coherence criterion\n                        If \n                              \n                                 \n                                    e\n                                 \n                                 \n                                    1\n                                 \n                              \n                              ,\n                              \u2026\n                              ,\n                              \n                                 \n                                    e\n                                 \n                                 \n                                    k\n                                 \n                              \n                            are events and \u03b2 is a book on them, then \u03b2 is coherent if and only if it does not lead \n                           B \n                           to a sure loss, that is to say, to a total balance for B which is negative in every possible world V.\n\nDe Finetti's celebrated Dutch Book Theorem states that a book \u03b2 is coherent if and only if \u03b2 coincides with the restriction to \n                        {\n                        \n                           \n                              e\n                           \n                           \n                              1\n                           \n                        \n                        ,\n                        \u2026\n                        ,\n                        \n                           \n                              e\n                           \n                           \n                              k\n                           \n                        \n                        }\n                      of a finitely additive and normalised function P mapping elements of the free Boolean algebra generated by the \n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                     's to \n                        [\n                        0\n                        ,\n                        1\n                        ]\n                     . It is customary to say that P is a probability measure extending \u03b2, or that \u03b2 extends to a (finitely additive) probability measure P.\n\nA central feature of de Finetti's method is that a possible world V decides completely and unambiguously the truth-value of the events of interest, that is to say, events are for de Finetti, modelled by the semantics of the classical propositional calculus.\n                        3\n                     \n                     \n                        3\n                        We refer again to [12] for a more detailed analysis of this important point.\n                      A practical consequence of this assumption is that V provides B and G with sufficient information about the (Boolean) events \n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                     's to compute the value of the total balance in (1). However, it is natural to ask whether de Finetti's method can be extended to characterise coherent belief in those cases in which possible worlds do not determine completely whether events of interest are true or false.\n\nAlong this line, two generalisations have been proposed by Jaffray [19] and Mundici [25], respectively, to extend de Finetti's betting framework in two different ways. Jaffray investigated betting games where the information possessed by the agent at the time of resolving the uncertainty may not determine completely whether the events are true or false. Mundici, on the other hand, investigated betting games where the available information determines the truth value of all the events of interest, but considers a more general semantics than de Finetti's by allowing the events of interest to be evaluated with degrees of truth between 0 and 1.\n\nIndeed, Jaffray's framework builds on the idea that if a given event e (represented by a sentence of the classical propositional calculus) occurs, then every (non-contradictory event) which follows logically from e, also occurs. Jaffray's adaptation of de Finetti's betting method, which he terms a game under partially resolving uncertainty, mirrors rather closely the game recalled above. First B publishes a book \n                        \u03b2\n                        :\n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                        \u21a6\n                        \n                           \n                              \u03b2\n                           \n                           \n                              i\n                           \n                        \n                     . Second G places stakes \n                        \n                           \n                              \u03c3\n                           \n                           \n                              1\n                           \n                        \n                        ,\n                        \u2026\n                        ,\n                        \n                           \n                              \u03c3\n                           \n                           \n                              k\n                           \n                        \n                      on \n                        \n                           \n                              e\n                           \n                           \n                              1\n                           \n                        \n                        ,\n                        \u2026\n                        ,\n                        \n                           \n                              e\n                           \n                           \n                              k\n                           \n                        \n                      at the betting odds written in \u03b2. Finally, G pays B for each \n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                      the amount \n                        \n                           \n                              \u03c3\n                           \n                           \n                              i\n                           \n                        \n                        \u22c5\n                        \n                           \n                              \u03b2\n                           \n                           \n                              i\n                           \n                        \n                      and B gains from G the amount \n                        \n                           \n                              \u03c3\n                           \n                           \n                              i\n                           \n                        \n                        \u22c5\n                        \n                           \n                              C\n                           \n                           \n                              e\n                           \n                        \n                        (\n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                        )\n                     , where \n                        \n                           \n                              C\n                           \n                           \n                              e\n                           \n                        \n                        (\n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                        )\n                        =\n                        1\n                      if \n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                      follows from e (under classical propositional logic, i.e. if \n                        \u22a8\n                        e\n                        \u2192\n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                     ), and \n                        \n                           \n                              C\n                           \n                           \n                              e\n                           \n                        \n                        (\n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                        )\n                        =\n                        0\n                      otherwise. Therefore, the total balance for B is given by\n                        \n                           (2)\n                           \n                              \n                                 \u2211\n                                 \n                                    i\n                                    =\n                                    1\n                                 \n                                 k\n                              \n                              \n                                 \n                                    \u03c3\n                                 \n                                 \n                                    i\n                                 \n                              \n                              \n                                 (\n                                 \n                                    \n                                       \u03b2\n                                    \n                                    \n                                       i\n                                    \n                                 \n                                 \u2212\n                                 \n                                    \n                                       C\n                                    \n                                    \n                                       e\n                                    \n                                 \n                                 (\n                                 \n                                    \n                                       e\n                                    \n                                    \n                                       i\n                                    \n                                 \n                                 )\n                                 )\n                              \n                              .\n                           \n                        \n                     \n                  \n\nJaffray calls a book \u03b2 coherent under partially resolved uncertainty if it does not lead B to incur a sure loss, i.e. if it is not the case that, for every fixed non-contradictory event e, \n                        \n                           \n                              \u2211\n                           \n                           \n                              i\n                              =\n                              1\n                           \n                           \n                              k\n                           \n                        \n                        \n                           \n                              \u03c3\n                           \n                           \n                              i\n                           \n                        \n                        (\n                        \n                           \n                              \u03b2\n                           \n                           \n                              i\n                           \n                        \n                        \u2212\n                        \n                           \n                              C\n                           \n                           \n                              e\n                           \n                        \n                        (\n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                        )\n                        )\n                        <\n                        0\n                     . Finally he shows that this notion of coherence characterises Dempster\u2013Shafer belief functions \n                     [30] (see Section 2.1) essentially in the same way probability measures are characterised by de Finetti's own notion of coherence:\n\n\n                     \n                        Theorem 1.1\n                        \n                           (See \n                           \n                              [19]\n                           \n                           .) A book \u03b2 under partially resolved uncertainty on events of interest \n                           \n                              \n                                 \n                                    e\n                                 \n                                 \n                                    1\n                                 \n                              \n                              ,\n                              \u2026\n                              ,\n                              \n                                 \n                                    e\n                                 \n                                 \n                                    k\n                                 \n                              \n                              \u2208\n                              \n                                 \n                                    2\n                                 \n                                 \n                                    W\n                                 \n                              \n                            \n                           is coherent iff it can be extended to a belief function on the Boolean algebra \n                           \n                              \n                                 \n                                    2\n                                 \n                                 \n                                    W\n                                 \n                              \n                           \n                           .\n                           \n                              4\n                           \n                           \n                              4\n                              Jaffray's original setting is slightly, but immaterially, different from our rendering since he takes Gambler's, rather than Bookmaker's point of view for the calculation of the total balance.\n                           \n                        \n\nOn the other hand, Mundici extends in [25] de Finetti's coherence criterion to formulas of the infinitely-valued \u0141ukasiewicz calculus. In this setting events are represented by formulas which are evaluated by possible worlds into the real unit interval \n                        [\n                        0\n                        ,\n                        1\n                        ]\n                      (as opposed to the two element set \n                        {\n                        0\n                        ,\n                        1\n                        }\n                     ) according to the semantics of \u0141ukasiewicz logic. As in de Finetti's game G chooses stakes and pays B, for each \n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                     , \n                        \n                           \n                              \u03c3\n                           \n                           \n                              i\n                           \n                        \n                        \u22c5\n                        \n                           \n                              \u03b2\n                           \n                           \n                              i\n                           \n                        \n                     , while B receives from G, in the possible world v, \n                        \n                           \n                              \u03c3\n                           \n                           \n                              i\n                           \n                        \n                        \u22c5\n                        v\n                        (\n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                        )\n                     , that is an amount proportional to the truth of \n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                     . Therefore, the total balance for B is given by\n                        \n                           (3)\n                           \n                              \n                                 \u2211\n                                 \n                                    i\n                                    =\n                                    1\n                                 \n                                 k\n                              \n                              \n                                 \n                                    \u03c3\n                                 \n                                 \n                                    i\n                                 \n                              \n                              \n                                 (\n                                 \n                                    \n                                       \u03b2\n                                    \n                                    \n                                       i\n                                    \n                                 \n                                 \u2212\n                                 v\n                                 (\n                                 \n                                    \n                                       e\n                                    \n                                    \n                                       i\n                                    \n                                 \n                                 )\n                                 )\n                              \n                              .\n                           \n                        \n                      The notion of a coherent book is then defined exactly as in de Finetti's betting method: the book \n                        \u03b2\n                        :\n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                        \u21a6\n                        \n                           \n                              \u03b2\n                           \n                           \n                              i\n                           \n                        \n                      is said to be state-coherent if it does not lead B to incur a sure loss, i.e. if it is not the case that for every \u0141ukasiewicz \n                        [\n                        0\n                        ,\n                        1\n                        ]\n                     -truth evaluation v, \n                        \n                           \n                              \u2211\n                           \n                           \n                              i\n                              =\n                              1\n                           \n                           \n                              k\n                           \n                        \n                        \n                           \n                              \u03c3\n                           \n                           \n                              i\n                           \n                        \n                        (\n                        \n                           \n                              \u03b2\n                           \n                           \n                              i\n                           \n                        \n                        \u2212\n                        v\n                        (\n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                        )\n                        )\n                        <\n                        0\n                     . Mundici shows that his notion of state-coherence characterises states (see Section 2.2), i.e. normalised and finitely additive measures on MV-algebras (the algebraic counterpart of \u0141ukasiewicz logic) in the same way de Finetti's coherence characterises finitely additive probabilities:\n\n\n                     \n                        Theorem 1.2\n                        \n                           (See \n                           \n                              [25]\n                           \n                           .) Let \n                           M \n                           be an MV-algebra, and let \n                           \n                              {\n                              \n                                 \n                                    e\n                                 \n                                 \n                                    1\n                                 \n                              \n                              ,\n                              \u2026\n                              ,\n                              \n                                 \n                                    e\n                                 \n                                 \n                                    k\n                                 \n                              \n                              }\n                              \u2286\n                              M\n                           \n                           . A book \n                           \n                              \u03b2\n                              :\n                              \n                                 \n                                    e\n                                 \n                                 \n                                    i\n                                 \n                              \n                              \u21a6\n                              \n                                 \n                                    \u03b2\n                                 \n                                 \n                                    i\n                                 \n                              \n                            \n                           is state-coherent iff \u03b2 extends to a state on \n                           M\n                           .\n                        \n\nThus states on MV-algebras can be seen to arise as a coherent quantification of uncertainty from a suitable extension of de Finetti's betting method in a many-valued framework.\n\nGiven these antecedents, the aim of this paper is to put forward an extension of de Finetti's criterion and operational interpretation of uncertainty on many-valued events. As a consequence, this paper explores methods for an operational quantification of the uncertainty of many-valued events whose evaluation is obtained aggregating (possibly inconsistent) observations provided by more or less reliable agents. The following fictitious example illustrates a decision-making problem in which such a generalised uncertainty quantification may arise in practice.\n\n\n                     \n                        Example 1.3\n                        The Global Health Agency (Agency, for short) is faced with the problem of choosing life-saving drugs against k diseases, \n                              \n                                 \n                                    D\n                                 \n                                 \n                                    1\n                                 \n                              \n                              ,\n                              \u2026\n                              ,\n                              \n                                 \n                                    D\n                                 \n                                 \n                                    k\n                                 \n                              \n                           , which can turn into potential epidemics. On top of the uncertainty related to whether a certain epidemic will occur, Agency will be interested in the extent to which \n                              \n                                 \n                                    D\n                                 \n                                 \n                                    i\n                                 \n                              \n                            will spread across the globe. So, the events that Agency is facing are best seen as \n                              \n                                 \n                                    e\n                                 \n                                 \n                                    i\n                                 \n                              \n                           : \u201cthe outbreak of \n                              \n                                 \n                                    D\n                                 \n                                 \n                                    i\n                                 \n                              \n                            will be aggressive\u201d. This can be captured by allowing each event \n                              \n                                 \n                                    e\n                                 \n                                 \n                                    i\n                                 \n                              \n                            be evaluated in the real unit interval \n                              [\n                              0\n                              ,\n                              1\n                              ]\n                           , rather than, as usually done, in the binary set with values 0 (i.e. not aggressive) and 1 (i.e. aggressive).\n\nAs for the evaluation of each event, the Agency is supposed to ask data about the actual pandemics to the individual national health organisations, say \n                              \n                                 \n                                    a\n                                 \n                                 \n                                    1\n                                 \n                              \n                              ,\n                              \u2026\n                              ,\n                              \n                                 \n                                    a\n                                 \n                                 \n                                    m\n                                 \n                              \n                           . These will provide \n                              [\n                              0\n                              ,\n                              1\n                              ]\n                           -valued assessments \n                              \n                                 \n                                    a\n                                 \n                                 \n                                    1\n                                 \n                              \n                              (\n                              \n                                 \n                                    e\n                                 \n                                 \n                                    i\n                                 \n                              \n                              )\n                              ,\n                              \u2026\n                              ,\n                              \n                                 \n                                    a\n                                 \n                                 \n                                    m\n                                 \n                              \n                              (\n                              \n                                 \n                                    e\n                                 \n                                 \n                                    i\n                                 \n                              \n                              )\n                            of how aggressive is each disease \n                              \n                                 \n                                    D\n                                 \n                                 \n                                    i\n                                 \n                              \n                            in its country. Agency, in order to determine the evaluation for each event, and hence to determine the extent to which disease \n                              \n                                 \n                                    D\n                                 \n                                 \n                                    i\n                                 \n                              \n                            turned out to be aggressive, needs to aggregate these data according to some aggregation method agg. The aggregation methods considered in this paper will be based on determining a reliability map \u03b7 which assigns to each national health organisation \n                              \n                                 \n                                    a\n                                 \n                                 \n                                    i\n                                 \n                              \n                            a reliability degree \n                              \u03b7\n                              (\n                              \n                                 \n                                    a\n                                 \n                                 \n                                    i\n                                 \n                              \n                              )\n                           . The idea behind this is that some countries might announce the outbreak of \n                              \n                                 \n                                    D\n                                 \n                                 \n                                    i\n                                 \n                              \n                            but could do so on the basis of very poor information, for instance because of inadequate sampling of the population. Other countries might do very accurate statistical sampling instead, thereby producing a completely reliable report. To cope with this we assume that Agency can determine the true reliability of the data produced by each country by running say a (completely reliable) statistical analysis on the sampling methods used by the national agencies.\n\nBy considering different aggregation methods, we provide an operational semantics for a wide class of uncertainty measures including belief functions on MV-algebras, plausibility functions on MV-algebras, but also belief functions on Boolean algebras and classical probability measures.\n\nThe remainder of the paper is organised as follows: In Section 2 we shall briefly recall the preliminary notions needed for the paper, namely belief functions on Boolean algebras, states of MV-algebras and belief functions on MV-algebras. Section 3 will be devoted to presenting our generalised betting framework. In the same section we shall characterise uncertainty measures on many-valued events by exploring the possible ways in which the aggregation map can be chosen. Refinements of the set of available reliability maps will be investigated in Section 4 where we show how particular classes of belief functions on MV-algebras can be described. In Section 5 we shall discuss on conclusions and future work.\n\nThe paper includes two appendices: Appendix A provides the necessary notions and results about \u0141ukasiewicz logic and MV-algebras. Appendix B collects the proofs of some technical results which, in the interest of readability, we refrained from including in the main body of the paper.\n\nWe briefly recall in this section the main definitions of Dempster\u2013Shafer belief functions [30] needed in the rest of the paper. Consider a finite set W of mutually exclusive (and exhaustive) propositions of interest, and whose powerset \n                           \n                              \n                                 2\n                              \n                              \n                                 W\n                              \n                           \n                         represents all such propositions. We can think of W as a frame of discernment, with elements \n                           w\n                           \u2208\n                           W\n                         representing the lowest level of discernible information that can be dealt with.\n\nA map \n                           m\n                           :\n                           \n                              \n                                 2\n                              \n                              \n                                 W\n                              \n                           \n                           \u2192\n                           [\n                           0\n                           ,\n                           1\n                           ]\n                         is said to be a basic belief assignment, or a mass assignment whenever\n                           \n                              \n                                 m\n                                 (\n                                 \u2205\n                                 )\n                                 =\n                                 0\n                                 \n                                 and\n                                 \n                                 \n                                    \u2211\n                                    \n                                       A\n                                       \u2208\n                                       \n                                          \n                                             2\n                                          \n                                          \n                                             W\n                                          \n                                       \n                                    \n                                 \n                                 m\n                                 (\n                                 A\n                                 )\n                                 =\n                                 1\n                                 .\n                              \n                           \n                         Given such a mass assignment m on \n                           \n                              \n                                 2\n                              \n                              \n                                 W\n                              \n                           \n                        , for every \n                           A\n                           \u2208\n                           \n                              \n                                 2\n                              \n                              \n                                 W\n                              \n                           \n                        , the belief of A is defined as\n                           \n                              (4)\n                              \n                                 \n                                    \n                                       Bel\n                                    \n                                    \n                                       m\n                                    \n                                 \n                                 (\n                                 A\n                                 )\n                                 =\n                                 \n                                    \u2211\n                                    \n                                       B\n                                       \u2286\n                                       A\n                                    \n                                 \n                                 m\n                                 (\n                                 B\n                                 )\n                                 .\n                              \n                           \n                         Notice that each mass assignment m on \n                           \n                              \n                                 2\n                              \n                              \n                                 W\n                              \n                           \n                         is in fact a probability distribution on \n                           \n                              \n                                 2\n                              \n                              \n                                 W\n                              \n                           \n                         that naturally induces a probability measure \n                           \n                              \n                                 P\n                              \n                              \n                                 m\n                              \n                           \n                         on \n                           \n                              \n                                 2\n                              \n                              \n                                 \n                                    \n                                       2\n                                    \n                                    \n                                       W\n                                    \n                                 \n                              \n                           \n                        . Consequently, the belief function \n                           \n                              \n                                 Bel\n                              \n                              \n                                 m\n                              \n                           \n                         defined from m can be equivalently described as follows: for every \n                           A\n                           \u2208\n                           \n                              \n                                 2\n                              \n                              \n                                 W\n                              \n                           \n                        ,\n                           \n                              (5)\n                              \n                                 \n                                    \n                                       Bel\n                                    \n                                    \n                                       m\n                                    \n                                 \n                                 (\n                                 A\n                                 )\n                                 =\n                                 \n                                    \n                                       P\n                                    \n                                    \n                                       m\n                                    \n                                 \n                                 \n                                    (\n                                    \n                                       {\n                                       B\n                                       \u2208\n                                       \n                                          \n                                             2\n                                          \n                                          \n                                             W\n                                          \n                                       \n                                       :\n                                       B\n                                       \u2286\n                                       A\n                                       }\n                                    \n                                    )\n                                 \n                                 .\n                              \n                           \n                         Therefore, identifying the set \n                           {\n                           B\n                           \u2208\n                           \n                              \n                                 2\n                              \n                              \n                                 W\n                              \n                           \n                           :\n                           B\n                           \u2286\n                           A\n                           }\n                         with its characteristic function defined by\n                           \n                              (6)\n                              \n                                 \n                                    \n                                       \u03b9\n                                    \n                                    \n                                       A\n                                    \n                                 \n                                 :\n                                 B\n                                 \u2208\n                                 \n                                    \n                                       2\n                                    \n                                    \n                                       W\n                                    \n                                 \n                                 \u21a6\n                                 \n                                    {\n                                    \n                                       \n                                          \n                                             1\n                                          \n                                          \n                                             if \n                                             B\n                                             \u2286\n                                             A\n                                          \n                                       \n                                       \n                                          \n                                             0\n                                          \n                                          \n                                             otherwise,\n                                          \n                                       \n                                    \n                                 \n                              \n                           \n                         it is easy to see that, for every \n                           A\n                           \u2208\n                           \n                              \n                                 2\n                              \n                              \n                                 W\n                              \n                           \n                        , and for every mass assignment \n                           m\n                           :\n                           \n                              \n                                 2\n                              \n                              \n                                 W\n                              \n                           \n                           \u2192\n                           [\n                           0\n                           ,\n                           1\n                           ]\n                        , we have\n                           \n                              (7)\n                              \n                                 \n                                    \n                                       Bel\n                                    \n                                    \n                                       m\n                                    \n                                 \n                                 (\n                                 A\n                                 )\n                                 =\n                                 \n                                    \n                                       P\n                                    \n                                    \n                                       m\n                                    \n                                 \n                                 (\n                                 \n                                    \n                                       \u03b9\n                                    \n                                    \n                                       A\n                                    \n                                 \n                                 )\n                                 .\n                              \n                           \n                         This characterisation will be useful when discussing the extensions of belief functions on MV-algebras. Similarly useful to understand our generalised betting method is the rather obvious observation to the effect that for every \n                           A\n                           \u2208\n                           \n                              \n                                 2\n                              \n                              \n                                 W\n                              \n                           \n                        , \n                           \n                              \n                                 \u03b9\n                              \n                              \n                                 A\n                              \n                           \n                         can be regarded as a map evaluating the (strict) inclusion of B into A, for every subset B of W.\n\nFinally, recall that a subset A of W such that \n                           m\n                           (\n                           A\n                           )\n                           >\n                           0\n                         is said to be a focal element. Every belief function is characterised by the value that m takes over its focal elements, and therefore, the focal elements of a belief function \n                           \n                              \n                                 Bel\n                              \n                              \n                                 m\n                              \n                           \n                         carry all the relevant information about \n                           \n                              \n                                 Bel\n                              \n                              \n                                 m\n                              \n                           \n                        .\n\nStates of MV-algebras were introduced by Mundici in [24] as averaging processes for the infinitely-valued \u0141ukasiewicz logic. A state of an MV-algebra\n                        \n                           5\n                        \n                        \n                           5\n                           See Appendix A for details on MV-algebras.\n                         \n                        \n                           M\n                           =\n                           (\n                           M\n                           ,\n                           \u2295\n                           ,\n                           \u00ac\n                           ,\n                           \n                              \n                                 0\n                              \n                              \n                                 M\n                              \n                           \n                           )\n                         is a map \n                           s\n                           :\n                           M\n                           \u2192\n                           [\n                           0\n                           ,\n                           1\n                           ]\n                         satisfying the following:\n                           \n                              (i)\n                              \n                                 \n                                    s\n                                    (\n                                    \n                                       \n                                          1\n                                       \n                                       \n                                          M\n                                       \n                                    \n                                    )\n                                    =\n                                    1\n                                 ,\n\n\n                                 \n                                    s\n                                    (\n                                    x\n                                    \u2295\n                                    y\n                                    )\n                                    =\n                                    s\n                                    (\n                                    x\n                                    )\n                                    +\n                                    s\n                                    (\n                                    y\n                                    )\n                                 , for every \n                                    x\n                                    ,\n                                    y\n                                    \u2208\n                                    M\n                                  such that \n                                    x\n                                    \u2299\n                                    y\n                                    =\n                                    \n                                       \n                                          0\n                                       \n                                       \n                                          M\n                                       \n                                    \n                                 ,\n\nStates play the same role on MV-algebra as probability measures do on Boolean algebras. Indeed, the two properties (i) and (ii) characterise each state of M as a \n                           [\n                           0\n                           ,\n                           1\n                           ]\n                        -valued map that is normalised (i) and additive (ii) with respect to MV-algebraic operations. Moreover, it is easy to see that, for every MV-algebra M and for every \n                           s\n                           \u2208\n                           S\n                           (\n                           M\n                           )\n                        , the restriction of s to the Boolean skeleton of M (the largest Boolean algebra contained in M) is a finitely additive probability measure.\n\nThe following theorem independently proved by Kroupa [20, Theorem 28] and Panti [28, Proposition 1.1], provides an integral representation of states by Borel probability measures defined on the \u03c3-algebra \n                           B\n                           (\n                           \n                              Max\n                           \n                           (\n                           M\n                           )\n                           )\n                         of Borel subsets of \n                           \n                              Max\n                           \n                           (\n                           M\n                           )\n                        , where \n                           \n                              Max\n                           \n                           (\n                           M\n                           )\n                         is the maximal spectral space of M (see Appendix A for further details on \n                           \n                              Max\n                           \n                           (\n                           M\n                           )\n                        ).\n                           7\n                        \n                        \n                           7\n                           While Kroupa proved Theorem 2.1 in the case of semisimple MV-algebras, Panti showed that the hypothesis on the semisimplicity of the MV-algebra can be relaxed, since, for every MV-algebra M, there is a canonical bijection between the class \n                                 S\n                                 (\n                                 M\n                                 )\n                               of all the states on M, and the class \n                                 S\n                                 (\n                                 M\n                                 /\n                                 \n                                    Rad\n                                 \n                                 (\n                                 M\n                                 )\n                                 )\n                               of all the states on its most general semisimple quotient \n                                 M\n                                 /\n                                 \n                                    Rad\n                                 \n                                 (\n                                 M\n                                 )\n                              .\n                        \n                     \n\n\n                        \n                           Theorem 2.1\n                           \n                              For every MV-algebra M, there is a one-to-one correspondence between the class \n                              \n                                 S\n                                 (\n                                 M\n                                 )\n                               \n                              of states on M, and the regular Borel probability measures on \n                              \n                                 B\n                                 (\n                                 \n                                    Max\n                                 \n                                 (\n                                 M\n                                 )\n                                 )\n                              \n                              . In particular, for every state s of M, there exists a unique regular Borel probability measure \u03bc on \n                              \n                                 B\n                                 (\n                                 \n                                    Max\n                                 \n                                 (\n                                 M\n                                 )\n                                 )\n                               \n                              such that for every \n                              \n                                 a\n                                 \u2208\n                                 M\n                              \n                              ,\n                              \n                                 \n                                    (8)\n                                    \n                                       s\n                                       (\n                                       a\n                                       )\n                                       =\n                                       \n                                          \u222b\n                                          \n                                             \n                                                Max\n                                             \n                                             (\n                                             M\n                                             )\n                                          \n                                       \n                                       a\n                                       \n                                       d\n                                       \u03bc\n                                       .\n                                    \n                                 \n                              \n                           \n\nIt is worth noticing that, for MV-algebras of the form \n                                 \n                                    \n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                    \n                                    \n                                       Y\n                                    \n                                 \n                               (Y can either be finite or infinite), their maximal spectral space \n                                 \n                                    Max\n                                 \n                                 (\n                                 \n                                    \n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                    \n                                    \n                                       Y\n                                    \n                                 \n                                 )\n                               coincides, up to bijections, with Y. As a matter of fact, for every \n                                 y\n                                 \u2208\n                                 Y\n                              , the subset \n                                 \n                                    \n                                       m\n                                    \n                                    \n                                       y\n                                    \n                                 \n                               of \n                                 \n                                    \n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                    \n                                    \n                                       Y\n                                    \n                                 \n                               consisting on those functions \n                                 f\n                                 :\n                                 Y\n                                 \u2192\n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                               such that \n                                 f\n                                 (\n                                 y\n                                 )\n                                 =\n                                 1\n                               is a maximal filter of \n                                 \n                                    \n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                    \n                                    \n                                       Y\n                                    \n                                 \n                              . Furthermore, the map \n                                 y\n                                 \u2208\n                                 Y\n                                 \u21a6\n                                 \n                                    \n                                       m\n                                    \n                                    \n                                       y\n                                    \n                                 \n                                 \u2208\n                                 \n                                    Max\n                                 \n                                 (\n                                 \n                                    \n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                    \n                                    \n                                       Y\n                                    \n                                 \n                                 )\n                               is a bijection. In the remainder of this paper, we shall often use this remark.\n\nWhen M is an MV-algebra of functions of the kind \n                           \n                              \n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                              \n                              \n                                 Y\n                              \n                           \n                        , where Y is countable set, the above representation theorem boils down to claiming that for any state s on M there exists a probability distribution \n                           p\n                           :\n                           Y\n                           \u2192\n                           [\n                           0\n                           ,\n                           1\n                           ]\n                         such that, for any \n                           f\n                           \u2208\n                           \n                              \n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                              \n                              \n                                 Y\n                              \n                           \n                        ,\n                           \n                              \n                                 s\n                                 (\n                                 f\n                                 )\n                                 =\n                                 \n                                    \u2211\n                                    \n                                       y\n                                       \u2208\n                                       Y\n                                    \n                                 \n                                 f\n                                 (\n                                 y\n                                 )\n                                 \u22c5\n                                 p\n                                 (\n                                 y\n                                 )\n                                 .\n                              \n                           \n                         In other words, states of MV-algebras of \n                           [\n                           0\n                           ,\n                           1\n                           ]\n                        -valued functions are nothing else but Zadeh's probabilities of fuzzy events [35].\n\nAs we recalled in Section 1, generalising a previous result by Paris [29], Mundici [25] shows that states of MV-algebras can be seen to arise as a coherent quantification of uncertainty from a suitable extension of de Finetti's betting method. We now recall the theorem in more detail, as it will be useful in what follows.\n\n\n                        \n                           Theorem 2.3\n                           \n                              (See \n                              \n                                 [25]\n                              \n                              .) Let M be an MV-algebra, let \n                              \n                                 {\n                                 \n                                    \n                                       e\n                                    \n                                    \n                                       1\n                                    \n                                 \n                                 ,\n                                 \u2026\n                                 ,\n                                 \n                                    \n                                       e\n                                    \n                                    \n                                       k\n                                    \n                                 \n                                 }\n                                 \u2286\n                                 M\n                              \n                              , and let \n                              \n                                 \u03b2\n                                 :\n                                 \n                                    \n                                       e\n                                    \n                                    \n                                       i\n                                    \n                                 \n                                 \u21a6\n                                 \n                                    \n                                       \u03b2\n                                    \n                                    \n                                       i\n                                    \n                                 \n                               \n                              be a book. Then the following are equivalent:\n                              \n                                 \n                                    (1)\n                                    \n                                       \u03b2 is state-coherent,\n                                    \n\n\n                                       \u03b2 extends to a state of M.\n                                    \n\nIn the literature several attempts to extend belief functions on many-valued (i.e. fuzzy) events can be found. The first extensions of Dempster\u2013Shafer theory to the general framework of fuzzy set theory were proposed by Zadeh in the context of information granularity and possibility theory [34] in the form of an expected conditional necessity, and by Smets who proposed in [31] to extend a classical belief function Bel on \n                           \n                              \n                                 2\n                              \n                              \n                                 X\n                              \n                           \n                         to fuzzy subsets A of X as the lower expectation of the characteristic function of A with respect to the class of probability measures lower bounded by Bel. After Zadeh and Smets, several further generalisations were proposed, depending on the way a measure of inclusion among fuzzy sets is used to define the belief functions of fuzzy events based on fuzzy evidence. Indeed, given a mass assignment m for the bodies of evidence \n                           {\n                           \n                              \n                                 A\n                              \n                              \n                                 1\n                              \n                           \n                           ,\n                           \n                              \n                                 A\n                              \n                              \n                                 2\n                              \n                           \n                           ,\n                           \u2026\n                           }\n                        , and a measure \n                           I\n                           (\n                           A\n                           \u2286\n                           B\n                           )\n                         of inclusion among fuzzy sets, the belief of a fuzzy set B can be defined in general by the value: \n                           \n                              Bel\n                           \n                           (\n                           B\n                           )\n                           =\n                           \n                              \n                                 \u2211\n                              \n                              \n                                 i\n                              \n                           \n                           I\n                           (\n                           \n                              \n                                 A\n                              \n                              \n                                 i\n                              \n                           \n                           \u2286\n                           B\n                           )\n                           \u22c5\n                           m\n                           (\n                           \n                              \n                                 A\n                              \n                              \n                                 i\n                              \n                           \n                           )\n                        . We refer the reader to [7,18,32,33] for exhaustive surveys, and to [1] for another approach through fuzzy subsethood.\n\nThe set \n                           \n                              \n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                              \n                              \n                                 W\n                              \n                           \n                         of fuzzy subsets of a set W (mappings from W into \n                           [\n                           0\n                           ,\n                           1\n                           ]\n                        ) can be endowed with an MV-algebra structure by the pointwise extension of the MV-algebra operations in the standard MV-algebra \n                           \n                              \n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                              \n                              \n                                 M\n                                 V\n                              \n                           \n                         (see (2) and (4) in Example 5.1 in Appendix A). Belief functions were firstly generalised to this MV-algebraic setting by Kroupa [21,22] in the following way.\n\nAssume W be finite, and for each element a in the MV-algebra \n                           \n                              \n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                              \n                              \n                                 W\n                              \n                           \n                        , let the map \n                           \n                              \n                                 \n                                    \n                                       \u03c1\n                                    \n                                    \n                                       \u02c6\n                                    \n                                 \n                              \n                              \n                                 a\n                              \n                           \n                           :\n                           \n                              \n                                 2\n                              \n                              \n                                 W\n                              \n                           \n                           \u2192\n                           [\n                           0\n                           ,\n                           1\n                           ]\n                         be defined by the following stipulation: for all \n                           B\n                           \u2208\n                           \n                              \n                                 2\n                              \n                              \n                                 W\n                              \n                           \n                        ,\n                           \n                              (9)\n                              \n                                 \n                                    \n                                       \n                                          \n                                             \u03c1\n                                          \n                                          \n                                             \u02c6\n                                          \n                                       \n                                    \n                                    \n                                       a\n                                    \n                                 \n                                 (\n                                 B\n                                 )\n                                 =\n                                 \n                                    {\n                                    \n                                       \n                                          \n                                             \n                                                \n                                                   min\n                                                \n                                                \n                                                   w\n                                                   \u2208\n                                                   B\n                                                \n                                             \n                                             \u2061\n                                             a\n                                             (\n                                             w\n                                             )\n                                          \n                                          \n                                             if \n                                             B\n                                             \u2260\n                                             \u2205\n                                             ,\n                                          \n                                       \n                                       \n                                          \n                                             1\n                                          \n                                          \n                                             if \n                                             B\n                                             =\n                                             \u2205\n                                             .\n                                          \n                                       \n                                    \n                                 \n                              \n                           \n                        \n                     \n\nIt is clear that \n                           \n                              \n                                 \n                                    \n                                       \u03c1\n                                    \n                                    \n                                       \u02c6\n                                    \n                                 \n                              \n                              \n                                 a\n                              \n                           \n                         generalises the map \n                           \n                              \n                                 \u03b9\n                              \n                              \n                                 A\n                              \n                           \n                         we discussed in Section 2.1 in the following sense: whenever \n                           A\n                           \u2208\n                           \n                              \n                                 2\n                              \n                              \n                                 W\n                              \n                           \n                        , then \n                           \n                              \n                                 \n                                    \n                                       \u03c1\n                                    \n                                    \n                                       \u02c6\n                                    \n                                 \n                              \n                              \n                                 A\n                              \n                           \n                           =\n                           \n                              \n                                 \u03b9\n                              \n                              \n                                 A\n                              \n                           \n                        . Indeed, for every \n                           A\n                           \u2208\n                           \n                              \n                                 2\n                              \n                              \n                                 W\n                              \n                           \n                        , \n                           \n                              \n                                 \n                                    \n                                       \u03c1\n                                    \n                                    \n                                       \u02c6\n                                    \n                                 \n                              \n                              \n                                 A\n                              \n                           \n                           (\n                           B\n                           )\n                           =\n                           1\n                         if \n                           B\n                           \u2286\n                           A\n                        , and \n                           \n                              \n                                 \n                                    \n                                       \u03c1\n                                    \n                                    \n                                       \u02c6\n                                    \n                                 \n                              \n                              \n                                 A\n                              \n                           \n                           (\n                           B\n                           )\n                           =\n                           0\n                        , otherwise. Against this background Kroupa proposes to define belief functions on \n                           \n                              \n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                              \n                              \n                                 W\n                              \n                           \n                         by replacing in (7) the maps \n                           \n                              \n                                 \u03b9\n                              \n                              \n                                 A\n                              \n                           \n                         by the maps \n                           \n                              \n                                 \n                                    \n                                       \u03c1\n                                    \n                                    \n                                       \u02c6\n                                    \n                                 \n                              \n                              \n                                 a\n                              \n                           \n                         and the probabilities over \n                           \n                              \n                                 2\n                              \n                              \n                                 \n                                    \n                                       2\n                                    \n                                    \n                                       W\n                                    \n                                 \n                              \n                           \n                         by states on \n                           \n                              \n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                              \n                              \n                                 (\n                                 \n                                    \n                                       2\n                                    \n                                    \n                                       W\n                                    \n                                 \n                                 )\n                              \n                           \n                        .\n\n\n                        \n                           Definition 2.4\n                           Crisp focal belief function\n\n\n                           Let W be a finite nonempty set. Then a map \n                                 \n                                    \n                                       Bel\n                                    \n                                    \n                                       \u02c6\n                                    \n                                 \n                                 :\n                                 \n                                    \n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                    \n                                    \n                                       W\n                                    \n                                 \n                                 \u2192\n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                               is a crisp-focal belief function, if there exists a state \n                                 s\n                                 :\n                                 \n                                    \n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                    \n                                    \n                                       (\n                                       \n                                          \n                                             2\n                                          \n                                          \n                                             W\n                                          \n                                       \n                                       )\n                                    \n                                 \n                                 \u2192\n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                               such that, for all \n                                 a\n                                 \u2208\n                                 \n                                    \n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                    \n                                    \n                                       W\n                                    \n                                 \n                              \n                              \n                                 \n                                    \n                                       \n                                          \n                                             Bel\n                                          \n                                          \n                                             \u02c6\n                                          \n                                       \n                                       (\n                                       a\n                                       )\n                                       =\n                                       s\n                                       (\n                                       \n                                          \n                                             \n                                                \n                                                   \u03c1\n                                                \n                                                \n                                                   \u02c6\n                                                \n                                             \n                                          \n                                          \n                                             a\n                                          \n                                       \n                                       )\n                                       .\n                                    \n                                 \n                              \n                           \n\nWe call the maps \n                           \n                              \n                                 Bel\n                              \n                              \n                                 \u02c6\n                              \n                           \n                         \n                        crisp-focal belief functions since the focal elements are (crisp) subsets of \n                           \n                              \n                                 2\n                              \n                              \n                                 W\n                              \n                           \n                        . Indeed we have \n                           s\n                           (\n                           \n                              \n                                 \n                                    \n                                       \u03c1\n                                    \n                                    \n                                       \u02c6\n                                    \n                                 \n                              \n                              \n                                 a\n                              \n                           \n                           )\n                           =\n                           \n                              \n                                 \u2211\n                              \n                              \n                                 B\n                                 \u2208\n                                 \n                                    \n                                       2\n                                    \n                                    \n                                       W\n                                    \n                                 \n                              \n                           \n                           \n                              \n                                 \n                                    \n                                       \u03c1\n                                    \n                                    \n                                       \u02c6\n                                    \n                                 \n                              \n                              \n                                 a\n                              \n                           \n                           (\n                           B\n                           )\n                           \u22c5\n                           \u03bc\n                           (\n                           B\n                           )\n                        , where \n                           \u03bc\n                           :\n                           \n                              \n                                 2\n                              \n                              \n                                 W\n                              \n                           \n                           \u2192\n                           [\n                           0\n                           ,\n                           1\n                           ]\n                         is the probability distribution on \n                           \n                              \n                                 2\n                              \n                              \n                                 W\n                              \n                           \n                         defined as \n                           \u03bc\n                           (\n                           B\n                           )\n                           =\n                           s\n                           (\n                           {\n                           B\n                           }\n                           )\n                        , identifying \n                           {\n                           B\n                           }\n                         with its characteristic function on \n                           \n                              \n                                 2\n                              \n                              \n                                 W\n                              \n                           \n                        . Therefore it is clear, by construction, that those elements from \n                           \n                              \n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                              \n                              \n                                 W\n                              \n                           \n                         with a positive probability can only be crisp subsets of W.\n\nKroupa's approach has been further generalised in [16,17] as follows.\n                           8\n                        \n                        \n                           8\n                           We invite the interested reader to consult [14] for further details.\n                         For every finite set W, and for every element a of the MV-algebra \n                           \n                              \n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                              \n                              \n                                 W\n                              \n                           \n                        , first define the map\n                           \n                              \n                                 \n                                    \n                                       \u03c1\n                                    \n                                    \n                                       a\n                                    \n                                 \n                                 :\n                                 b\n                                 \u2208\n                                 \n                                    \n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                    \n                                    \n                                       W\n                                    \n                                 \n                                 \u21a6\n                                 min\n                                 \u2061\n                                 \n                                    {\n                                    b\n                                    (\n                                    w\n                                    )\n                                    \u21d2\n                                    a\n                                    (\n                                    w\n                                    )\n                                    |\n                                    w\n                                    \u2208\n                                    W\n                                    }\n                                 \n                                 .\n                                 \n                                    \n                                       9\n                                    \n                                 \n                              \n                           \n                         The map \n                           \n                              \n                                 \u03c1\n                              \n                              \n                                 a\n                              \n                           \n                         generalises both the map \n                           \n                              \n                                 \u03b9\n                              \n                              \n                                 A\n                              \n                           \n                         introduced in (6) and the map \n                           \n                              \n                                 \n                                    \n                                       \u03c1\n                                    \n                                    \n                                       \u02c6\n                                    \n                                 \n                              \n                              \n                                 a\n                              \n                           \n                         defined in (9). Indeed it is clear that the restriction of \n                           \n                              \n                                 \u03c1\n                              \n                              \n                                 a\n                              \n                           \n                         to \n                           \n                              \n                                 2\n                              \n                              \n                                 W\n                              \n                           \n                         coincides with \n                           \n                              \n                                 \n                                    \n                                       \u03c1\n                                    \n                                    \n                                       \u02c6\n                                    \n                                 \n                              \n                              \n                                 a\n                              \n                           \n                        , and for every crisp subset A of W, the restriction of \n                           \n                              \n                                 \u03c1\n                              \n                              \n                                 A\n                              \n                           \n                         to \n                           \n                              \n                                 2\n                              \n                              \n                                 W\n                              \n                           \n                         coincides with \n                           \n                              \n                                 \u03b9\n                              \n                              \n                                 A\n                              \n                           \n                        . Moreover, for every fixed \n                           b\n                           \u2208\n                           \n                              \n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                              \n                              \n                                 W\n                              \n                           \n                         the map \n                           \n                              \n                                 N\n                              \n                              \n                                 b\n                              \n                           \n                           :\n                           \n                              \n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                              \n                              \n                                 W\n                              \n                           \n                           \u2192\n                           [\n                           0\n                           ,\n                           1\n                           ]\n                         defined by\n                           \n                              (10)\n                              \n                                 \n                                    \n                                       N\n                                    \n                                    \n                                       b\n                                    \n                                 \n                                 :\n                                 a\n                                 \u2208\n                                 \n                                    \n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                    \n                                    \n                                       W\n                                    \n                                 \n                                 \u21a6\n                                 \n                                    \n                                       \u03c1\n                                    \n                                    \n                                       a\n                                    \n                                 \n                                 (\n                                 b\n                                 )\n                                 \u2208\n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                                 ,\n                              \n                           \n                         is a homogeneous necessity measure induced by the mapping b,\n                           9\n                           Recall that \n                                 u\n                                 \u21d2\n                                 v\n                                 =\n                                 min\n                                 \u2061\n                                 (\n                                 1\n                                 ,\n                                 1\n                                 \u2212\n                                 u\n                                 +\n                                 v\n                                 )\n                              , for each \n                                 u\n                                 ,\n                                 v\n                                 \u2208\n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                              .\n                        \n                        \n                           10\n                        \n                        \n                           10\n                           This means that the following properties hold: i) \n                                 \n                                    \n                                       N\n                                    \n                                    \n                                       b\n                                    \n                                 \n                                 (\n                                 a\n                                 \u2227\n                                 \n                                    \n                                       a\n                                    \n                                    \n                                       \u2032\n                                    \n                                 \n                                 )\n                                 =\n                                 min\n                                 \u2061\n                                 {\n                                 \n                                    \n                                       N\n                                    \n                                    \n                                       b\n                                    \n                                 \n                                 (\n                                 a\n                                 )\n                                 ,\n                                 \n                                    \n                                       N\n                                    \n                                    \n                                       b\n                                    \n                                 \n                                 (\n                                 \n                                    \n                                       a\n                                    \n                                    \n                                       \u2032\n                                    \n                                 \n                                 )\n                                 }\n                               and \n                                 \n                                    \n                                       N\n                                    \n                                    \n                                       b\n                                    \n                                 \n                                 (\n                                 \n                                    r\n                                    \u00af\n                                 \n                                 \u2295\n                                 a\n                                 )\n                                 =\n                                 r\n                                 \u2295\n                                 \n                                    \n                                       N\n                                    \n                                    \n                                       b\n                                    \n                                 \n                                 (\n                                 a\n                                 )\n                               for every \n                                 r\n                                 \u2208\n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                              . Here \n                                 u\n                                 \u2295\n                                 v\n                                 =\n                                 min\n                                 \u2061\n                                 (\n                                 1\n                                 ,\n                                 u\n                                 +\n                                 v\n                                 )\n                               and \n                                 \n                                    r\n                                    \u00af\n                                 \n                               denotes the constant function of value r.\n                         understood as a possibility distribution (see e.g. [15]). Moreover, \n                           \n                              \n                                 N\n                              \n                              \n                                 b\n                              \n                           \n                         is normalised (i.e. \n                           \n                              \n                                 N\n                              \n                              \n                                 b\n                              \n                           \n                           (\n                           \n                              0\n                              \u00af\n                           \n                           )\n                           =\n                           0\n                        ) if and only if so is b (i.e. \n                           \n                              \n                                 max\n                              \n                              \n                                 w\n                                 \u2208\n                                 W\n                              \n                           \n                           \u2061\n                           b\n                           (\n                           w\n                           )\n                           =\n                           1\n                        ). An easy adaptation of [15, Theorem 3.3] shows that the following proposition holds.\n\n\n                        \n                           Proposition 2.5\n                           \n                              (1) The class \n                              \n                                 N\n                                 (\n                                 \n                                    \n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                    \n                                    \n                                       W\n                                    \n                                 \n                                 )\n                               \n                              of all necessity measures on \n                              \n                                 \n                                    \n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                    \n                                    \n                                       W\n                                    \n                                 \n                               \n                              coincides with the class\n                              \n                                 \n                                    \n                                       \n                                          {\n                                          \n                                             \n                                                \u03c1\n                                             \n                                             \n                                                (\n                                                \u22c5\n                                                )\n                                             \n                                          \n                                          (\n                                          b\n                                          )\n                                          :\n                                          f\n                                          \u2208\n                                          \n                                             \n                                                [\n                                                0\n                                                ,\n                                                1\n                                                ]\n                                             \n                                             \n                                                W\n                                             \n                                          \n                                          \u21a6\n                                          \n                                             \n                                                \u03c1\n                                             \n                                             \n                                                f\n                                             \n                                          \n                                          (\n                                          b\n                                          )\n                                          |\n                                          b\n                                          \u2208\n                                          \n                                             \n                                                [\n                                                0\n                                                ,\n                                                1\n                                                ]\n                                             \n                                             \n                                                W\n                                             \n                                          \n                                          }\n                                       \n                                       .\n                                    \n                                 \n                              \n                           \n\n\n                              (2) The class \n                              \n                                 \n                                    \n                                       N\n                                    \n                                    \n                                       \u22a4\n                                    \n                                 \n                                 (\n                                 \n                                    \n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                    \n                                    \n                                       W\n                                    \n                                 \n                                 )\n                               \n                              of all normalised necessity measures on \n                              \n                                 \n                                    \n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                    \n                                    \n                                       W\n                                    \n                                 \n                               \n                              coincides with the class\n                              \n                                 \n                                    \n                                       \n                                          {\n                                          \n                                             \n                                                \u03c1\n                                             \n                                             \n                                                (\n                                                \u22c5\n                                                )\n                                             \n                                          \n                                          (\n                                          b\n                                          )\n                                          :\n                                          f\n                                          \u2208\n                                          \n                                             \n                                                [\n                                                0\n                                                ,\n                                                1\n                                                ]\n                                             \n                                             \n                                                W\n                                             \n                                          \n                                          \u21a6\n                                          \n                                             \n                                                \u03c1\n                                             \n                                             \n                                                f\n                                             \n                                          \n                                          (\n                                          b\n                                          )\n                                          |\n                                          b\n                                          \u2208\n                                          \n                                             \n                                                [\n                                                0\n                                                ,\n                                                1\n                                                ]\n                                             \n                                             \n                                                W\n                                             \n                                          \n                                          ,\n                                          \n                                          \n                                             max\n                                             \n                                                w\n                                                \u2208\n                                                W\n                                             \n                                          \n                                          \u2061\n                                          b\n                                          (\n                                          w\n                                          )\n                                          =\n                                          1\n                                          }\n                                       \n                                       .\n                                    \n                                 \n                              \n                           \n\nFor every finite set W let \n                           R\n                           (\n                           W\n                           )\n                         be the MV-algebra generated by the set \n                           {\n                           \n                              \n                                 \u03c1\n                              \n                              \n                                 a\n                              \n                           \n                           |\n                           a\n                           \u2208\n                           \n                              \n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                              \n                              \n                                 W\n                              \n                           \n                           }\n                        . The following holds. \n                           Proposition 2.6\n                           \n                              (See \n                              \n                                 [14]\n                              \n                              .) For every finite set W, the algebra \n                              \n                                 R\n                                 (\n                                 W\n                                 )\n                               \n                              is a separating MV-algebra of continuous functions. That is, each \n                              \n                                 f\n                                 \u2208\n                                 R\n                                 (\n                                 W\n                                 )\n                               \n                              is a continuous map, and for each \n                              \n                                 \n                                    \n                                       w\n                                    \n                                    \n                                       1\n                                    \n                                 \n                                 ,\n                                 \n                                    \n                                       w\n                                    \n                                    \n                                       2\n                                    \n                                 \n                                 \u2208\n                                 W\n                               \n                              such that \n                              \n                                 \n                                    \n                                       w\n                                    \n                                    \n                                       1\n                                    \n                                 \n                                 \u2260\n                                 \n                                    \n                                       w\n                                    \n                                    \n                                       2\n                                    \n                                 \n                              \n                              , there is an \n                              \n                                 f\n                                 \u2208\n                                 R\n                                 (\n                                 W\n                                 )\n                               \n                              such that \n                              \n                                 f\n                                 (\n                                 \n                                    \n                                       w\n                                    \n                                    \n                                       1\n                                    \n                                 \n                                 )\n                                 \u2260\n                                 f\n                                 (\n                                 \n                                    \n                                       w\n                                    \n                                    \n                                       2\n                                    \n                                 \n                                 )\n                              \n                              .\n                           \n\nNow we are ready to define belief functions on MV-algebras of fuzzy sets. \n                           Definition 2.7\n                           (See [17].) Let W be a finite set. A map \n                                 \n                                    Bel\n                                 \n                                 :\n                                 \n                                    \n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                    \n                                    \n                                       W\n                                    \n                                 \n                                 \u2192\n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                               is a belief function provided that there exists a state \n                                 s\n                                 :\n                                 R\n                                 (\n                                 W\n                                 )\n                                 \u2192\n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                               such that, for every \n                                 a\n                                 \u2208\n                                 \n                                    \n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                    \n                                    \n                                       W\n                                    \n                                 \n                              \n                              \n                                 \n                                    \n                                       \n                                          Bel\n                                       \n                                       (\n                                       a\n                                       )\n                                       =\n                                       s\n                                       (\n                                       \n                                          \n                                             \u03c1\n                                          \n                                          \n                                             a\n                                          \n                                       \n                                       )\n                                    \n                                 \n                               The state s is called the state assignment of Bel.\n\nAs pointed out in [17] (see also [13,14]), since \n                           \n                              \n                                 \u03c1\n                              \n                              \n                                 0\n                              \n                           \n                         does not coincide in general with the zero-constant function \n                           \n                              0\n                              \u00af\n                           \n                        , \n                           \n                              Bel\n                           \n                           (\n                           \n                              0\n                              \u00af\n                           \n                           )\n                         cannot be ensured to equal 0. We call normalised each belief function Bel on \n                           \n                              \n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                              \n                              \n                                 W\n                              \n                           \n                         satisfying \n                           \n                              Bel\n                           \n                           (\n                           \n                              0\n                              \u00af\n                           \n                           )\n                           =\n                           0\n                        .\n\nIf \n                           W\n                           =\n                           {\n                           \n                              \n                                 w\n                              \n                              \n                                 1\n                              \n                           \n                           ,\n                           \u2026\n                           ,\n                           \n                              \n                                 w\n                              \n                              \n                                 n\n                              \n                           \n                           }\n                         is a finite set, the Boolean algebra \n                           \n                              \n                                 2\n                              \n                              \n                                 W\n                              \n                           \n                         is clearly also finite, and hence any mass assignment \n                           m\n                           :\n                           \n                              \n                                 2\n                              \n                              \n                                 W\n                              \n                           \n                           \u2192\n                           [\n                           0\n                           ,\n                           1\n                           ]\n                         obviously has only finitely many focal elements. Also in the framework of finite MV-algebras, the mass assignment can be easily defined. Indeed, every finite MV-algebra can be embedded into an MV-algebra of the form \n                           \n                              \n                                 (\n                                 \n                                    \n                                       S\n                                    \n                                    \n                                       m\n                                    \n                                 \n                                 )\n                              \n                              \n                                 W\n                              \n                           \n                         where \n                           \n                              \n                                 S\n                              \n                              \n                                 m\n                              \n                           \n                           =\n                           {\n                           0\n                           ,\n                           1\n                           /\n                           m\n                           ,\n                           \u2026\n                           ,\n                           (\n                           m\n                           \u2212\n                           1\n                           )\n                           /\n                           m\n                           ,\n                           1\n                           }\n                         and W is a finite set, and every belief function Bel on \n                           \n                              \n                                 (\n                                 \n                                    \n                                       S\n                                    \n                                    \n                                       m\n                                    \n                                 \n                                 )\n                              \n                              \n                                 W\n                              \n                           \n                         can be written as:\n                           \n                              \n                                 \n                                    Bel\n                                 \n                                 (\n                                 f\n                                 )\n                                 =\n                                 \n                                    \u2211\n                                    \n                                       a\n                                       \u2208\n                                       \n                                          \n                                             (\n                                             \n                                                \n                                                   S\n                                                \n                                                \n                                                   m\n                                                \n                                             \n                                             )\n                                          \n                                          \n                                             W\n                                          \n                                       \n                                    \n                                 \n                                 \n                                    \n                                       \u03c1\n                                    \n                                    \n                                       a\n                                    \n                                 \n                                 (\n                                 f\n                                 )\n                                 \u22c5\n                                 \u03bc\n                                 \n                                    (\n                                    {\n                                    a\n                                    }\n                                    )\n                                 \n                                 ,\n                              \n                           \n                         where \u03bc is a uniquely determined probability measure on \n                           \n                              \n                                 2\n                              \n                              \n                                 \n                                    \n                                       (\n                                       \n                                          \n                                             S\n                                          \n                                          \n                                             m\n                                          \n                                       \n                                       )\n                                    \n                                    \n                                       W\n                                    \n                                 \n                              \n                           \n                         (cf. [14, Remark 4.10]). Hence, an element \n                           a\n                           \u2208\n                           \n                              \n                                 (\n                                 \n                                    \n                                       S\n                                    \n                                    \n                                       m\n                                    \n                                 \n                                 )\n                              \n                              \n                                 W\n                              \n                           \n                         is a focal element for Bel if and only if \n                           \u03bc\n                           (\n                           {\n                           a\n                           }\n                           )\n                           >\n                           0\n                        . (We will turn back on this, in Remark 4.4.)\n\nOn the other hand, for a belief function defined on the MV-algebra \n                           \n                              \n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                              \n                              \n                                 W\n                              \n                           \n                        , Theorem 2.1 ensures that, if \n                           \u03bc\n                           :\n                           B\n                           (\n                           \n                              \n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                              \n                              \n                                 W\n                              \n                           \n                           )\n                           \u2192\n                           [\n                           0\n                           ,\n                           1\n                           ]\n                         is a regular Borel probability measure, the map \n                           \n                              Bel\n                           \n                           :\n                           \n                              \n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                              \n                              \n                                 W\n                              \n                           \n                           \u2192\n                           [\n                           0\n                           ,\n                           1\n                           ]\n                        , defined as\n                           \n                              \n                                 \n                                    Bel\n                                 \n                                 (\n                                 a\n                                 )\n                                 =\n                                 \n                                    \u222b\n                                    \n                                       \n                                          [\n                                          0\n                                          ,\n                                          1\n                                          ]\n                                       \n                                       \n                                          W\n                                       \n                                    \n                                 \n                                 \n                                    \n                                       \u03c1\n                                    \n                                    \n                                       a\n                                    \n                                 \n                                 \n                                 d\n                                 \u03bc\n                                 ,\n                              \n                           \n                         is a belief function and conversely, that every belief function on \n                           \n                              \n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                              \n                              \n                                 W\n                              \n                           \n                         arises in this way. Clearly, the MV-algebra \n                           \n                              \n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                              \n                              \n                                 W\n                              \n                           \n                         has uncountably many elements, and hence we cannot find, in general, a mass assignment \u03bc defined over \n                           B\n                           (\n                           \n                              \n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                              \n                              \n                                 W\n                              \n                           \n                           )\n                         which is supported by a set which is at most countable.\n                           11\n                        \n                        \n                           11\n                           If it happens to be that \u03bc has a countable support (i.e. there is a countable subset \n                                 K\n                                 \u2282\n                                 \n                                    \n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                    \n                                    \n                                       W\n                                    \n                                 \n                               such that \n                                 \u03bc\n                                 (\n                                 K\n                                 )\n                                 =\n                                 1\n                              ) then the belief function defined induced by \u03bc takes the simplified form \n                                 \n                                    Bel\n                                 \n                                 (\n                                 f\n                                 )\n                                 =\n                                 \n                                    \n                                       \u2211\n                                    \n                                    \n                                       a\n                                       \u2208\n                                       \n                                          \n                                             [\n                                             0\n                                             ,\n                                             1\n                                             ]\n                                          \n                                          \n                                             W\n                                          \n                                       \n                                    \n                                 \n                                 \n                                    \n                                       \u03c1\n                                    \n                                    \n                                       a\n                                    \n                                 \n                                 (\n                                 f\n                                 )\n                                 \u22c5\n                                 \u03bc\n                                 (\n                                 {\n                                 a\n                                 }\n                                 )\n                              , for any \n                                 f\n                                 \u2208\n                                 \n                                    \n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                    \n                                    \n                                       W\n                                    \n                                 \n                              .\n                         This observation leads to the following definition. \n                           Definition 2.8\n                           (See [14].) Let \n                                 K\n                               be the set of all compact subsets of an MV-algebra of fuzzy sets \n                                 \n                                    \n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                    \n                                    \n                                       W\n                                    \n                                 \n                              . For every regular Borel probability measure \u03bc defined on \n                                 B\n                                 (\n                                 \n                                    \n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                    \n                                    \n                                       W\n                                    \n                                 \n                                 )\n                              , we call the set\n                                 \n                                    \n                                       spt\n                                       \n                                       \u03bc\n                                       =\n                                       \u22c2\n                                       \n                                          {\n                                          K\n                                          |\n                                          K\n                                          \u2208\n                                          K\n                                          ,\n                                          \u03bc\n                                          (\n                                          K\n                                          )\n                                          =\n                                          1\n                                          }\n                                       \n                                    \n                                 \n                               the support of \u03bc.\n\nBy Theorem 2.1 we can regard spt\n                        \u03bc as the support of the state assignment s defined from \u03bc via (8). In particular, the following holds:\n                           \n                              (11)\n                              \n                                 \n                                    Bel\n                                 \n                                 (\n                                 a\n                                 )\n                                 =\n                                 \n                                    \u222b\n                                    \n                                       \n                                          [\n                                          0\n                                          ,\n                                          1\n                                          ]\n                                       \n                                       \n                                          W\n                                       \n                                    \n                                 \n                                 \n                                    \n                                       \u03c1\n                                    \n                                    \n                                       a\n                                    \n                                 \n                                 \n                                 d\n                                 \u03bc\n                                 =\n                                 \n                                    \u222b\n                                    \n                                       spt\n                                       \n                                       \u03bc\n                                    \n                                 \n                                 \n                                    \n                                       \u03c1\n                                    \n                                    \n                                       a\n                                    \n                                 \n                                 \n                                 d\n                                 \u03bc\n                                 .\n                              \n                           \n                         Therefore, the set of focal elements of a belief function Bel on \n                           \n                              \n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                              \n                              \n                                 W\n                              \n                           \n                         whose state assignment s is represented by a regular Borel probability measure \u03bc effectively coincides with spt\n                        \u03bc. As a consequence we will freely speak of either the support or the set of focal elements of such belief functions with no risk of confusion arising.\n\nAs in the classical Dempster\u2013Shafer theory, plausibility functions on fuzzy sets can also be defined by duality from a belief function. In other words, if Bel is a belief function on \n                           \n                              \n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                              \n                              \n                                 W\n                              \n                           \n                         (as in Definition 2.7), its dual plausibility function \n                        \n                           \n                              Pl\n                           \n                           :\n                           \n                              \n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                              \n                              \n                                 W\n                              \n                           \n                           \u2192\n                           [\n                           0\n                           ,\n                           1\n                           ]\n                         is defined by the following stipulation: for every \n                           a\n                           \u2208\n                           \n                              \n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                              \n                              \n                                 W\n                              \n                           \n                        ,\n                           \n                              (12)\n                              \n                                 \n                                    Pl\n                                 \n                                 (\n                                 a\n                                 )\n                                 =\n                                 1\n                                 \u2212\n                                 \n                                    Bel\n                                 \n                                 (\n                                 \u00ac\n                                 a\n                                 )\n                                 =\n                                 1\n                                 \u2212\n                                 s\n                                 (\n                                 \n                                    \n                                       \u03c1\n                                    \n                                    \n                                       \u00ac\n                                       a\n                                    \n                                 \n                                 )\n                              \n                           \n                         where \n                           s\n                           :\n                           R\n                           (\n                           W\n                           )\n                           \u2192\n                           [\n                           0\n                           ,\n                           1\n                           ]\n                         is the state-assignment of Bel. Since states are self-dual (i.e. \n                           s\n                           (\n                           \u00ac\n                           x\n                           )\n                           =\n                           1\n                           \u2212\n                           s\n                           (\n                           x\n                           )\n                        ), the above expression reduces to \n                           \n                              Pl\n                           \n                           (\n                           a\n                           )\n                           =\n                           s\n                           (\n                           \u00ac\n                           \n                              \n                                 \u03c1\n                              \n                              \n                                 \u00ac\n                                 a\n                              \n                           \n                           )\n                        , for all \n                           a\n                           \u2208\n                           \n                              \n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                              \n                              \n                                 W\n                              \n                           \n                        . Therefore, since by Proposition 2.5 the map \n                           \n                              \n                                 \u03c1\n                              \n                              \n                                 (\n                                 \u22c5\n                                 )\n                              \n                           \n                           (\n                           b\n                           )\n                         is a necessity measure (and in particular it is normalised whenever \n                           max\n                           \u2061\n                           {\n                           b\n                           (\n                           w\n                           )\n                           :\n                           w\n                           \u2208\n                           W\n                           }\n                           =\n                           1\n                        ), \n                           \u00ac\n                           \n                              \n                                 \u03c1\n                              \n                              \n                                 \u00ac\n                                 (\n                                 \u22c5\n                                 )\n                              \n                           \n                           (\n                           b\n                           )\n                         is a (normalised) possibility measure [15, Definition 3.2]. Moreover, every (normalised) possibility measure on \n                           \n                              \n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                              \n                              \n                                 W\n                              \n                           \n                         can be obtained in this way.\n\nWe now introduce a betting method which generalises both Jaffray and Mundici's frameworks recalled above. As anticipated and motivated in the introductory section of this paper, we generalise Jaffray's by considering many-valued events, and generalise Mundici's by considering several sources of information (each of distinct reliability) and allowing for (partly) unresolved uncertainty.\n\nAs usual, our two players will be labelled B (for Bookmaker) and G (for Gambler), and we fix a set of (many-valued) events of interest \n                        {\n                        \n                           \n                              e\n                           \n                           \n                              1\n                           \n                        \n                        ,\n                        \u2026\n                        ,\n                        \n                           \n                              e\n                           \n                           \n                              k\n                           \n                        \n                        }\n                     . As in the classical case, the game begins with B publishing a book \u03b2 which assigns, to each event \n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                     , a real number \n                        \n                           \n                              \u03b2\n                           \n                           \n                              i\n                           \n                        \n                        \u2208\n                        [\n                        0\n                        ,\n                        1\n                        ]\n                     . Again, in full analogy with de Finetti's method, B and G agree that the stakes placed by G at the second stage of the game can either be positive or negative. In other words, for every \n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                     , G choses real numbers \n                        \n                           \n                              \u03c3\n                           \n                           \n                              i\n                           \n                        \n                      and pays to B the amount \n                        \n                           \n                              \u2211\n                           \n                           \n                              i\n                              =\n                              1\n                           \n                           \n                              k\n                           \n                        \n                        \n                           \n                              \u03b2\n                           \n                           \n                              i\n                           \n                        \n                        \u22c5\n                        \n                           \n                              \u03c3\n                           \n                           \n                              i\n                           \n                        \n                      in Euros. This corresponds to the price that B accepts to pay to bet on the \n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                     's.\n\nIn the spirit of the Global Health Agency example above, our framework introduces the following main novelties with respect to de Finetti's:\n                        \n                           (i)\n                           a finite set of many-valued possible worlds \n                              \n                                 W\n                                 =\n                                 {\n                                 \n                                    \n                                       w\n                                    \n                                    \n                                       1\n                                    \n                                 \n                                 ,\n                                 \u2026\n                                 ,\n                                 \n                                    \n                                       w\n                                    \n                                    \n                                       n\n                                    \n                                 \n                                 }\n                              , to be interpreted as the set of possible (complete) scenarios regarding the events, i.e. scenarios which determine the truth-value (from \n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                              ) in which every event holds. [In our running example, such scenarios determine the degree to which a certain disease turns out to be aggressive.]\n\na finite set Ag of informative agents \n                              \n                                 {\n                                 \n                                    \n                                       a\n                                    \n                                    \n                                       1\n                                    \n                                 \n                                 ,\n                                 \u2026\n                                 ,\n                                 \n                                    \n                                       a\n                                    \n                                    \n                                       m\n                                    \n                                 \n                                 }\n                              , each one notifying which is the resulting scenario according to its subjective point of view. [Again in our example, such agents coincide with the individual National Health Organisations.]\n\nagents, as information sources, may be more or less reliable. [In our running example this depends on the fact that the measurement concerning the outbreak of a particular disease is intrinsically statistical and therefore it is susceptible of being more or less accurate.]\n\nwe identify events with formulas of \u0141ukasiewicz logic over a language built on a set of propositional variables V;\n\nwe identify the set of possible worlds or scenarios with a subset of evaluations for formulas, i.e. \n                                 W\n                                 \u2286\n                                 \n                                    \n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                    \n                                    \n                                       V\n                                    \n                                 \n                              ;\n\nwe identify the information provided by each agent with the choice of one possible world or scenario from W, i.e. each agent \n                                 a\n                                 \u2208\n                                 A\n                               chooses one \n                                 \n                                    \n                                       w\n                                    \n                                    \n                                       a\n                                    \n                                 \n                                 \u2208\n                                 W\n                              ;\n\nwe assume an oracle \n                                 O\n                               to assign a reliability degree to each agent, i.e. \n                                 O\n                               determines a reliability map \n                                 \u03b7\n                                 :\n                                 \n                                    Ag\n                                 \n                                 \u2192\n                                 [\n                                 0\n                                 ,\n                                 1\n                                 ]\n                              , where \n                                 \u03b7\n                                 (\n                                 a\n                                 )\n                                 =\n                                 1\n                               means that agent a is fully reliable, \n                                 0\n                                 <\n                                 \u03b7\n                                 (\n                                 a\n                                 )\n                                 <\n                                 1\n                               means that a is somewhat reliable (the higher the more reliable), and \n                                 \u03b7\n                                 (\n                                 a\n                                 )\n                                 =\n                                 0\n                               means that a is not reliable at all. We also assume that, amongst all agents, at least one is not completely unreliable, that is \n                                 \n                                    \n                                       max\n                                    \n                                    \n                                       a\n                                       \u2208\n                                       \n                                          Ag\n                                       \n                                    \n                                 \n                                 \u2061\n                                 \u03b7\n                                 (\n                                 a\n                                 )\n                                 >\n                                 0\n                              . The set of these reliability maps will be denoted \n                                 \n                                    \n                                       \u039b\n                                    \n                                    \n                                       +\n                                    \n                                 \n                                 (\n                                 \n                                    Ag\n                                 \n                                 )\n                              .\n\nNotice that, as far as betting in this framework is concerned, the first two assumptions above imply that events can only be distinguished by how possible worlds evaluate them, hence they can be represented as functions defined on \n                        \n                           \n                              [\n                              0\n                              ,\n                              1\n                              ]\n                           \n                           \n                              W\n                           \n                        \n                     , namely one event e can be understood as the function \n                        w\n                        \u21a6\n                        w\n                        (\n                        e\n                        )\n                     , for each \n                        w\n                        \u2208\n                        W\n                     .\n\nA triple \n                        E\n                        =\n                        (\n                        \n                           Ag\n                        \n                        ,\n                        \n                           w\n                           \u00af\n                        \n                        ,\n                        \u03b7\n                        )\n                     , where \n                        \n                           w\n                           \u00af\n                        \n                        =\n                        {\n                        \n                           \n                              w\n                           \n                           \n                              a\n                           \n                        \n                        \u2208\n                        W\n                        |\n                        a\n                        \u2208\n                        \n                           Ag\n                        \n                        }\n                      is a set of evaluations of events for each \n                        a\n                        \u2208\n                        \n                           Ag\n                        \n                     , will be called an evaluating triple.\n\nAll the above ingredients allow us to evaluate the events involved in the betting as a weighted aggregation of the information provided by the agents, where weights are related to reliability degrees. More concretely, we consider an aggregation method as a two-place function \n                        \n                           agg\n                        \n                        (\n                        \u22c5\n                        ,\n                        \u22c5\n                        )\n                      such that, for each evaluating triplet \n                        E\n                      and for each event \n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                     , \n                        \n                           agg\n                        \n                        (\n                        E\n                        ,\n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                        )\n                        \u2208\n                        [\n                        0\n                        ,\n                        1\n                        ]\n                     . We will assume that \n                        \n                           agg\n                        \n                        (\n                        \u22c5\n                        ,\n                        \u22c5\n                        )\n                      satisfies some suitable properties that we leave unspecified for the moment. Whenever \n                        E\n                      is fixed, we shall denote by \n                        \n                           \n                              agg\n                           \n                           \n                              E\n                           \n                        \n                        (\n                        \u22c5\n                        )\n                      the one-place map \n                        \n                           agg\n                        \n                        (\n                        E\n                        ,\n                        \u22c5\n                        )\n                     .\n\nFinally, once an evaluation triplet \n                        E\n                      and the aggregation method agg are fixed and agreed by the bookmaker and the gambler, the specification of the betting framework is completed by determining that the amount gambler G receives from bookmaker B for each event \n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                      is proportional to the value \n                        \n                           \n                              agg\n                           \n                           \n                              E\n                           \n                        \n                        (\n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                        )\n                     , the total amount being \n                        \n                           \n                              \u2211\n                           \n                           \n                              i\n                              =\n                              1\n                           \n                           \n                              k\n                           \n                        \n                        \n                           \n                              \u03c3\n                           \n                           \n                              i\n                           \n                        \n                        \u22c5\n                        \n                           \n                              agg\n                           \n                           \n                              E\n                           \n                        \n                        (\n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                        )\n                     . Then the total amount for B is:\n                        \n                           (13)\n                           \n                              \n                                 \u2211\n                                 \n                                    i\n                                    =\n                                    1\n                                 \n                                 k\n                              \n                              \n                                 \n                                    \u03c3\n                                 \n                                 \n                                    i\n                                 \n                              \n                              \u22c5\n                              \n                                 (\n                                 \n                                    \n                                       \u03b2\n                                    \n                                    \n                                       i\n                                    \n                                 \n                                 \u2212\n                                 \n                                    \n                                       agg\n                                    \n                                    \n                                       E\n                                    \n                                 \n                                 (\n                                 \n                                    \n                                       e\n                                    \n                                    \n                                       i\n                                    \n                                 \n                                 )\n                                 )\n                              \n                              .\n                           \n                        \n                     \n                  \n\nNote that (13) generalises both (2) and (3). Indeed, if Ag consists of only one agent a and \n                        \u03b7\n                        (\n                        a\n                        )\n                        =\n                        1\n                     , then we are in Mundici's betting framework. On the other hand, if \n                        \u03b7\n                        (\n                        a\n                        )\n                        =\n                        1\n                      for each \n                        a\n                        \u2208\n                        \n                           Ag\n                        \n                      and \n                        \n                           agg\n                        \n                        (\n                        E\n                        ,\n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                        )\n                        =\n                        1\n                      if \n                        \n                           \n                              w\n                           \n                           \n                              a\n                           \n                        \n                        (\n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                        )\n                        =\n                        1\n                      for all \n                        a\n                        \u2208\n                        \n                           Ag\n                        \n                     , and \n                        \n                           agg\n                        \n                        (\n                        E\n                        ,\n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                        )\n                        =\n                        0\n                      otherwise, then we essentially recover Jaffray's betting framework.\n                        12\n                     \n                     \n                        12\n                        Actually, strictly speaking, in Jaffray's betting framework there is only one information source providing an (incomplete) description of the world, while in this particular scenario of our betting framework we have a set of informative agents, each one providing a possible complete description of the world. So, they both are equivalent forms of representing an incomplete information, or in Jaffray's terms, an \u201cunresolved uncertainty\u201d setting.\n                     \n                  \n\nNow we are ready to introduce the notion of coherence in our extended framework.\n\n\n                     \n                        Coherence in the aggregate criterion\n                        We say that a book \u03b2 is coherent in the aggregate \n                           agg, if it does not lead B to lose money independently of the evaluating triple \n                              E\n                           .\n\nIn other words, \u03b2 is coherent in the aggregate (with respect to the aggregation agg), if and only if, for every \n                        \n                           \n                              \u03c3\n                           \n                           \n                              1\n                           \n                        \n                        ,\n                        \u2026\n                        ,\n                        \n                           \n                              \u03c3\n                           \n                           \n                              k\n                           \n                        \n                        \u2208\n                        R\n                     , there exists an evaluating triple \n                        E\n                     , such that\n                        \n                           (14)\n                           \n                              \n                                 \u2211\n                                 \n                                    i\n                                    =\n                                    1\n                                 \n                                 k\n                              \n                              \n                                 \n                                    \u03c3\n                                 \n                                 \n                                    i\n                                 \n                              \n                              \n                                 (\n                                 \n                                    \n                                       \u03b2\n                                    \n                                    \n                                       i\n                                    \n                                 \n                                 \u2212\n                                 \n                                    \n                                       agg\n                                    \n                                    \n                                       E\n                                    \n                                 \n                                 (\n                                 \n                                    \n                                       e\n                                    \n                                    \n                                       i\n                                    \n                                 \n                                 )\n                                 )\n                              \n                              \u2265\n                              0\n                              .\n                           \n                        \n                     \n                  \n\nNote that the underlying idea behind our notion of coherence in the aggregate is virtually identical to the seminal one which lead to de Finetti's original version of the Dutch Book: in a suitably specified betting problem, Bookmaker is incoherent if she exposes herself to the logical possibility of incurring sure loss. What our twofold generalisation brings to the problem is a considerably refined understanding of what \u201cthe logical possibility of sure loss\u201d means. Yet it is worth remarking that the formal adjustments do not require an essential modification of the concept of coherence. This, in our view, provides a solid foundation for the investigation of belief functions on many-valued events as measures of rational belief as opposed to a mathematically deep albeit purely formal exercise.\n\nGoing back to our main concern, the aggregate values \n                        \n                           \n                              agg\n                           \n                           \n                              E\n                           \n                        \n                        (\n                        \n                           \n                              e\n                           \n                           \n                              i\n                           \n                        \n                        )\n                      can be obtained by several aggregation procedures, see e.g. [9]. In this paper we shall consider three relevant cases which we term pessimistic, optimistic and average, respectively. The terminology of pessimistic and optimistic attitudes and the way they are modelled (namely by generalised necessity and possibility measures) conforms to the ones in use in possibilistic decision theory, see e.g. [8,11,10]. The average attitude, on the other hand, arises naturally in the context of the problem under investigation.\n\n\n                     \n                        Definition 3.1\n                        Aggregation\n\n\n                        Let \n                              E\n                              =\n                              (\n                              \n                                 Ag\n                              \n                              ,\n                              \n                                 w\n                                 \u00af\n                              \n                              ,\n                              \u03b7\n                              )\n                            be an evaluating triple. For every event \n                              e\n                              \u2208\n                              \n                                 \n                                    [\n                                    0\n                                    ,\n                                    1\n                                    ]\n                                 \n                                 \n                                    W\n                                 \n                              \n                           , we define the optimistic, the pessimistic and the average aggregation maps \n                              \n                                 \n                                    \u03a0\n                                 \n                                 \n                                    E\n                                 \n                              \n                           , \n                              \n                                 \n                                    N\n                                 \n                                 \n                                    E\n                                 \n                              \n                            and \n                              \n                                 \n                                    M\n                                 \n                                 \n                                    E\n                                 \n                              \n                            respectively, as follows:\n                              \n                                 (15)\n                                 \n                                    \n                                       \n                                          \n                                             \u03a0\n                                          \n                                          \n                                             E\n                                          \n                                       \n                                       (\n                                       e\n                                       )\n                                       =\n                                       \n                                          max\n                                          \n                                             a\n                                             \u2208\n                                             \n                                                Ag\n                                             \n                                          \n                                       \n                                       \u2061\n                                       \n                                          {\n                                          \u03b7\n                                          (\n                                          a\n                                          )\n                                          \u2299\n                                          \n                                             \n                                                w\n                                             \n                                             \n                                                a\n                                             \n                                          \n                                          (\n                                          e\n                                          )\n                                          }\n                                       \n                                       ,\n                                    \n                                 \n                                 \n                                    \n                                       \n                                          \n                                             N\n                                          \n                                          \n                                             E\n                                          \n                                       \n                                       (\n                                       e\n                                       )\n                                       =\n                                       \n                                          min\n                                          \n                                             a\n                                             \u2208\n                                             \n                                                Ag\n                                             \n                                          \n                                       \n                                       \u2061\n                                       \n                                          {\n                                          \u03b7\n                                          (\n                                          a\n                                          )\n                                          \u21d2\n                                          \n                                             \n                                                w\n                                             \n                                             \n                                                a\n                                             \n                                          \n                                          (\n                                          e\n                                          )\n                                          }\n                                       \n                                       ,\n                                    \n                                 \n                                 \n                                    \n                                       \n                                          \n                                             M\n                                          \n                                          \n                                             E\n                                          \n                                       \n                                       (\n                                       e\n                                       )\n                                       =\n                                       \n                                          [\n                                          \n                                             \u2211\n                                             \n                                                a\n                                                \u2208\n                                                \n                                                   Ag\n                                                \n                                             \n                                          \n                                          \u03b7\n                                          (\n                                          a\n                                          )\n                                          \u22c5\n                                          \n                                             \n                                                w\n                                             \n                                             \n                                                a\n                                             \n                                          \n                                          (\n                                          e\n                                          )\n                                          ]\n                                       \n                                       /\n                                       \n                                          \u2211\n                                          \n                                             a\n                                             \u2208\n                                             \n                                                Ag\n                                             \n                                          \n                                       \n                                       \u03b7\n                                       (\n                                       a\n                                       )\n                                       .\n                                    \n                                 \n                              \n                           \n                        \n\nThe next lemma shows that these three kinds of aggregation maps are in fact restrictions of possibility measures, necessity necessity measures and states on the MV-algebra of functions \n                        \n                           \n                              [\n                              0\n                              ,\n                              1\n                              ]\n                           \n                           \n                              W\n                           \n                        \n                     .\n\n\n                     \n                        Lemma 3.2\n                        \n                           For every evaluation triple \n                           \n                              E\n                              =\n                              (\n                              \n                                 Ag\n                              \n                              ,\n                              \n                                 w\n                                 \u00af\n                              \n                              ,\n                              \u03b7\n                              )\n                            \n                           and for every class C of events in \n                           \n                              \n                                 \n                                    [\n                                    0\n                                    ,\n                                    1\n                                    ]\n                                 \n                                 \n                                    W\n                                 \n                              \n                            \n                           the following properties hold:\n                           \n                              \n                                 \n                                    (i)\n                                 \n                                 \n                                    \n                                       \n                                          \n                                             \u03a0\n                                          \n                                          \n                                             E\n                                          \n                                       \n                                     \n                                    is the restriction on C of a possibility measure on \n                                    \n                                       \n                                          \n                                             [\n                                             0\n                                             ,\n                                             1\n                                             ]\n                                          \n                                          \n                                             W\n                                          \n                                       \n                                    \n                                    . Conversely, for each possibility distribution \n                                    \n                                       \u03c0\n                                       :\n                                       W\n                                       \u2192\n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                     \n                                    there exists an evaluating triple \n                                    \n                                       E\n                                     \n                                    such that \n                                    \n                                       \n                                          \n                                             \u03a0\n                                          \n                                          \n                                             \u03c0\n                                          \n                                       \n                                       (\n                                       e\n                                       )\n                                       =\n                                       \n                                          \n                                             max\n                                          \n                                          \n                                             w\n                                             \u2208\n                                             W\n                                          \n                                       \n                                       \u2061\n                                       \u03c0\n                                       (\n                                       w\n                                       )\n                                       \u2299\n                                       w\n                                       (\n                                       e\n                                       )\n                                       =\n                                       \n                                          \n                                             \u03a0\n                                          \n                                          \n                                             E\n                                          \n                                       \n                                       (\n                                       e\n                                       )\n                                     \n                                    for each \n                                    \n                                       e\n                                       \u2208\n                                       C\n                                    \n                                    .\n                                 \n\n\n                                    \n                                       \n                                          \n                                             N\n                                          \n                                          \n                                             E\n                                          \n                                       \n                                     \n                                    is the restriction on C of a necessity measure on \n                                    \n                                       \n                                          \n                                             [\n                                             0\n                                             ,\n                                             1\n                                             ]\n                                          \n                                          \n                                             W\n                                          \n                                       \n                                    \n                                    . For each possibility distribution \n                                    \n                                       \u03c0\n                                       :\n                                       W\n                                       \u2192\n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                     \n                                    there exists an evaluating triple \n                                    \n                                       E\n                                     \n                                    such that \n                                    \n                                       \n                                          \n                                             N\n                                          \n                                          \n                                             \u03c0\n                                          \n                                       \n                                       (\n                                       e\n                                       )\n                                       =\n                                       \n                                          \n                                             max\n                                          \n                                          \n                                             w\n                                             \u2208\n                                             W\n                                          \n                                       \n                                       \u2061\n                                       \u03c0\n                                       (\n                                       w\n                                       )\n                                       \u2299\n                                       w\n                                       (\n                                       e\n                                       )\n                                       =\n                                       \n                                          \n                                             N\n                                          \n                                          \n                                             E\n                                          \n                                       \n                                       (\n                                       e\n                                       )\n                                     \n                                    for each \n                                    \n                                       e\n                                       \u2208\n                                       C\n                                    \n                                    .\n                                 \n\n\n                                    \n                                       \n                                          \n                                             M\n                                          \n                                          \n                                             E\n                                          \n                                       \n                                     \n                                    is the restriction on C of a state on \n                                    \n                                       \n                                          \n                                             [\n                                             0\n                                             ,\n                                             1\n                                             ]\n                                          \n                                          \n                                             W\n                                          \n                                       \n                                    \n                                    . Conversely, for each probability distribution \n                                    \n                                       p\n                                       :\n                                       W\n                                       \u2192\n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                     \n                                    there exists an evaluating triple \n                                    \n                                       E\n                                     \n                                    such that \n                                    \n                                       \n                                          \n                                             \u2211\n                                          \n                                          \n                                             w\n                                             \u2208\n                                             W\n                                          \n                                       \n                                       p\n                                       (\n                                       w\n                                       )\n                                       \u22c5\n                                       w\n                                       (\n                                       e\n                                       )\n                                       =\n                                       \n                                          \n                                             M\n                                          \n                                          \n                                             E\n                                          \n                                       \n                                     \n                                    for each \n                                    \n                                       e\n                                       \u2208\n                                       C\n                                    \n                                    .\n                                 \n\n\n                     \n                        Proof\n                        \n                           \n                              \n                                 (i)\n                                 Define the possibility distribution \n                                       \u03c0\n                                       :\n                                       W\n                                       \u2192\n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                     as follows: \n                                       \u03c0\n                                       (\n                                       w\n                                       )\n                                       =\n                                       max\n                                       \u2061\n                                       {\n                                       \u03b7\n                                       (\n                                       a\n                                       )\n                                       |\n                                       a\n                                       \u2208\n                                       \n                                          Ag\n                                       \n                                        such that \n                                       \n                                          \n                                             w\n                                          \n                                          \n                                             a\n                                          \n                                       \n                                       =\n                                       w\n                                       }\n                                    . One can check then that, for every \n                                       e\n                                       \u2208\n                                       C\n                                    , \n                                       \n                                          \n                                             \u03a0\n                                          \n                                          \n                                             E\n                                          \n                                       \n                                       (\n                                       e\n                                       )\n                                       =\n                                       \n                                          \n                                             \u03a0\n                                          \n                                          \n                                             \u03c0\n                                          \n                                       \n                                       (\n                                       e\n                                       )\n                                       =\n                                       \n                                          \n                                             max\n                                          \n                                          \n                                             w\n                                             \u2208\n                                             W\n                                          \n                                       \n                                       \u2061\n                                       \u03c0\n                                       (\n                                       w\n                                       )\n                                       \u2299\n                                       w\n                                       (\n                                       e\n                                       )\n                                    . Indeed, we have:\n                                       \n                                          \n                                             \n                                                \n                                                   \u03a0\n                                                \n                                                \n                                                   \u03c0\n                                                \n                                             \n                                             (\n                                             e\n                                             )\n                                             =\n                                             \n                                                max\n                                                \n                                                   w\n                                                   \u2208\n                                                   W\n                                                \n                                             \n                                             \u2061\n                                             \u03c0\n                                             (\n                                             w\n                                             )\n                                             \u2299\n                                             w\n                                             (\n                                             e\n                                             )\n                                             =\n                                             \n                                                max\n                                                \n                                                   w\n                                                   \u2208\n                                                   W\n                                                \n                                             \n                                             \u2061\n                                             max\n                                             \u2061\n                                             \n                                                {\n                                                \u03b7\n                                                (\n                                                a\n                                                )\n                                                \u2299\n                                                w\n                                                (\n                                                e\n                                                )\n                                                |\n                                                a\n                                                \u2208\n                                                \n                                                   Ag\n                                                \n                                                ,\n                                                w\n                                                =\n                                                \n                                                   \n                                                      w\n                                                   \n                                                   \n                                                      a\n                                                   \n                                                \n                                                }\n                                             \n                                             =\n                                             max\n                                             \u2061\n                                             \n                                                {\n                                                \u03b7\n                                                (\n                                                a\n                                                )\n                                                \u2299\n                                                \n                                                   \n                                                      w\n                                                   \n                                                   \n                                                      a\n                                                   \n                                                \n                                                (\n                                                e\n                                                )\n                                                |\n                                                a\n                                                \u2208\n                                                \n                                                   Ag\n                                                \n                                                }\n                                             \n                                             =\n                                             \n                                                \n                                                   \u03a0\n                                                \n                                                \n                                                   E\n                                                \n                                             \n                                             (\n                                             e\n                                             )\n                                             .\n                                          \n                                       \n                                     To prove that for each possibility distribution \n                                       \u03c0\n                                       :\n                                       W\n                                       \u2192\n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                     there exists an evaluating triple \n                                       (\n                                       \n                                          Ag\n                                       \n                                       ,\n                                       \n                                          w\n                                          \u00af\n                                       \n                                       ,\n                                       \u03b7\n                                       )\n                                     such that \n                                       \n                                          \n                                             \u03a0\n                                          \n                                          \n                                             \u03c0\n                                          \n                                       \n                                       (\n                                       e\n                                       )\n                                       =\n                                       \n                                          \n                                             \u03a0\n                                          \n                                          \n                                             E\n                                          \n                                       \n                                       (\n                                       e\n                                       )\n                                     for each \n                                       e\n                                       \u2208\n                                       C\n                                    , it is enough to take \n                                       \n                                          Ag\n                                       \n                                       =\n                                       W\n                                    , \n                                       \u03b7\n                                       =\n                                       \u03c0\n                                     and \n                                       \n                                          \n                                             w\n                                          \n                                          \n                                             a\n                                          \n                                       \n                                       =\n                                       a\n                                     for each \n                                       a\n                                       \u2208\n                                       W\n                                    .\n\nThe proof of this item directly follows from (i) and recalling that possibility and necessity measures are dual, that is, for every \n                                       \u03c0\n                                       :\n                                       W\n                                       \u2192\n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                     and for every \n                                       e\n                                       \u2208\n                                       C\n                                    , \n                                       \n                                          \n                                             \u03a0\n                                          \n                                          \n                                             \u03c0\n                                          \n                                       \n                                       (\n                                       e\n                                       )\n                                       =\n                                       1\n                                       \u2212\n                                       \n                                          \n                                             N\n                                          \n                                          \n                                             \u03c0\n                                          \n                                       \n                                       (\n                                       1\n                                       \u2212\n                                       e\n                                       )\n                                    .\n\nThe proof is a direct consequence of the representation theorem for states (Theorem 2.1) in the special case of finite W. In this case, in fact, all states are of the form \n                                       s\n                                       (\n                                       a\n                                       )\n                                       =\n                                       \n                                          \n                                             \u2211\n                                          \n                                          \n                                             x\n                                             \u2208\n                                             W\n                                          \n                                       \n                                       a\n                                       (\n                                       x\n                                       )\n                                       p\n                                       (\n                                       x\n                                       )\n                                    , where \n                                       p\n                                       :\n                                       W\n                                       \u2192\n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                     is a probability distribution on W, i.e. \n                                       \n                                          \n                                             \u2211\n                                          \n                                          \n                                             x\n                                             \u2208\n                                             W\n                                          \n                                       \n                                       p\n                                       (\n                                       x\n                                       )\n                                       =\n                                       1\n                                    . To prove that for every probability distribution there exists an evaluation triple \n                                       E\n                                       =\n                                       (\n                                       \n                                          Ag\n                                       \n                                       ,\n                                       \n                                          w\n                                          \u00af\n                                       \n                                       ,\n                                       \u03b7\n                                       )\n                                     such that \n                                       \n                                          \n                                             M\n                                          \n                                          \n                                             E\n                                          \n                                       \n                                       =\n                                       \n                                          \n                                             \u2211\n                                          \n                                          \n                                             w\n                                             \u2208\n                                             W\n                                          \n                                       \n                                       p\n                                       (\n                                       w\n                                       )\n                                       \u22c5\n                                       w\n                                       (\n                                       e\n                                       )\n                                     it is sufficient to settle \n                                       \n                                          Ag\n                                       \n                                       =\n                                       W\n                                    , \n                                       \u03b7\n                                       =\n                                       p\n                                     and \n                                       \n                                          \n                                             w\n                                          \n                                          \n                                             a\n                                          \n                                       \n                                       =\n                                       w\n                                     for every \n                                       a\n                                       \u2208\n                                       W\n                                    .\u2003\u25a1\n\n\n                     \n                        Remark 3.3\n                        Actually, the way of building the possibility distribution \u03c0 in the proofs of items (i) and (ii) of the above Lemma 3.2 reflects the disjunctive nature of the information aggregation underlying the optimistic and pessimistic operators \n                              \n                                 \n                                    \u03a0\n                                 \n                                 \n                                    E\n                                 \n                              \n                            and \n                              \n                                 \n                                    N\n                                 \n                                 \n                                    E\n                                 \n                              \n                            respectively. In fact, one can argue that two agents a and \n                              \n                                 \n                                    a\n                                 \n                                 \n                                    \u2032\n                                 \n                              \n                           , say both with equal reliability, reporting two different words \n                              \n                                 \n                                    w\n                                 \n                                 \n                                    a\n                                 \n                              \n                              \u2260\n                              \n                                 \n                                    w\n                                 \n                                 \n                                    \n                                       \n                                          a\n                                       \n                                       \n                                          \u2032\n                                       \n                                    \n                                 \n                              \n                            denote a contradiction in the information they provide, since worlds represent complete descriptions and hence if \n                              \n                                 \n                                    w\n                                 \n                                 \n                                    a\n                                 \n                              \n                            is supposed to hold for a, \n                              \n                                 \n                                    w\n                                 \n                                 \n                                    \n                                       \n                                          a\n                                       \n                                       \n                                          \u2032\n                                       \n                                    \n                                 \n                              \n                            cannot hold as well for a. However, in our betting metaphor we take the stand point that agents are providers of only possible scenarios, so in that case, agents a and \n                              \n                                 \n                                    a\n                                 \n                                 \n                                    \u2032\n                                 \n                              \n                            are reporting that worlds \n                              \n                                 \n                                    w\n                                 \n                                 \n                                    a\n                                 \n                              \n                            and \n                              \n                                 \n                                    w\n                                 \n                                 \n                                    \n                                       \n                                          a\n                                       \n                                       \n                                          \u2032\n                                       \n                                    \n                                 \n                              \n                            are both possible scenarios, and they are possible to the extent they are considered reliable.\n\nIn fact, an equivalent alternative to the multi-agent betting framework for the case of optimistic and pessimistic aggregation could be considering the oracle \n                              O\n                            to provide an imprecise description of the world in the form a nested set of subsets of possible worlds \n                              \u2205\n                              \u2260\n                              \n                                 \n                                    W\n                                 \n                                 \n                                    1\n                                 \n                              \n                              \u2282\n                              \n                                 \n                                    W\n                                 \n                                 \n                                    2\n                                 \n                              \n                              \u2282\n                              \u2026\n                              \u2282\n                              \n                                 \n                                    W\n                                 \n                                 \n                                    n\n                                 \n                              \n                              \u2286\n                              W\n                            together with increasing confidence degrees \n                              0\n                              <\n                              \n                                 \n                                    \u03b1\n                                 \n                                 \n                                    1\n                                 \n                              \n                              \u2264\n                              \n                                 \n                                    \u03b1\n                                 \n                                 \n                                    2\n                                 \n                              \n                              \u2264\n                              \u2026\n                              \u2264\n                              \n                                 \n                                    \u03b1\n                                 \n                                 \n                                    n\n                                 \n                              \n                              =\n                              1\n                           . Interpreting a value \n                              \n                                 \n                                    \u03b1\n                                 \n                                 \n                                    i\n                                 \n                              \n                            as the necessity degrees with which the oracle believes the actual world is in the set \n                              \n                                 \n                                    W\n                                 \n                                 \n                                    i\n                                 \n                              \n                           , the (epistemic) information provided by the oracle amounts to directly provide the possibility distribution \u03c0 on W defined as \n                              \u03c0\n                              (\n                              w\n                              )\n                              =\n                              min\n                              \u2061\n                              {\n                              1\n                              \u2212\n                              \n                                 \n                                    \u03b1\n                                 \n                                 \n                                    i\n                                 \n                              \n                              :\n                              1\n                              \u2264\n                              i\n                              \u2264\n                              n\n                               such that \n                              w\n                              \u2209\n                              \n                                 \n                                    W\n                                 \n                                 \n                                    i\n                                 \n                              \n                              }\n                           . Indeed, using this betting scenario for the pessimistic aggregation, it becomes clearer that we are generalising Jaffray's betting framework.\n                              13\n                           \n                           \n                              13\n                              We are thankful to one reviewer for pointing us this issue.\n                           \n                        \n\nIt is easy to see that our assumption according to which at least one informative agent is not completely unreliable, i.e. that reliability maps are chosen in \n                        \n                           \n                              \u039b\n                           \n                           \n                              +\n                           \n                        \n                        (\n                        \n                           Ag\n                        \n                        )\n                     , forces the possibility distributions arising from the above Lemma 3.2 to belong to the class \n                        \n                           \n                              P\n                           \n                           \n                              +\n                           \n                        \n                        (\n                        W\n                        )\n                        =\n                        {\n                        \u03c0\n                        \u2208\n                        \n                           \n                              [\n                              0\n                              ,\n                              1\n                              ]\n                           \n                           \n                              W\n                           \n                        \n                        |\n                        \n                           \n                              max\n                           \n                           \n                              w\n                              \u2208\n                              W\n                           \n                        \n                        \u2061\n                        \u03c0\n                        (\n                        w\n                        )\n                        >\n                        0\n                        }\n                     .\n\nWe now introduce the three notions of coherence which arise in our generalised betting methods when instantiating the coherence in the aggregate considering criterion (13) with the threefold definition of aggregation given above. For each of them we will prove a characterisation result in terms of three corresponding generalised uncertainty measures for MV-algebras of events: plausibility functions, belief functions, and states.\n\n\n                     \n                        Definition 3.4\n                        Coherence in the aggregate\n\n\n                        Let \n                              {\n                              \n                                 \n                                    e\n                                 \n                                 \n                                    1\n                                 \n                              \n                              ,\n                              \u2026\n                              ,\n                              \n                                 \n                                    e\n                                 \n                                 \n                                    k\n                                 \n                              \n                              }\n                            be events, and let \n                              \u03b2\n                              :\n                              \n                                 \n                                    e\n                                 \n                                 \n                                    i\n                                 \n                              \n                              \u21a6\n                              \n                                 \n                                    \u03b2\n                                 \n                                 \n                                    i\n                                 \n                              \n                            be the book of interest. If for every \n                              \n                                 \n                                    \u03c3\n                                 \n                                 \n                                    1\n                                 \n                              \n                              ,\n                              \u2026\n                              ,\n                              \n                                 \n                                    \u03c3\n                                 \n                                 \n                                    n\n                                 \n                              \n                              \u2208\n                              R\n                           , there exists an evaluating triple \n                              E\n                            such that:\n                              \n                                 1.\n                                 \n                                    \n                                       \n                                          \n                                             \u2211\n                                          \n                                          \n                                             i\n                                             =\n                                             1\n                                          \n                                          \n                                             k\n                                          \n                                       \n                                       \n                                          \n                                             \u03c3\n                                          \n                                          \n                                             i\n                                          \n                                       \n                                       (\n                                       \n                                          \n                                             \u03b2\n                                          \n                                          \n                                             i\n                                          \n                                       \n                                       \u2212\n                                       \n                                          \n                                             N\n                                          \n                                          \n                                             E\n                                          \n                                       \n                                       (\n                                       \n                                          \n                                             e\n                                          \n                                          \n                                             i\n                                          \n                                       \n                                       )\n                                       )\n                                       \u2265\n                                       0\n                                    , then the book \u03b2 is said to be pessimistically coherent,\n\n\n                                    \n                                       \n                                          \n                                             \u2211\n                                          \n                                          \n                                             i\n                                             =\n                                             1\n                                          \n                                          \n                                             k\n                                          \n                                       \n                                       \n                                          \n                                             \u03c3\n                                          \n                                          \n                                             i\n                                          \n                                       \n                                       (\n                                       \n                                          \n                                             \u03b2\n                                          \n                                          \n                                             i\n                                          \n                                       \n                                       \u2212\n                                       \n                                          \n                                             \u03a0\n                                          \n                                          \n                                             E\n                                          \n                                       \n                                       (\n                                       \n                                          \n                                             e\n                                          \n                                          \n                                             i\n                                          \n                                       \n                                       )\n                                       )\n                                       \u2265\n                                       0\n                                    , then the book \u03b2 is said to be optimistically coherent,\n\n\n                                    \n                                       \n                                          \n                                             \u2211\n                                          \n                                          \n                                             i\n                                             =\n                                             1\n                                          \n                                          \n                                             k\n                                          \n                                       \n                                       \n                                          \n                                             \u03c3\n                                          \n                                          \n                                             i\n                                          \n                                       \n                                       (\n                                       \n                                          \n                                             \u03b2\n                                          \n                                          \n                                             i\n                                          \n                                       \n                                       \u2212\n                                       \n                                          \n                                             M\n                                          \n                                          \n                                             E\n                                          \n                                       \n                                       (\n                                       \n                                          \n                                             e\n                                          \n                                          \n                                             i\n                                          \n                                       \n                                       )\n                                       )\n                                       \u2265\n                                       0\n                                    , then the book \u03b2 is said to be coherent in the average,\n\n\n                     \n                        Remark 3.5\n                        If we let the evaluating triple \n                              E\n                            vary, then the MV-algebra generated by the functions \n                              \n                                 \n                                    N\n                                 \n                                 \n                                    E\n                                 \n                              \n                            is exactly \n                              R\n                              (\n                              W\n                              )\n                            (recall Subsection 2.3).\n\n\n                     \n                        Lemma 3.6\n                        \n                           Let \n                           \n                              {\n                              \n                                 \n                                    e\n                                 \n                                 \n                                    1\n                                 \n                              \n                              ,\n                              \u2026\n                              ,\n                              \n                                 \n                                    e\n                                 \n                                 \n                                    k\n                                 \n                              \n                              }\n                            \n                           be events and \n                           \n                              \u03b2\n                              :\n                              \n                                 \n                                    e\n                                 \n                                 \n                                    i\n                                 \n                              \n                              \u21a6\n                              \n                                 \n                                    \u03b2\n                                 \n                                 \n                                    i\n                                 \n                              \n                            \n                           be a book. The following are equivalent\n                           \n                              \n                                 1.\n                                 \n                                    There exists a belief function \n                                    \n                                       \n                                          Bel\n                                       \n                                       :\n                                       \n                                          \n                                             [\n                                             0\n                                             ,\n                                             1\n                                             ]\n                                          \n                                          \n                                             W\n                                          \n                                       \n                                       \u2192\n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                     \n                                    such that \n                                    \n                                       \n                                          Bel\n                                       \n                                       (\n                                       \n                                          \n                                             e\n                                          \n                                          \n                                             i\n                                          \n                                       \n                                       )\n                                       =\n                                       \n                                          \n                                             \u03b2\n                                          \n                                          \n                                             i\n                                          \n                                       \n                                       ,\n                                       i\n                                       =\n                                       1\n                                       ,\n                                       \u2026\n                                       ,\n                                       k\n                                    \n                                    .\n                                 \n\n\n                                    For all \n                                    \n                                       \n                                          \n                                             \u03c3\n                                          \n                                          \n                                             1\n                                          \n                                       \n                                       ,\n                                       \u2026\n                                       ,\n                                       \n                                          \n                                             \u03c3\n                                          \n                                          \n                                             k\n                                          \n                                       \n                                       \u2208\n                                       R\n                                    \n                                    , there exists an MV-homomorphism \n                                    \n                                       h\n                                       \u2208\n                                       H\n                                       (\n                                       R\n                                       (\n                                       W\n                                       )\n                                       ,\n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                       )\n                                     \n                                    such that\n                                    \n                                       \n                                          \n                                             \n                                                \u2211\n                                                \n                                                   i\n                                                   =\n                                                   1\n                                                \n                                                k\n                                             \n                                             \n                                                \n                                                   \u03c3\n                                                \n                                                \n                                                   i\n                                                \n                                             \n                                             \n                                                (\n                                                \n                                                   \n                                                      \u03b2\n                                                   \n                                                   \n                                                      i\n                                                   \n                                                \n                                                \u2212\n                                                h\n                                                (\n                                                \n                                                   \n                                                      \u03c1\n                                                   \n                                                   \n                                                      \n                                                         \n                                                            e\n                                                         \n                                                         \n                                                            i\n                                                         \n                                                      \n                                                   \n                                                \n                                                )\n                                                )\n                                             \n                                             \u2265\n                                             0\n                                             .\n                                          \n                                       \n                                    \n                                 \n\n\n                     \n                        Proof\n                        A map \n                              \n                                 Bel\n                              \n                              :\n                              \n                                 \n                                    [\n                                    0\n                                    ,\n                                    1\n                                    ]\n                                 \n                                 \n                                    W\n                                 \n                              \n                              \u2192\n                              [\n                              0\n                              ,\n                              1\n                              ]\n                            is a belief function extending \u03b2 iff, by definition, there exists a state \n                              s\n                              :\n                              R\n                              (\n                              W\n                              )\n                              \u2192\n                              [\n                              0\n                              ,\n                              1\n                              ]\n                            such that, for all \n                              i\n                              =\n                              1\n                              ,\n                              \u2026\n                              ,\n                              k\n                           , \n                              s\n                              (\n                              \n                                 \n                                    \u03c1\n                                 \n                                 \n                                    \n                                       \n                                          e\n                                       \n                                       \n                                          i\n                                       \n                                    \n                                 \n                              \n                              )\n                              =\n                              \n                                 \n                                    \u03b2\n                                 \n                                 \n                                    i\n                                 \n                              \n                            iff, by Theorem 2.3, the book \n                              \n                                 \n                                    \u03b2\n                                 \n                                 \n                                    \u2032\n                                 \n                              \n                              :\n                              \n                                 \n                                    \u03c1\n                                 \n                                 \n                                    \n                                       \n                                          e\n                                       \n                                       \n                                          i\n                                       \n                                    \n                                 \n                              \n                              \u21a6\n                              \n                                 \n                                    \u03b2\n                                 \n                                 \n                                    i\n                                 \n                              \n                            is state coherent, iff, by definition, for all \n                              \n                                 \n                                    \u03c3\n                                 \n                                 \n                                    1\n                                 \n                              \n                              ,\n                              \u2026\n                              ,\n                              \n                                 \n                                    \u03c3\n                                 \n                                 \n                                    k\n                                 \n                              \n                              \u2208\n                              R\n                           , there exists an \n                              h\n                              \u2208\n                              H\n                              (\n                              R\n                              (\n                              W\n                              )\n                              ,\n                              [\n                              0\n                              ,\n                              1\n                              ]\n                              )\n                            such that \n                              \n                                 \n                                    \u2211\n                                 \n                                 \n                                    i\n                                    =\n                                    1\n                                 \n                                 \n                                    k\n                                 \n                              \n                              \n                                 \n                                    \u03c3\n                                 \n                                 \n                                    i\n                                 \n                              \n                              (\n                              \n                                 \n                                    \u03b2\n                                 \n                                 \n                                    i\n                                 \n                              \n                              \u2212\n                              h\n                              (\n                              \n                                 \n                                    \u03c1\n                                 \n                                 \n                                    \n                                       \n                                          e\n                                       \n                                       \n                                          i\n                                       \n                                    \n                                 \n                              \n                              )\n                              )\n                              \u2265\n                              0\n                           . Hence our claim is settled. \u2003\u25a1\n\nFinally, we are now in a position to prove the main result of this paper, which provides a threefold characterisation of coherence arising from the betting method informally introduced in Section 1 and made precise in this section.\n\n\n                     \n                        Theorem 3.7\n                        Main Theorem\n\n\n                        \n                           Let \n                           \n                              {\n                              \n                                 \n                                    e\n                                 \n                                 \n                                    1\n                                 \n                              \n                              ,\n                              \u2026\n                              ,\n                              \n                                 \n                                    e\n                                 \n                                 \n                                    k\n                                 \n                              \n                              }\n                            \n                           be events and \n                           \n                              \u03b2\n                              :\n                              \n                                 \n                                    e\n                                 \n                                 \n                                    i\n                                 \n                              \n                              \u21a6\n                              \n                                 \n                                    \u03b2\n                                 \n                                 \n                                    i\n                                 \n                              \n                            \n                           be a book. Then the following conditions hold:\n                           \n                              \n                                 1.\n                                 \n                                    \u03b2 is pessimistically coherent iff there exists a belief function \n                                    \n                                       \n                                          Bel\n                                       \n                                       :\n                                       \n                                          \n                                             [\n                                             0\n                                             ,\n                                             1\n                                             ]\n                                          \n                                          \n                                             W\n                                          \n                                       \n                                       \u2192\n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                     \n                                    such that \n                                    \n                                       \n                                          Bel\n                                       \n                                       (\n                                       \n                                          \n                                             e\n                                          \n                                          \n                                             i\n                                          \n                                       \n                                       )\n                                       =\n                                       \n                                          \n                                             \u03b2\n                                          \n                                          \n                                             i\n                                          \n                                       \n                                    \n                                    , for \n                                    \n                                       i\n                                       =\n                                       1\n                                       ,\n                                       \u2026\n                                       ,\n                                       k\n                                    \n                                    ,\n                                 \n\n\n                                    \u03b2 is optimistically coherent iff there exists a plausibility function \n                                    \n                                       \n                                          Pl\n                                       \n                                       :\n                                       \n                                          \n                                             [\n                                             0\n                                             ,\n                                             1\n                                             ]\n                                          \n                                          \n                                             W\n                                          \n                                       \n                                       \u2192\n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                     \n                                    such that \n                                    \n                                       \n                                          Pl\n                                       \n                                       (\n                                       \n                                          \n                                             e\n                                          \n                                          \n                                             i\n                                          \n                                       \n                                       )\n                                       =\n                                       \n                                          \n                                             \u03b2\n                                          \n                                          \n                                             i\n                                          \n                                       \n                                    \n                                    , for \n                                    \n                                       i\n                                       =\n                                       1\n                                       ,\n                                       \u2026\n                                       ,\n                                       k\n                                    \n                                    ,\n                                 \n\n\n                                    \u03b2 is coherent in the average iff \u03b2 is state coherent.\n                                 \n\n\n                     \n                        Proof\n                        See Appendix B. \u2003\u25a1\n\nThe threefold criterion of coherence in the aggregate presupposes that an oracle \n                        O\n                      is choosing a reliability map among all the possible ones, i.e. in the whole class \n                        \n                           \n                              \u039b\n                           \n                           \n                              +\n                           \n                        \n                        (\n                        \n                           Ag\n                        \n                        )\n                        =\n                        {\n                        \u03b7\n                        :\n                        \n                           Ag\n                        \n                        \u2192\n                        [\n                        0\n                        ,\n                        1\n                        ]\n                        |\n                        there exists \n                        a\n                        \u2208\n                        \n                           Ag\n                        \n                        ,\n                        \u03b7\n                        (\n                        a\n                        )\n                        >\n                        0\n                        }\n                     . However it may be desirable to capture the extra information that bookmaker and gambler may possess the reliability of the informative agents. So, instead of belonging to the whole set \n                        \n                           \n                              \u039b\n                           \n                           \n                              +\n                           \n                        \n                        (\n                        \n                           Ag\n                        \n                        )\n                     , the reliability degrees attributed to the individual informative agents may be chosen among specified subsets. This section investigates how suitable restrictions to \n                        \n                           \n                              \u039b\n                           \n                           \n                              +\n                           \n                        \n                        (\n                        \n                           Ag\n                        \n                        )\n                      give rise to interesting classes of belief functions.\n\nBuilding again on the idea behind the Global Health Agency example of Section 1, it is quite natural to consider betting problems in which B and G agree to bet only when the reliability of informative agents is characterised by one of the following conditions:\n                        \n                           \u2022\n                           \n                              \n                                 \n                                    \n                                       \u039b\n                                    \n                                    \n                                       N\n                                    \n                                 \n                                 (\n                                 \n                                    Ag\n                                 \n                                 )\n                               is the set of reliability assignments \u03b7 on Ag which corresponds to the assumption that at least one agent is completely reliable, in other words \n                                 \u03b7\n                                 (\n                                 a\n                                 )\n                                 =\n                                 1\n                               for some \n                                 a\n                                 \u2208\n                                 \n                                    Ag\n                                 \n                               and hence \n                                 \n                                    \n                                       \u03b7\n                                    \n                                    \n                                       a\n                                    \n                                 \n                                 =\n                                 1\n                              ;\n\n\n                              \n                                 \n                                    \n                                       \u039b\n                                    \n                                    \n                                       C\n                                    \n                                 \n                                 (\n                                 \n                                    Ag\n                                 \n                                 )\n                               is the set of reliability assignments \u03b7 on Ag corresponding to the assumption that at least one agent is completely reliable, as in the previous case, and further that the others are completely unreliable, that is assignments satisfying \n                                 \u03b7\n                                 (\n                                 a\n                                 )\n                                 \u2208\n                                 {\n                                 0\n                                 ,\n                                 1\n                                 }\n                               for every \n                                 a\n                                 \u2208\n                                 \n                                    Ag\n                                 \n                              .\n\nFinally, \n                                 \n                                    \n                                       \u039b\n                                    \n                                    \n                                       D\n                                    \n                                 \n                                 (\n                                 \n                                    Ag\n                                 \n                                 )\n                               is the set of reliability assignments \u03b7 on Ag arising from the assumption that there exists exactly one agent which is completely reliable, and the others are completely unreliable. This means, it consists of assignments \u03b7 such that there exists \n                                 a\n                                 \u2208\n                                 \n                                    Ag\n                                 \n                               with \n                                 \u03b7\n                                 (\n                                 a\n                                 )\n                                 =\n                                 1\n                              , and \n                                 \u03b7\n                                 (\n                                 b\n                                 )\n                                 =\n                                 0\n                               for all \n                                 b\n                                 \u2260\n                                 a\n                              .\n\n\n                     \n                        Lemma 4.1\n                        \n                           Let \n                           \n                              E\n                              =\n                              (\n                              \n                                 Ag\n                              \n                              ,\n                              \n                                 w\n                                 \u00af\n                              \n                              ,\n                              \u03b7\n                              )\n                            \n                           be an evaluation tripe, and let \n                           \n                              \u03c0\n                              \u2208\n                              \n                                 \n                                    P\n                                 \n                                 \n                                    +\n                                 \n                              \n                              (\n                              W\n                              )\n                            \n                           as arising from \n                           \n                              Lemma 3.2\n                           \n                           , i.e. defined as \n                           \n                              \u03c0\n                              (\n                              w\n                              )\n                              =\n                              max\n                              \u2061\n                              {\n                              \u03b7\n                              (\n                              a\n                              )\n                              |\n                              a\n                              \u2208\n                              \n                                 Ag\n                              \n                               \n                                 such that \n                              \n                              \n                                 \n                                    w\n                                 \n                                 \n                                    a\n                                 \n                              \n                              =\n                              w\n                              }\n                           \n                           , for every \n                           \n                              w\n                              \u2208\n                              W\n                           \n                           . The following hold:\n                           \n                              \n                                 1.\n                                 \n                                    if \n                                    \n                                       \u03b7\n                                       \u2208\n                                       \n                                          \n                                             \u039b\n                                          \n                                          \n                                             N\n                                          \n                                       \n                                       (\n                                       \n                                          Ag\n                                       \n                                       )\n                                     \n                                    then \u03c0 is normalised, that is, there is a \n                                    \n                                       w\n                                       \u2208\n                                       W\n                                     \n                                    such that \n                                    \n                                       \u03c0\n                                       (\n                                       w\n                                       )\n                                       =\n                                       1\n                                    \n                                    ,\n                                 \n\n\n                                    if \n                                    \n                                       \u03b7\n                                       \u2208\n                                       \n                                          \n                                             \u039b\n                                          \n                                          \n                                             C\n                                          \n                                       \n                                       (\n                                       \n                                          Ag\n                                       \n                                       )\n                                     \n                                    then \u03c0 is classical, that is \n                                    \n                                       \u03c0\n                                       (\n                                       w\n                                       )\n                                       \u2208\n                                       {\n                                       0\n                                       ,\n                                       1\n                                       }\n                                     \n                                    for every \n                                    \n                                       w\n                                       \u2208\n                                       W\n                                    \n                                    ,\n                                 \n\n\n                                    if \n                                    \n                                       \u03b7\n                                       \u2208\n                                       \n                                          \n                                             \u039b\n                                          \n                                          \n                                             D\n                                          \n                                       \n                                       (\n                                       \n                                          Ag\n                                       \n                                       )\n                                     \n                                    then \u03c0 is drastic, that is there is a unique \n                                    \n                                       \n                                          \n                                             w\n                                          \n                                          \n                                             0\n                                          \n                                       \n                                       \u2208\n                                       W\n                                     \n                                    such that \n                                    \n                                       \u03c0\n                                       (\n                                       \n                                          \n                                             w\n                                          \n                                          \n                                             0\n                                          \n                                       \n                                       )\n                                       =\n                                       1\n                                    \n                                    , and \n                                    \n                                       \u03c0\n                                       (\n                                       w\n                                       )\n                                       =\n                                       0\n                                     \n                                    for all \n                                    \n                                       w\n                                       \u2260\n                                       \n                                          \n                                             w\n                                          \n                                          \n                                             0\n                                          \n                                       \n                                    \n                                    .\n                                 \n\nFinally, it is useful to have the following notation for relevant classes of possibility distributions on W:\n                        \n                           \u2013\n                           \n                              \n                                 N\n                                 (\n                                 W\n                                 )\n                                 =\n                                 {\n                                 \u03c0\n                                 \u2208\n                                 \n                                    \n                                       P\n                                    \n                                    \n                                       +\n                                    \n                                 \n                                 (\n                                 W\n                                 )\n                                 |\n                                 \u2203\n                                 x\n                                 \u2208\n                                 W\n                                 ,\n                                 \u03c0\n                                 (\n                                 x\n                                 )\n                                 =\n                                 1\n                                 }\n                              , which we call the set of normalised possibility distributions.\n\n\n                              \n                                 C\n                                 (\n                                 W\n                                 )\n                                 =\n                                 {\n                                 \u03c0\n                                 \u2208\n                                 N\n                                 (\n                                 W\n                                 )\n                                 |\n                                 \u2200\n                                 x\n                                 \u2208\n                                 W\n                                 ,\n                                 \u03c0\n                                 (\n                                 x\n                                 )\n                                 =\n                                 1\n                                  or \n                                 \u03c0\n                                 (\n                                 x\n                                 )\n                                 =\n                                 0\n                                 }\n                              , which we call the set of classical (or crisp) possibility distributions, and finally\n\n\n                              \n                                 D\n                                 (\n                                 W\n                                 )\n                                 =\n                                 {\n                                 \u03c0\n                                 \u2208\n                                 C\n                                 (\n                                 W\n                                 )\n                                 |\n                                 \u2203\n                                 !\n                                 x\n                                 \u2208\n                                 W\n                                 ,\n                                 \u03c0\n                                 (\n                                 x\n                                 )\n                                 =\n                                 1\n                                 }\n                              , which we call the class of drastic possibility distributions.\n\nWe are now ready to formulate three refinements of the notion of pessimistic coherence each arising from the three kinds of restriction imposed on the classes of reliability assignments or possibility distributions.\n\n\n                     \n                        Definition 4.2\n                        Refined pessimistic coherence\n\n\n                        Let \n                              {\n                              \n                                 \n                                    e\n                                 \n                                 \n                                    1\n                                 \n                              \n                              ,\n                              \u2026\n                              ,\n                              \n                                 \n                                    e\n                                 \n                                 \n                                    k\n                                 \n                              \n                              }\n                            be events, and let \n                              \u03b2\n                              :\n                              \n                                 \n                                    e\n                                 \n                                 \n                                    i\n                                 \n                              \n                              \u21a6\n                              \n                                 \n                                    \u03b2\n                                 \n                                 \n                                    i\n                                 \n                              \n                            be a pessimistically coherent book. Then \u03b2 is said to be \n                              N\n                           \n                           - (resp. \n                           \n                              C\n                           \n                           -, \n                           \n                              D\n                           \n                           -) pessimistically coherent if there exists an evaluating triple \n                              E\n                              =\n                              (\n                              \n                                 Ag\n                              \n                              ,\n                              \n                                 w\n                                 \u00af\n                              \n                              ,\n                              \u03b7\n                              )\n                            with \n                              \u03b7\n                              \u2208\n                              \n                                 \n                                    \u039b\n                                 \n                                 \n                                    N\n                                 \n                              \n                              (\n                              \n                                 Ag\n                              \n                              )\n                            (resp. \n                              \u03b7\n                              \u2208\n                              \n                                 \n                                    \u039b\n                                 \n                                 \n                                    C\n                                 \n                              \n                              (\n                              \n                                 Ag\n                              \n                              )\n                           , \n                              \u03b7\n                              \u2208\n                              \n                                 \n                                    \u039b\n                                 \n                                 \n                                    D\n                                 \n                              \n                              (\n                              \n                                 Ag\n                              \n                              )\n                           ) such that \n                              \n                                 \n                                    \u2211\n                                 \n                                 \n                                    i\n                                    =\n                                    1\n                                 \n                                 \n                                    k\n                                 \n                              \n                              \n                                 \n                                    \u03c3\n                                 \n                                 \n                                    i\n                                 \n                              \n                              (\n                              \n                                 \n                                    \u03b2\n                                 \n                                 \n                                    i\n                                 \n                              \n                              \u2212\n                              \n                                 \n                                    N\n                                 \n                                 \n                                    E\n                                 \n                              \n                              (\n                              \n                                 \n                                    e\n                                 \n                                 \n                                    i\n                                 \n                              \n                              )\n                              )\n                              \u2265\n                              0\n                           .\n\nFor the sake of a simpler notation, in the remainder of this section we will rely heavily on Lemma 3.2 and Lemma 4.1 which allow us to identify evaluating triples with possibility distributions.\n\nLet \n                        S\n                        (\n                        W\n                        )\n                      be a Borel subset of \n                        \n                           \n                              P\n                           \n                           \n                              +\n                           \n                        \n                        (\n                        W\n                        )\n                     . Note that \n                        N\n                        (\n                        W\n                        )\n                        ,\n                        C\n                        (\n                        W\n                        )\n                     , and \n                        D\n                        (\n                        W\n                        )\n                      are Borel subsets of \n                        \n                           \n                              P\n                           \n                           \n                              +\n                           \n                        \n                        (\n                        W\n                        )\n                      since they are compact subsets of \n                        \n                           \n                              [\n                              0\n                              ,\n                              1\n                              ]\n                           \n                           \n                              W\n                           \n                        \n                     . Then we will denote by \n                        \n                           \n                              Bel\n                           \n                           \n                              S\n                           \n                        \n                      any belief function on \n                        \n                           \n                              [\n                              0\n                              ,\n                              1\n                              ]\n                           \n                           \n                              W\n                           \n                        \n                     \n                     \n                        \n                           (16)\n                           \n                              \n                                 \n                                    Bel\n                                 \n                                 \n                                    S\n                                 \n                              \n                              (\n                              \u22c5\n                              )\n                              =\n                              \n                                 \u222b\n                                 \n                                    \n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                    \n                                    \n                                       W\n                                    \n                                 \n                              \n                              \n                                 \n                                    \u03c1\n                                 \n                                 \n                                    (\n                                    \u22c5\n                                    )\n                                 \n                              \n                              \n                              d\n                              \n                                 \n                                    \u03bc\n                                 \n                                 \n                                    S\n                                 \n                              \n                           \n                        \n                      whose state assignment has an integral representation given by a \n                        \n                           \n                              \u03bc\n                           \n                           \n                              S\n                           \n                        \n                        :\n                        B\n                        (\n                        \n                           \n                              [\n                              0\n                              ,\n                              1\n                              ]\n                           \n                           \n                              W\n                           \n                        \n                        )\n                        \u2192\n                        [\n                        0\n                        ,\n                        1\n                        ]\n                      such that\n                        \n                           \n                              spt\n                              \n                              \n                                 (\n                                 \n                                    \n                                       \u03bc\n                                    \n                                    \n                                       S\n                                    \n                                 \n                                 )\n                              \n                              =\n                              S\n                              (\n                              W\n                              )\n                              .\n                           \n                        \n                      Hence \n                        \n                           \n                              \u03bc\n                           \n                           \n                              S\n                           \n                        \n                        (\n                        J\n                        )\n                        =\n                        0\n                      for all \n                        J\n                        \u2208\n                        B\n                        (\n                        \n                           \n                              [\n                              0\n                              ,\n                              1\n                              ]\n                           \n                           \n                              W\n                           \n                        \n                        )\n                      such that \n                        J\n                        \u2229\n                        S\n                        (\n                        W\n                        )\n                        =\n                        \u2205\n                     .\n\n\n                     \n                        Lemma 4.3\n                        \n                           Let \n                           \n                              \n                                 \n                                    e\n                                 \n                                 \n                                    1\n                                 \n                              \n                              ,\n                              \u2026\n                              ,\n                              \n                                 \n                                    e\n                                 \n                                 \n                                    k\n                                 \n                              \n                            \n                           be events, \n                           \n                              \u03b2\n                              :\n                              \n                                 \n                                    e\n                                 \n                                 \n                                    i\n                                 \n                              \n                              \u21a6\n                              \n                                 \n                                    \u03b2\n                                 \n                                 \n                                    i\n                                 \n                              \n                            \n                           a book and let \n                           \n                              S\n                              \u2208\n                              {\n                              \n                                 N\n                                 ,\n                                 C\n                                 ,\n                                 D\n                              \n                              }\n                           \n                           . Then \u03b2 is \n                           \n                              S\n                           \n                           -pessimistic coherent iff there is a \n                           \n                              \n                                 \n                                    Bel\n                                 \n                                 \n                                    S\n                                 \n                              \n                            \n                           extending \u03b2.\n                        \n\n\n                     \n                        Proof\n                        See Appendix B. \u2003\u25a1\n\n\n                     \n                        Remark 4.4\n                        Suppose the events \n                              \n                                 \n                                    e\n                                 \n                                 \n                                    1\n                                 \n                              \n                              ,\n                              \u2026\n                              ,\n                              \n                                 \n                                    e\n                                 \n                                 \n                                    k\n                                 \n                              \n                            in the previous Lemma 4.3 are functions from a finite set W into \n                              [\n                              0\n                              ,\n                              1\n                              ]\n                              \u2229\n                              Q\n                           , the rational unit interval. In particular, for each \n                              \n                                 \n                                    e\n                                 \n                                 \n                                    i\n                                 \n                              \n                           , let \n                              \n                                 \n                                    d\n                                 \n                                 \n                                    i\n                                 \n                              \n                            be the least common divisor of all the denominators of \n                              \n                                 \n                                    e\n                                 \n                                 \n                                    i\n                                 \n                              \n                              (\n                              x\n                              )\n                            (for \n                              x\n                              \u2208\n                              W\n                           ), and let m be the least common divisor of \n                              \n                                 \n                                    d\n                                 \n                                 \n                                    1\n                                 \n                              \n                              ,\n                              \u2026\n                              ,\n                              \n                                 \n                                    d\n                                 \n                                 \n                                    k\n                                 \n                              \n                           . Then, the \n                              \n                                 \n                                    e\n                                 \n                                 \n                                    i\n                                 \n                              \n                           's can be regarded, without loss of generality, as functions from W into the finite MV-chain having domain \n                              \n                                 \n                                    S\n                                 \n                                 \n                                    m\n                                 \n                              \n                              =\n                              {\n                              0\n                              ,\n                              1\n                              /\n                              m\n                              ,\n                              \u2026\n                              ,\n                              (\n                              m\n                              \u2212\n                              1\n                              )\n                              /\n                              m\n                              ,\n                              1\n                              }\n                           . In this case, the set \n                              \n                                 \n                                    P\n                                 \n                                 \n                                    +\n                                 \n                              \n                              (\n                              W\n                              )\n                            of all non-zero possibility distributions \n                              \u03c0\n                              :\n                              W\n                              \u2192\n                              \n                                 \n                                    S\n                                 \n                                 \n                                    m\n                                 \n                              \n                            is finite, and hence so is each \n                              S\n                              (\n                              W\n                              )\n                           . Therefore, the belief function \n                              \n                                 \n                                    Bel\n                                 \n                                 \n                                    S\n                                 \n                              \n                              :\n                              \n                                 \n                                    S\n                                 \n                                 \n                                    m\n                                 \n                                 \n                                    W\n                                 \n                              \n                              \u2192\n                              [\n                              0\n                              ,\n                              1\n                              ]\n                            can be written as follows: for all \n                              f\n                              \u2208\n                              \n                                 \n                                    S\n                                 \n                                 \n                                    m\n                                 \n                                 \n                                    W\n                                 \n                              \n                           ,\n                              \n                                 \n                                    \n                                       \n                                          Bel\n                                       \n                                       \n                                          S\n                                       \n                                    \n                                    (\n                                    f\n                                    )\n                                    =\n                                    \n                                       \u2211\n                                       \n                                          \u03c0\n                                          \u2208\n                                          \n                                             \n                                                S\n                                             \n                                             \n                                                m\n                                             \n                                             \n                                                W\n                                             \n                                          \n                                       \n                                    \n                                    \n                                       \n                                          \u03c1\n                                       \n                                       \n                                          f\n                                       \n                                    \n                                    (\n                                    \u03c0\n                                    )\n                                    \u22c5\n                                    \n                                       \n                                          \u03bc\n                                       \n                                       \n                                          S\n                                       \n                                    \n                                    \n                                       (\n                                       {\n                                       \u03c0\n                                       }\n                                       )\n                                    \n                                    .\n                                    \n                                       \n                                          14\n                                       \n                                    \n                                 \n                              \n                            Therefore, since \n                              \n                                 \n                                    \u03bc\n                                 \n                                 \n                                    S\n                                 \n                              \n                              (\n                              {\n                              \u03c0\n                              }\n                              )\n                              =\n                              0\n                            if \n                              \u03c0\n                              \u2209\n                              S\n                              (\n                              W\n                              )\n                           , it is reasonable to think of \n                              S\n                              (\n                              W\n                              )\n                            as the set to which the focal elements of \n                              \n                                 \n                                    Bel\n                                 \n                                 \n                                    S\n                                 \n                              \n                            belong. Indeed, recalling Definition 2.8, it is easy to see that, in this particular case, \n                              S\n                              (\n                              W\n                              )\n                              \u2287\n                              spt\n                              (\n                              \n                                 \n                                    \u03bc\n                                 \n                                 \n                                    S\n                                 \n                              \n                              )\n                           . Obviously, the condition of being in \n                              S\n                              (\n                              W\n                              )\n                            is necessary but not sufficient for \u03c0 to be a focal element. In fact, it does not hold in general that \n                              \n                                 \n                                    \u03bc\n                                 \n                                 \n                                    S\n                                 \n                              \n                              (\n                              {\n                              \u03c0\n                              }\n                              )\n                              >\n                              0\n                            \n                           iff \n                           \n                              \u03c0\n                              \u2208\n                              S\n                              (\n                              W\n                              )\n                           .\n\n\n                           Let \n                           \n                              \n                                 \n                                    e\n                                 \n                                 \n                                    1\n                                 \n                              \n                              ,\n                              \u2026\n                              ,\n                              \n                                 \n                                    e\n                                 \n                                 \n                                    k\n                                 \n                              \n                            \n                           be events and let \n                           \n                              \u03b2\n                              :\n                              \n                                 \n                                    e\n                                 \n                                 \n                                    i\n                                 \n                              \n                              \u21a6\n                              \n                                 \n                                    \u03b2\n                                 \n                                 \n                                    i\n                                 \n                              \n                            \n                           be a book. Then:\n                           \n                              \n                                 1.\n                                 \n                                    \u03b2 is \n                                    \n                                       N\n                                    \n                                    -pessimistically coherent iff there exists a normalised belief function \n                                    \n                                       \n                                          Bel\n                                       \n                                       :\n                                       \n                                          \n                                             [\n                                             0\n                                             ,\n                                             1\n                                             ]\n                                          \n                                          \n                                             W\n                                          \n                                       \n                                       \u2192\n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                     \n                                    which extends \u03b2.\n                                 \n\n\n                                    \u03b2 is \n                                    \n                                       C\n                                    \n                                    -pessimistically coherent iff there exists a crisp-focal belief function \n                                    \n                                       \n                                          Bel\n                                       \n                                       :\n                                       \n                                          \n                                             [\n                                             0\n                                             ,\n                                             1\n                                             ]\n                                          \n                                          \n                                             W\n                                          \n                                       \n                                       \u2192\n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                     \n                                    which extends \u03b2.\n                                 \n\n\n                                    \u03b2 is \n                                    \n                                       D\n                                    \n                                    -pessimistically coherent iff there exists a state \n                                    \n                                       s\n                                       :\n                                       \n                                          \n                                             [\n                                             0\n                                             ,\n                                             1\n                                             ]\n                                          \n                                          \n                                             W\n                                          \n                                       \n                                       \u2192\n                                       [\n                                       0\n                                       ,\n                                       1\n                                       ]\n                                     \n                                    which extends \u03b2.\n                                 \n\nFor any \n                              S\n                              \u2208\n                              {\n                              \n                                 N\n                                 ,\n                                 C\n                                 ,\n                                 D\n                              \n                              }\n                           , from Lemma 4.3 \n                           \u03b2 is \n                              S\n                           -pessimistic coherent iff the belief function \n                              \n                                 \n                                    Bel\n                                 \n                                 \n                                    S\n                                 \n                              \n                              (\n                              \u22c5\n                              )\n                            defined as in (16) extends \u03b2.\n\n\n                           \n                              14\n                              We invite the reader to check [14, Remark 4.10] for further details.\n                           \n                        \n\nWe now consider each case in turn:\n\n1. Assume that \n                              S\n                              =\n                              N\n                           . Then, \n                              \n                                 \n                                    \u03c1\n                                 \n                                 \n                                    \n                                       0\n                                       \u00af\n                                    \n                                 \n                                 \n                                    N\n                                 \n                              \n                              :\n                              \n                                 \n                                    P\n                                 \n                                 \n                                    +\n                                 \n                              \n                              (\n                              W\n                              )\n                              \u2192\n                              [\n                              0\n                              ,\n                              1\n                              ]\n                            maps each \n                              \u03c0\n                              \u2208\n                              \n                                 \n                                    P\n                                 \n                                 \n                                    +\n                                 \n                              \n                              (\n                              W\n                              )\n                            into 0 if \n                              \u03c0\n                              \u2209\n                              N\n                              (\n                              W\n                              )\n                           , and every \n                              \u03c0\n                              \u2208\n                              N\n                              (\n                              W\n                              )\n                            in\n                              \n                                 \n                                    inf\n                                    \u2061\n                                    \n                                       {\n                                       \u03c0\n                                       (\n                                       w\n                                       )\n                                       \u21d2\n                                       0\n                                       |\n                                       w\n                                       \u2208\n                                       W\n                                       }\n                                    \n                                    =\n                                    inf\n                                    \u2061\n                                    \n                                       {\n                                       \u00ac\n                                       \u03c0\n                                       (\n                                       w\n                                       )\n                                       |\n                                       w\n                                       \u2208\n                                       W\n                                       }\n                                    \n                                    .\n                                 \n                              \n                            Since \n                              \u03c0\n                              \u2208\n                              N\n                              (\n                              W\n                              )\n                            iff there is a \n                              w\n                              \u2208\n                              W\n                            such that \n                              \u03c0\n                              (\n                              w\n                              )\n                              =\n                              1\n                           , \n                              \n                                 \n                                    \u03c1\n                                 \n                                 \n                                    \n                                       0\n                                       \u00af\n                                    \n                                 \n                                 \n                                    N\n                                 \n                              \n                            is the zero constant function and hence \n                              \n                                 \n                                    Bel\n                                 \n                                 \n                                    N\n                                 \n                              \n                              (\n                              \n                                 0\n                                 \u00af\n                              \n                              )\n                              =\n                              s\n                              (\n                              \n                                 \n                                    \u03c1\n                                 \n                                 \n                                    \n                                       0\n                                       \u00af\n                                    \n                                 \n                                 \n                                    N\n                                 \n                              \n                              )\n                              =\n                              0\n                           . Hence \n                              \n                                 \n                                    Bel\n                                 \n                                 \n                                    N\n                                 \n                              \n                            is normalised.\n\n2. Assume \n                              S\n                              =\n                              C\n                           . Then, similarly to the above case, for every \n                              f\n                              \u2208\n                              \n                                 \n                                    [\n                                    0\n                                    ,\n                                    1\n                                    ]\n                                 \n                                 \n                                    W\n                                 \n                              \n                           , \n                              \n                                 \n                                    \u03c1\n                                 \n                                 \n                                    a\n                                 \n                                 \n                                    C\n                                 \n                              \n                            maps each \n                              \u03c0\n                              \u2208\n                              P\n                              (\n                              W\n                              )\n                            into 0 if \n                              \u03c0\n                              \u2209\n                              C\n                              (\n                              W\n                              )\n                            and if \n                              \u03c0\n                              \u2208\n                              C\n                              (\n                              W\n                              )\n                            into,\n                              \n                                 \n                                    \n                                       \n                                          \u03c1\n                                       \n                                       \n                                          f\n                                       \n                                       \n                                          C\n                                       \n                                    \n                                    (\n                                    \u03c0\n                                    )\n                                    =\n                                    inf\n                                    \u2061\n                                    \n                                       {\n                                       \u03c0\n                                       (\n                                       w\n                                       )\n                                       \u21d2\n                                       f\n                                       (\n                                       w\n                                       )\n                                       |\n                                       w\n                                       \u2208\n                                       W\n                                       }\n                                    \n                                    =\n                                    inf\n                                    \u2061\n                                    \n                                       {\n                                       f\n                                       (\n                                       w\n                                       )\n                                       |\n                                       \u03c0\n                                       (\n                                       w\n                                       )\n                                       =\n                                       1\n                                       }\n                                    \n                                    =\n                                    inf\n                                    \u2061\n                                    \n                                       {\n                                       f\n                                       (\n                                       w\n                                       )\n                                       |\n                                       w\n                                       \u2208\n                                       \u03c0\n                                       }\n                                    \n                                    =\n                                    \n                                       \n                                          \n                                             \n                                                \u03c1\n                                             \n                                             \n                                                \u02c6\n                                             \n                                          \n                                       \n                                       \n                                          f\n                                       \n                                    \n                                    (\n                                    \u03c0\n                                    )\n                                    .\n                                 \n                              \n                            Then the claim follows from Definition 2.4.\n\n3. If \n                              S\n                              =\n                              D\n                            then, since for every \n                              \u03c0\n                              \u2208\n                              D\n                              (\n                              W\n                              )\n                            there exists exactly one \n                              \n                                 \n                                    w\n                                 \n                                 \n                                    0\n                                 \n                              \n                              \u2208\n                              W\n                            for which \n                              \u03c0\n                              (\n                              \n                                 \n                                    w\n                                 \n                                 \n                                    0\n                                 \n                              \n                              )\n                              =\n                              1\n                            and \n                              \u03c0\n                              (\n                              w\n                              )\n                              =\n                              0\n                            for all \n                              w\n                              \u2260\n                              \n                                 \n                                    w\n                                 \n                                 \n                                    0\n                                 \n                              \n                           , we have:\n                              \n                                 \n                                    \n                                       \n                                          \u03c1\n                                       \n                                       \n                                          f\n                                       \n                                       \n                                          D\n                                       \n                                    \n                                    (\n                                    \u03c0\n                                    )\n                                    =\n                                    inf\n                                    \u2061\n                                    \n                                       {\n                                       \u03c0\n                                       (\n                                       w\n                                       )\n                                       \u21d2\n                                       f\n                                       (\n                                       w\n                                       )\n                                       |\n                                       w\n                                       \u2208\n                                       W\n                                       }\n                                    \n                                    =\n                                    f\n                                    (\n                                    \n                                       \n                                          w\n                                       \n                                       \n                                          0\n                                       \n                                    \n                                    )\n                                    .\n                                 \n                              \n                            Then, for all \n                              f\n                              \u2208\n                              \n                                 \n                                    [\n                                    0\n                                    ,\n                                    1\n                                    ]\n                                 \n                                 \n                                    W\n                                 \n                              \n                           , identifying possibility distributions from \n                              D\n                              (\n                              W\n                              )\n                            and elements from W, we have that \n                              \n                                 \n                                    \u03c1\n                                 \n                                 \n                                    f\n                                 \n                                 \n                                    D\n                                 \n                              \n                              (\n                              \u22c5\n                              )\n                              =\n                              f\n                              (\n                              \u22c5\n                              )\n                            and hence \n                              \n                                 \n                                    Bel\n                                 \n                                 \n                                    D\n                                 \n                              \n                              (\n                              f\n                              )\n                              =\n                              s\n                              (\n                              \n                                 \n                                    \u03c1\n                                 \n                                 \n                                    f\n                                 \n                                 \n                                    D\n                                 \n                              \n                              )\n                              =\n                              s\n                              (\n                              f\n                              )\n                           . \u2003\u25a1\n\nAs a direct consequence of the above Theorem 4.5 we obtain an alternative semantics for Jaffray's coherence under partially resolving uncertainty we discussed in Section 2.1. \n                        Corollary 4.6\n                        \n                           Let \n                           \n                              \n                                 \n                                    e\n                                 \n                                 \n                                    1\n                                 \n                              \n                              ,\n                              \u2026\n                              ,\n                              \n                                 \n                                    e\n                                 \n                                 \n                                    k\n                                 \n                              \n                            \n                           be two-valued events and let \n                           \n                              \u03b2\n                              :\n                              \n                                 \n                                    e\n                                 \n                                 \n                                    i\n                                 \n                              \n                              \u21a6\n                              \n                                 \n                                    \u03b2\n                                 \n                                 \n                                    i\n                                 \n                              \n                            \n                           be a book. Then \u03b2 is \n                           \n                              C\n                              (\n                              W\n                              )\n                           \n                           -coherent iff \u03b2 is coherent under partially resolving uncertainty.\n                        \n\nFrom Theorem 1.1, we just need to show that \u03b2 is \n                              C\n                           -pessimistically coherent iff there exists a classical belief function \n                              \n                                 Bel\n                              \n                              :\n                              \n                                 \n                                    2\n                                 \n                                 \n                                    W\n                                 \n                              \n                              \u2192\n                              [\n                              0\n                              ,\n                              1\n                              ]\n                            which extends \u03b2. From the above Theorem 4.5, \u03b2 is \n                              C\n                           -pessimistic coherent iff the exists a crisp-focal belief function \n                              \n                                 \n                                    Bel\n                                 \n                                 \n                                    \u2032\n                                 \n                              \n                              :\n                              \n                                 \n                                    [\n                                    0\n                                    ,\n                                    1\n                                    ]\n                                 \n                                 \n                                    W\n                                 \n                              \n                              \u2192\n                              [\n                              0\n                              ,\n                              1\n                              ]\n                            which extends \u03b2. Furthermore, since the events \n                              \n                                 \n                                    e\n                                 \n                                 \n                                    1\n                                 \n                              \n                              ,\n                              \u2026\n                              ,\n                              \n                                 \n                                    e\n                                 \n                                 \n                                    k\n                                 \n                              \n                            are classical, then the map \n                              \n                                 Bel\n                              \n                              :\n                              \n                                 \n                                    2\n                                 \n                                 \n                                    W\n                                 \n                              \n                              \u2192\n                              [\n                              0\n                              ,\n                              1\n                              ]\n                            obtained by restricting \n                              \n                                 \n                                    Bel\n                                 \n                                 \n                                    \u2032\n                                 \n                              \n                            to the Boolean skeleton \n                              \n                                 \n                                    2\n                                 \n                                 \n                                    W\n                                 \n                              \n                            of \n                              \n                                 \n                                    [\n                                    0\n                                    ,\n                                    1\n                                    ]\n                                 \n                                 \n                                    W\n                                 \n                              \n                            is a classical belief function which extends \u03b2. Hence the claim is settled. \u2003\u25a1\n\nFinally let us remark that, although in this section we have focused on refinements of the notion of pessimistic coherence the associated classes of belief functions they characterise, we could formulate analogous refinements for the notion optimistic coherence and get their corresponding classes of plausibility functions. However, the strong duality between the notions of pessimistic and optimistic coherence on the one hand, and between belief and plausibility functions on the other hand, would turn this into a rather tedious and uninformative exercise.", "title": "Coherence in the aggregate: A betting method for belief functions on many-valued events"}, "S2590188519300071": {"highlights": ["This work identifies Twitter feedback having causal effects on enterprise outcomes.", "Co-occurrence network analysis discovers influential terms from Twitter data.", "Influential terms having causal effects on enterprise outcomes are identified.", "Time lags between influential terms and enterprise outcomes are quantified.", "Identified influential terms support future enterprise decisions."], "abstract": "The authors present an expert and intelligent system that (1) identifies influential term groups having causal relationships with real-world enterprise outcomes from Twitter data and (2) quantifies the appropriate time lags between identified influential term groups and enterprise outcomes. Existing expert and intelligent systems, which are defined as computer systems that imitate the ability of human decision making, could enable computers to identify the spread of Twitter users\u2019 enterprise-related feedback automatically. However, existing expert and intelligent systems have limitations on automatically identifying the causal effects on enterprise outcomes. Identifying the causal effects on enterprise outcomes is important, because Twitter users\u2019 feedback toward enterprise decisions may have real-world implications. The proposed expert and intelligent system can support decision makers\u2019 decisions considering the real-world effects of identified Twitter users\u2019 feedback on enterprise outcomes. In particular, (1) a co-occurrence network analysis model is exploited to discover term candidates for generating influential term groups that are combinations of enterprise-related terms, which potentially influence enterprise outcomes. (2) Time series models and (3) a Granger causality analysis model are then employed to identify influential term groups having causal relationships with enterprise outcomes with the appropriate time lags. Case studies involving a real-world internet video streaming and disc rental provider as well as an airline company are used to test the validity of the proposed expert and intelligent system for both predicting enterprise outcomes in a long period and predicting the effects of specific events on enterprise outcomes in a short period.", "title": "Mining Twitter data for causal links between tweets and real-world outcomes"}, "S1319157818310954": {"highlights": ["An improved triangular-based star identification algorithm for low-cost star trackers is proposed.", "The overall identification rate is improved when few stars are detected.", "The proposed algorithm is highly robust to missing stars, and robust towards magnitude noise with an optimised star database.", "The proposed algorithm is successfully implemented on a star tracker prototype based on ARM processor.", "Our algorithm is more suitable for low-cost star trackers than previous algorithms."], "abstract": "Star identification algorithms based on triangular-pattern are more suitable for low-cost star trackers since they require less star density in the field of view to operate effectively. In this paper, we propose a modified star pattern recognition algorithm based on the triangular-based algorithm of \u201cLIEBE\u201d. The main contribution of the proposed work is twofold. First, a new strategy for the selection of star triplets is proposed for database construction. Second, new selection criteria of the reference star are considered for pattern generation process. A sky simulation program is developed to assess mainly the robustness against different conditions of noise. The obtained results show an improvement in the overall identification rate, more robustness towards missing stars, and more efficiency towards magnitude noise. Furthermore, our proposed algorithm shows comparable robustness with the recently proposed triangular algorithms despite their reliance on more accurate camera and a validation process. To assess the algorithm performance, the algorithm is implemented on a prototype of Data Processing Unit (DPU) based on ARM Cortex-M4 processor. In this part, we discuss the major design decisions and we present the hardware architecture of DPU. The algorithm shows promising running time at a reduced on-board database when implemented on ARM platform.", "title": "Improved triangular-based star pattern recognition algorithm for low-cost star trackers"}, "S0142061514005869": {"highlights": ["This paper proposes a novel load unbalance compensator (LUC) for the stand-alone microgrid using three-phase four-leg VSI.", "The model of a three-phase four-leg VSI for the LUC and the microgrid are simulated using PSCAD/EMTDC.", "This demonstrates that the proposed LUC increases the stability of stand-alone microgrid under unbalance load conditions."], "abstract": "This paper proposes a three-phase four-leg voltage sourced inverter (VSI) based load unbalance compensator (LUC) including its control algorithm, which is a component of a microgrid. The purpose of proposed three-phase four-leg VSI based LUC is to improve power quality of the standalone microgrid. Power quality of the microgrid which was installed in Mara-island, Korea is analyzed using a real operational data. In this work, the microgrid in Mara-island which includes a photovoltaic power generation system, a diesel generator, a battery energy storage system, and a power management system is modeled in PSCAD/EMTDC, and proposed three-phase four-leg VSI based LUC is also modeled and applies to the modeled microgrid. Power flow and stability of the modeled microgrid with the LUC is analyzed under variable irradiance and unbalance loads. The results show that the proposed LUC helps to improve stability of the stand-alone microgrid. The proposed three-phase four-leg VSI based LUC and its control algorithm can be effectively utilized to the stand alone microgrid which has large unbalance loads.", "title": "A novel three-phase four-leg inverter based load unbalance compensator for stand-alone microgrid"}, "S0888613X15000699": {"highlights": ["A new kind of full implication algorithm based on interval-valued fuzzy set is proposed.", "The R-type triple I solutions based on interval-valued fuzzy reasoning are given.", "The new triple I algorithms based on interval-valued fuzzy set are robust.", "The sensitivity of some special algorithms based on four important interval-valued residuated implication is given."], "abstract": "In this paper, a new full implication algorithm based on interval-valued fuzzy inference which extends the triple I principle for fuzzy inference based on fuzzy modus ponens and fuzzy modus tollens to the case of interval-valued fuzzy sets is presented. We first give the corresponding interval-valued \n                        R\n                     -type triple I solutions and then investigate the robustness of triple I algorithms based on interval-valued fuzzy sets for fuzzy inference. The sensitivity of some special algorithms based on four important interval-valued residuated implication is given. It is shown that the robustness of interval-valued full implication algorithms for fuzzy inference directly depends on the selection of interval-valued fuzzy connectives.", "title": "Robustness of full implication algorithms based on interval-valued fuzzy inference"}, "S1071581918303628": {"highlights": ["Susceptibility to phishing emails is explored in an ecologically valid setting.", "Authority and urgency techniques are found to impact employee susceptibility.", "Context-specific factors are also likely to impact employee susceptibility.", "A range of targeted initiatives are required to address susceptibility factors."], "abstract": "Phishing emails provide a means to infiltrate the technical systems of organisations by encouraging employees to click on malicious links or attachments. Despite the use of awareness campaigns and phishing simulations, employees remain vulnerable to phishing emails. The present research uses a mixed methods approach to explore employee susceptibility to targeted phishing emails, known as spear phishing. In study one, nine spear phishing simulation emails sent to 62,000 employees over a six-week period were rated according to the presence of authority and urgency influence techniques. Results demonstrated that the presence of authority cues increased the likelihood that a user would click a suspicious link contained in an email. In study two, six focus groups were conducted in a second organisation to explore whether additional factors within the work environment impact employee susceptibility to spear phishing. We discuss these factors in relation to current theoretical approaches and provide implications for user communities.", "title": "Exploring susceptibility to phishing in the workplace"}, "S0893608018301230": {"highlights": ["The dilution and symmetry of a recurrent neural network affect its limit behaviors.", "There are two optimal regions that optimize the number of limit behaviors.", "The first region is symmetric and fully connected as predicted by Hebbs\u2019 learning.", "The second region is asymmetric and diluted as found in the neocortex and hippocampus."], "abstract": "We study with numerical simulation the possible limit behaviors of synchronous discrete-time deterministic recurrent neural networks composed of \n                        N\n                      binary neurons as a function of a network\u2019s level of dilution and asymmetry. The network dilution measures the fraction of neuron couples that are connected, and the network asymmetry measures to what extent the underlying connectivity matrix is asymmetric. For each given neural network, we study the dynamical evolution of all the different initial conditions, thus characterizing the full dynamical landscape without imposing any learning rule. Because of the deterministic dynamics, each trajectory converges to an attractor, that can be either a fixed point or a limit cycle. These attractors form the set of all the possible limit behaviors of the neural network. For each network we then determine the convergence times, the limit cycles\u2019 length, the number of attractors, and the sizes of the attractors\u2019 basin. We show that there are two network structures that maximize the number of possible limit behaviors. The first optimal network structure is fully-connected and symmetric. On the contrary, the second optimal network structure is highly sparse and asymmetric. The latter optimal is similar to what observed in different biological neuronal circuits. These observations lead us to hypothesize that independently from any given learning model, an efficient and effective biologic network that stores a number of limit behaviors close to its maximum capacity tends to develop a connectivity structure similar to one of the optimal networks we found.", "title": "Effect of dilution in asymmetric recurrent neural networks"}, "S2589721719300030": {"highlights": ["We predict the genotype of maize offspring based on parents' phenotypic traits with logistic regression and na\u00efve bayes", "Both logistic regression and na\u00efve bayes produce similar results, in line with the theory by Tom Mitchell (Carnegie Mellon U)", "The AUC value is a good criterion of parent-offspring resemblance that depends on the set of predictors variables in the model"], "abstract": "We used two probabilistic methods, Gaussian Na\u00efve Bayes and Logistic Regression to predict the genotypes of the offspring of two maize strains, the BLC and the JNE genotypes, based on the phenotypic traits of the parents. We determined the prediction performance of the two models with the overall accuracy and the area under the receiver operating curve (AUC). The overall accuracy for both models ranged between 82% and 87%. The values of the area under the receiver operating curve were 0.90 or higher for Logistic Regression models, and 0.85 or higher for Gaussian Na\u00efve Bayes models. These statistics indicated that the two models were very effective in predicting the genotypes of the offspring. Furthermore, both models predicted the BLC genotype with higher accuracy than they did the JNE genotype. The BLC genotype appeared more homogeneous and more predictable. A Chi-square test for the homogeneity of the confusion matrices showed that in all cases the two models produced similar prediction results. That finding was in line with the assertion by Mitchell (2010) who theoretically showed that the two models are essentially the same. With logistic regression, each subset of the original data or its corresponding principal components produced exactly the same prediction results. The AUC value may be viewed as a criterion for parent-offspring resemblance for each set of phenotypic traits considered in the analysis.", "title": "Identification of maize (Zea mays L.) progeny genotypes based on two probabilistic approaches: Logistic regression and na\u00efve Bayes"}, "S0736584515300260": {"highlights": ["A positioning system has been built for the driven joints of the 3-PRR in SEM.", "The dead-zone of the system has been identified and applied to compensation.", "The proposed control algorithm improves the tracking precision significantly."], "abstract": "A 3PRR parallel precision positioning system, driven by three ultrasonic linear motors, was designed for use as the object stage of a scanning electron microscope (SEM). To improve the tracking accuracy of the parallel platform, the positioning control algorithms for the drive joints needed to be studied. The dead-zone phenomenon caused by static friction reduces the trajectory tracking accuracy significantly. Linear control algorithms such as PID (Proportion Integration Differentiation) are unable to compensate effectively for the dead-zone nonlinearity. To address this problem, two types of feedforward compensation control algorithms have been investigated. One is constant feedforward with the integral separation PID; the other is adaptive feedback and feedforward based on the model reference adaptive control (MRAC). Simulations and experiments were conducted using these two control algorithms. The results demonstrated that the constant feedforward with integral separation PID algorithm can compensate for the time-invariant system after identifying the dead-zone depth, while the adaptive feedback and feedforward algorithm is more suitable for the time-varying system. The experimental results show good agreement with the simulation results for these two control algorithms. For the dead-zone nonlinearity caused by the static friction, the adaptive feedback and feedforward algorithm can effectively improve the trajectory tracking accuracy.", "title": "Adaptive positioning control of an ultrasonic linear motor system"}, "S1319157818301101": {"highlights": ["Systematic organization of Data Compression (DC) concepts with its importance, mathematical formulation and performance measures.", "Critical investigation of various DC algorithms on the basis of data quality, coding schemes, data type and applications.", "We suggested potential research directions and open issues to explore the possible future trends in DC."], "abstract": "Explosive growth of data in digital world leads to the requirement of efficient technique to store and transmit data. Due to limited resources, data compression (DC) techniques are proposed to minimize the size of data being stored or communicated. As DC concepts results to effective utilization of available storage area and communication bandwidth, numerous approaches were developed in several aspects. In order to analyze how DC techniques and its applications have evolved, a detailed survey on many existing DC techniques is carried out to address the current requirements in terms of data quality, coding schemes, type of data and applications. A comparative analysis is also performed to identify the contribution of reviewed techniques in terms of their characteristics, underlying concepts, experimental factors and limitations. Finally, this paper insight to various open issues and research directions to explore the promising areas for future developments.", "title": "A survey on data compression techniques: From the perspective of data quality, coding schemes, data type and applications"}, "S0921889016305383": {"highlights": ["Bottom-up approach to organize robot\u2019s visuomotor experiences.", "Integration learning of drawing behavior by recurrent neural networks.", "Association of drawing motion from drawn picture image.", "Organizing distorted shapes by using drawing experiences."], "abstract": "Drawing is a way of visually expressing our feelings, knowledge, and situation. People draw pictures to share information with other human beings. This study investigates visuomotor memory (VM), which is a reusable memory storing drawing behavioral data. We propose a neural network-based model for acquiring a computational memory that can replicate VM through self-organized learning of a robot\u2019s actual drawing experiences. To design the model, we assume that VM has the following two characteristics: (1) it is formed by bottom-up learning and integration of temporal drawn pictures and motion data, and (2) it allows the observers to associate drawing motions from pictures. The proposed model comprises a deep neural network for dimensionally compressing temporal drawn images and a continuous-time recurrent neural network for integration learning of drawing motions and temporal drawn images. Two experiments are conducted on unicursal shape learning to investigate whether the proposed model can learn the function without any shape information for visual processing. Based on the first experiment, the model can learn 15 drawing sequences for three types of pictures, acquiring associative memory for drawing motions through the bottom-up learning process. Thus, it can associate drawing motions from untrained drawn images. In the second experiment, four types of pictures are trained, with four distorted variations per type. In this case, the model can organize the different shapes based on their distortions by utilizing both the image information and the drawing motions, even if visual characteristics are not shared.", "title": "Visual motor integration of robot\u2019s drawing behavior using recurrent neural network"}, "S0957417417300957": {"highlights": ["This work proposes a novel tree model for multivariate regression analysis.", "Both node splitting and regression coefficients are optimised in this model.", "The proposed method achieves improved prediction accuracy than literature methods.", "The resultant trees are at least as simple as the ones from previous methods."], "abstract": "Regression analysis is a machine learning approach that aims to accurately predict the value of continuous output variables from certain independent input variables, via automatic estimation of their latent relationship from data. Tree-based regression models are popular in literature due to their flexibility to model higher order non-linearity and great interpretability. Conventionally, regression tree models are trained in a two-stage procedure, i.e. recursive binary partitioning is employed to produce a tree structure, followed by a pruning process of removing insignificant leaves, with the possibility of assigning multivariate functions to terminal leaves to improve generalisation. This work introduces a novel methodology of node partitioning which, in a single optimisation model, simultaneously performs the two tasks of identifying the break-point of a binary split and assignment of multivariate functions to either leaf, thus leading to an efficient regression tree model. Using six real world benchmark problems, we demonstrate that the proposed method consistently outperforms a number of state-of-the-art regression tree models and methods based on other techniques, with an average improvement of 7\u201360% on the mean absolute errors (MAE) of the predictions.", "title": "A regression tree approach using mathematical programming"}, "S0925231218304168": {"highlights": ["Dynamic parallelism speeds up large spiking neural network simulations.", "Dynamic parallelism eliminates obsolete calculations at the synaptic updating step.", "Dynamic parallelism is particularly efficient when simulating sparsely firing neural networks."], "abstract": "Graphical processing units (GPUs) can significantly accelerate spiking neural network (SNN) simulations by exploiting parallelism for independent computations. Both the changes in membrane potential at each time-step, and checking for spiking threshold crossings for each neuron, can be calculated independently. However, because synaptic transmission requires communication between many different neurons, efficient parallel processing may be hindered, either by data transfers between GPU and CPU at each time-step or, alternatively, by running many parallel computations for neurons that do not elicit any spikes. This, in turn, would lower the effective throughput of the simulations. Traditionally, a central processing unit (CPU, host) administers the execution of parallel processes on the GPU (device), such as memory initialization on the device, data transfer between host and device, and starting and synchronizing parallel processes. The parallel computing platform CUDA 5.0 introduced dynamic parallelism, which allows the initiation of new parallel applications within an ongoing parallel kernel. Here, we apply dynamic parallelism for synaptic updating in SNN simulations on a GPU. Our algorithm eliminates the need to start many parallel applications at each time-step, and the associated lags of data transfer between CPU and GPU memories. We report a significant speed-up of SNN simulations, when compared to former accelerated parallelization strategies for SNNs on a GPU.", "title": "Dynamic parallelism for synaptic updating in GPU-accelerated spiking neural network simulations"}, "S2589721719300224": {"highlights": ["Coupling of crop assignments to fields and vehicle routing for harvest planning", "Integer linear programming formulations are derived for problem modeling.", "A heuristc suboptimal relaxation is proposed for large-scale applications."], "abstract": "A method for harvest planning based on the coupling of crop assignment with vehicle routing is presented. Given a setting with multiple fields, a path network connecting these, multiple depots at which a number of harvesters are initially located, the main question addressed is: Which crop out of a set of different crops to assign to each field when accounting for the given setting? It must be answered by every farm manager at the beginning of every work-cycle starting with plant seeding and ending with harvesting. Rather than solving an assignment problem only, it is here also accounted for the connectivity between fields. In practice, fields are often located distant apart. Traveling costs of machinery and limited harvesting windows demand optimized operation and route planning. Therefore, the proposed method outputs crop assignments to fields and simultaneously determines crop-tours, i.e., optimized sequences in which to service fields of the same crop during harvest. It is of particular relevance for larger farms and groups of farms that collaborate and share machinery. Integer programming based exact algorithms are derived. For large numbers of fields, where these algorithms may not be tractable due to computational constraints, elements of clustering and the solution of local Traveling Salesman Problems are added, thereby on the one hand rendering the method heuristic and in general suboptimal, but on the other hand maintaining large-scale applicability.\n               \n            \n\nSet of D depots, indexed by \n                           d\n                           ,\n                           i\n                           ,\n                           j\n                           \u2208\n                           D\n                        .\n\nSet of L fields, indexed by l,i,j \u2208\u2112.\n\nSet of K crops, indexed by \n                           k\n                           \u2208\n                           K\n                        .\n\nDecision variable for edge (i,j) and crop k.\n\nDecision variable for vertex l and crop k.\n\nDecision variable for depot d.\n\nDecision variable for the nr. of active crops.\n\nCost per harvester for arc (i,j) and crop k.\n\nCost for arc (i,j) and crop k.\n\nMonetary return for crop k on field l.\n\nCost coefficient for active depot d.\n\nCost coefficient per active crop.\n\nNr. of harvesters at depot d for crop-tour k.\n\nParameter for \n                           \n                              \n                                 k\n                              \n                              \u02dc\n                           \n                        -means clustering.\n\nMonetary return (revenue minus costs).\n\nInteger/linear programming\n\nTraveling Salesman Problem/multiple TSP", "title": "Coupling of crop assignment and vehicle routing for harvest planning in agriculture"}, "S0306437916303246": {"highlights": ["This work is a detailed companion reproducibility paper of the methods and experiments proposed in three previous works by Lastra-D\u00edaz and Garc\u00eda-Serrano, which introduce a set of reproducible experiments on word similarity based on HESML and ReproZip with the aim of exactly reproducing the experimental surveys in the aforementioned works.", "This work introduces a new representation model for taxonomies called PosetHERep, and a Java software library called Half-Edge Semantic Measures Library (HESML) based on it, which implements most ontology-based semantic similarity measures and Information Content (IC) models based on WordNet reported in the literature.", "PosetHERep proposes a memory-efficient representation for taxonomies which linearly scales with the size of the taxonomy and provides an efficient implementation of a large set of topological queries and graph-based algorithms, which is an adaptation of the half-edge data structure commonly used to represent discrete manifolds and planar graphs in computational geometry.", "This work also introduces a replication framework and dataset, called WNSimRep v1, which is provided as supplementary material and whose aim is to assist the exact replication of most similarity measures and IC models reported in the literature.", "Finally, this work introduces an experimental survey on the performance and scalability of the most recent state-of-the-art semantic measures libraries. This latter experimental survey confirms the statistically significant outperformance of HESML on the state-of-the-art libraries in terms of performance and scalability, as well as the possibility to improve significantly the performance and scalability of the semantic measures libraries without caching using PosetHERep."], "abstract": "This work is a detailed companion reproducibility paper of the methods and experiments proposed by Lastra-D\u00edaz and Garc\u00eda-Serrano in (2015, 2016) [56\u201358], which introduces the following contributions: (1) a new and efficient representation model for taxonomies, called PosetHERep, which is an adaptation of the half-edge data structure commonly used to represent discrete manifolds and planar graphs; (2) a new Java software library called the Half-Edge Semantic Measures Library (HESML) based on PosetHERep, which implements most ontology-based semantic similarity measures and Information Content (IC) models reported in the literature; (3) a set of reproducible experiments on word similarity based on HESML\nand ReproZip with the aim of exactly reproducing the experimental surveys in the three aforementioned works; (4) a replication framework and dataset, called WNSimRep v1, whose aim is to assist the exact replication of most methods reported in the literature; and finally, (5) a set of scalability and performance benchmarks for semantic measures libraries. PosetHERep and HESML are motivated by several drawbacks in the current semantic measures libraries, especially the performance and scalability, as well as the evaluation of new methods and the replication of most previous methods. The reproducible experiments introduced herein are encouraged by the lack of a set of large, self-contained and easily reproducible experiments with the aim of replicating and confirming previously reported results. Likewise, the WNSimRep v1 dataset is motivated by the discovery of several contradictory results and difficulties in reproducing previously reported methods and experiments. PosetHERep\nproposes a memory-efficient representation for taxonomies which linearly scales with the size of the taxonomy and provides an efficient implementation of most taxonomy-based algorithms used by the semantic measures and IC models, whilst HESML provides an open framework to aid research into the area by providing a simpler and more efficient software architecture than the current software libraries. Finally, we prove the outperformance of HESML on the state-of-the-art libraries, as well as the possibility of significantly improving their performance and scalability without caching using PosetHERep.", "title": "HESML: A scalable ontology-based semantic similarity measures library with a set of reproducible experiments and a replication dataset"}, "S0888613X1400173X": {"highlights": ["Propose a new decision model for solving time-critical multiagent decision making problems.", "Present an effective method to construct the model.", "Propose two methods to solve the model.", "Experiment the methods in three problem domains."], "abstract": "Multiagent time-critical dynamic decision making is a challenging task in many real-world applications where a trade-off between solution quality and computational tractability is required. In this paper, we present a formal representation for modelling time-critical multiagent dynamic decision problems based on interactive dynamic influence diagrams (I-DIDs). The new representation called time-critical I-DIDs (TC-IDIDs) represents space-temporal abstraction by providing time-index to nodes and the model is defined in terms of the condensed and deployed forms. The condensed form is a static model of TC-IDIDs and can be expanded into its dynamic version. To facilitate the conversion between the two forms, we exploit the notion of object-orientation design to develop flexible and reusable TC-IDIDs. The difficulty on expanding TC-IDIDs is to select a proper time sequence to index nodes in the condensed form so that the expanded TC-IDIDs can be solved efficiently without compromising the quality of the policy. For this purpose, we propose two methods to build the condensed form of TC-IDIDs. We evaluate the solution quality and time complexity in three well-studied problems and provide results in support.", "title": "Time-critical interactive dynamic influence diagram"}, "S0888613X15000158": {"highlights": ["A hybrid interval type2 Fuzzy-FLANN EGARCH model is proposed to forecast the volatility of three stock market indexes.", "The TSK-type interval type2 fuzzy inference system uses FLANN in the consequent part of the fuzzy rules for improved mapping.", "The leverage effect, asymmetric shock by leverage effect of EGARCH model are important for forecasting.", "A harmony search (HS) based learning strategy is used for EGARCH-FLANN model parameters.", "Statistical tests are also included for choosing the right model."], "abstract": "In this paper a new hybrid model integrating an interval type2 fuzzy logic system (IT2FLS) with a computationally efficient functional link artificial neural network (CEFLANN) and an Exponential Generalized Autoregressive Conditional Heteroskedasticity (EGARCH) model has been proposed for accurate forecasting and modeling of financial data with changing variance over time. The proposed model denoted as IT2F-CE-EGARCH helps to enhance the ability of EGARCH model through a joint estimation of the important features of EGARCH like leverage effect, asymmetric shock by leverage effect with the secondary membership functions of interval type2 TSK FLS and the functional expansion and learning component of a CEFLANN. The secondary membership functions with upper and lower limits of IT2FLS provide a forecasting interval for handling more complicated uncertainties involved in volatility forecasting compared to type1 FLS. The performance of the proposed model has been observed with two membership functions i.e. Gaussian with fixed mean, uncertain variance and Gaussian with fixed variance and uncertain mean. The proposed model has also been compared with a few other fuzzy time series models and GARCH family models based on four performance metrics: MSFE, RMSFE, MAFE and Rel MAE. Again a differential harmony search (DHS) algorithm has been suggested for optimizing the parameters of all the fuzzy time series models. The results indicate that the proposed IT2F-CE-EGARCH model offers significant improvements in volatility forecasting performance in comparison with all other specified models over BSE Sensex and CNX Nifty dataset.", "title": "A differential harmony search based hybrid interval type2 fuzzy EGARCH model for stock market volatility prediction"}, "S0957417419300491": {"highlights": ["Variable rate irrigation speed control was enhanced using spatial variability.", "Increasing or decreasing the rotation speed of central pivot using fuzzy system.", "Combining edaphoclimatic variables to fuzzy logic can solve problems in irrigation.", "Expert system using remote sensing can manage the speed control for central pivot."], "abstract": "Variable rate irrigation (VRI) is the capacity to spatially vary the depth of water application in a field to handle different types of soils, crops, and other conditions. Precise management zones must be developed to efficiently apply variable rate technologies. However, there is no universal method to determine management zones. Using speed control maps for the central pivot is one option. Thus, this study aims to develop an intelligent fuzzy inference system based on precision irrigation knowledge, i.e., a system that can create prescriptive maps to control the rotation speed of the central pivot. Satellite images are used in this study because remote sensing offers quick measurements and easy access to information on crops for large irrigation areas. Based on the VRI-prescribed map created using the intelligent decision-making system, the pivot can increase or decrease its speed, reaching the desired depth of application in a certain irrigation zone. Therefore, considering the spatial variability in the crop has made the strategy of speed control more realistic than traditional methods for crop management. The intelligent irrigation system pointed out areas with lower leaf development, indicating that the pivot must reduce its speed, thus increasing the water layer applied to that area. The existence of well-divided zones could be observed; each zone provides a specific value for the speed that the pivot must develop for decreasing or increasing the application of the water layer to the crop area. Three quarters of the total crop area had spatial variations during water application. The set point built by the developed system pointed out zones with a decreased speed in the order of 50%. From the viewpoint of a traditional control, the relay from pivot percent timer should have been adjusted from 70% to 35% whenever the central pivot passed over that specific area. The proposed system obtained values of 37% and 47% to adjust the pivot percent timer. Therefore, it is possible to affirm that traditional control models used for central-pivot irrigators do not support the necessary precision to meet the demands of speed control determined by the developed VRI systems. Results indicate that data from the edaphoclimatic variables when well-fitted to the fuzzy logic can solve uncertainties and non-linearities of an irrigation system and establish a control model for high-precision irrigation.\n               \n            \n\nThe Food and Agriculture Organization (FAO) of the United Nations estimates that to meet food demands in 2050 agriculture production must at least double or triple in the next 40 years, and 80% of this increase must come from increasing the production. Considering the limited resources of our planet, reaching this goal will be challenging (FAO,\u00a02016).\n\nThe adoption of irrigated agriculture enables increased productivity and the production of several crops (Borghetti,\u00a0Silva, Nocko, Loyola, & Chianca, 2017). However, with the growing limitation of water resources, the use of water in agriculture must be more efficient to maintain the current levels of productivity in conjunction with the expansion of irrigated areas. Decisions for irrigation management require taking into consideration inter-related economic, physical, and biological variables, which are frequently difficult to foresee and over which there is little or no control (Herrera,\u00a0Ibeas, & de\u00a0la Sen, 2013). The decade-long search for automated solutions to improve agricultural application for more efficient use (Evans & King, 2012; Gilley, Mielke, & Wilhelm, 1983; Omary, Camp, & Sadler, 1997; Sadler, Camp, Evans, & Usrey, 1996) has resulted in the introduction of several solutions for agricultural inputs to conduct water application with spatial correction. Irrigation systems that operate using variable rate water application are required for a spatial water management to increase crop efficiency (Armindo,\u00a0Botrel, & Garzella, 2011).\n\nDecision support systems for irrigation and water conservation are used intensely for minimizing water application and maximizing yield. However, the numerical optimization of irrigation systems is computer-intensive and often requires simplification and discretization of the model (Dogan, Gumrukcuoglu, Sandalci, & Opan, 2010; Navarro-Hell\u00edn, Mart\u00ednez-del-Rincon, Domingo-Miguel, Soto-Valles, & Torres-S\u00e1nchez, 2016). Furthermore, sensorial system and model integration do not reflect the natural flow of the environment (Voinov & Shugart,\u00a02013), creating significant limitations in performance. Control systems also do not reflect or satisfy the requirements of the final users due to the lack of domain knowledge capture (McIntosh\u00a0et\u00a0al., 2011). The use of advanced control techniques is a promising possibility. Literature shows that these tools can significantly improve irrigation systems and efficient use of water resources (McCarthy, Hancock, & Raine, 2013; Romero, Muriel, Garc\u00eda, & Mu\u00f1oz de la Pe\u00f1a, 2012). The final challenge of an environmental and agricultural support system is to overcome the uncertainty related to data quality and difficulties in remote sensing of large areas (Dutta, Morshed, Aryal, D'Este, & Das, 2014; McCarthy et\u00a0al., 2013). Moreover, the inter-related economic, physical, and biological variables are multi-attributed vaguely and in subjective terms.\n\nA neat approach to deal with such uncertain situations is found in the fuzzy set theory, which has now reached a mature state for expansion and application. Zadeh's\u00a0paper \u201cFuzzy Sets\u201d was published in 1965; since then, the theory of fuzzy sets has been used for writing more realistic decision support models. Fuzzy logic can analyze the imprecise information and is efficient in decision-making for vague and uncertain phenomena (Kweon,\u00a02012). Specialized systems that used fuzzy logic in its inception have been successfully applied to problems concerning decision, control, diagnose, and classification (Castillo & Melin,\u00a02008) because they are capable of managing intrinsic complex reasoning in an application area. In agriculture, the interface of these systems allows a natural and straightforward use, as a planning tool for the manager and farmer. In irrigation systems, the interaction between components is not always accurately defined. Fuzzy logic can be used in such systems for extracting inferences from an inaccurate input and for solving problems in this area (Thangavadivelu & Colvin,\u00a01997). An irrigation system based on the fuzzy logic with simple rules is more attractive to most farmers (Bahat,\u00a0Inbar, Yaniv, & Schneider, 2000) since these systems do not require a precise measurement or a precise model, which may be very complicated and require considerable funds, resources and development time.\n\nThis study is based on the premise that irrigation problems do not require precise measures. The support system to the fuzzy decision is considered useful due to its interactive nature and flexible approach (Kumar & Rajkumar, 2014; Raju & Kumar, 2005); therefore, the integration of fuzzy logic and irrigation planning issues in the field is very effective. Herein, several control techniques for VRI have been presented, of which some use fuzzy inference and neural networks for setting the amount of water required for irrigation (Bing et\u00a0al., 2015; Giusti & Marsili-Libelli, 2015; Papadopoulos, Kalivas, & Hatzichristos, 2011; Papageorgiou, Kokkinos, & Dikopoulou, 2016). Other techniques focus on determining when to irrigate and instruments that show spatial differences among sectors in the same crop area (Montalvo et\u00a0al., 2013; Omid et\u00a0al., 2010; Rafea, Hassen, & Hazman, 2003).\n\nHowever, all the techniques mentioned do not present control maps for the central pivot, as proposed herein. The problem examined herein is part of the crop production domain, approaching the issue of necessary decision-making for precision irrigation.\n\nTherefore, the main objective of this study is to develop a fuzzy inference system that decides when to increase or decrease the speed of the central pivot by considering the spatial variability of the field and using little or imprecise information of the phenophase of the crop provided by satellite images.\n\nAn intelligent irrigation system was developed by following the structure shown in Fig.\u00a01\n                     . The structure of the proposed system allows the elaboration of the management map in a systematic, autonomous, and automatized way to control the irrigation system. The commercial systems used more frequently by farmers still cannot draw such a control map using the proposed technique.\n\nVegetation indexes generated from the data gathered by remote sensing constitute an important tool for monitoring natural or anthropogenic changes in the use and coverage of the land. These indexes have been used to estimate several vegetation patterns, such as leaf area index and green biomass quantity, as well as in the evaluation of soil use and the maintenance and recovery of degraded areas (Okin,\u00a02007). Information from satellite images and values from the normalized difference vegetation index (NDVI) reading, which is an essential parameter for irrigation maintenance, were used and adjusted according to local conditions. Irrigation management through the plant shows the complexity inherent to the visualization of the symptoms of water deficit, which are difficult to detect. In certain occasions, problems are discovered when it is too late, i.e., when their effects have already compromised the production and quality of the product. Usually, these symptoms are related to the color tone of leaves, leaf curling, and leaf angle. However, a correlation between NDVI values and the basal crop coefficient (Kc) (Hunsaker,\u00a0Barnes, Clarke, Fitzgerald, & Pinter, 2005; and Kamble,\u00a0Kilic, & Hubbard, 2013) can be established since a strong correlation exists between estimated Kc (KcNDVI) and observed Kc (Allen, Pereira, Raes, & Smith, 1998/FAO-56) in corn and soy crops for guiding irrigation times in the season.\n\nThe use of canopy temperature and infrared thermometry is another way to relate to the development of the crop through remote sensing. A plant under water stress has decreased transpiration and would typically show a higher temperature than a plant that is not under stress (Bellvert,\u00a0Zarco-Tejada, Girona, & Fereres, 2014), a trait that could be used as a powerful tool to monitor and quantify water stress. Canopy temperature increases when solar radiation is absorbed (Idso & Baker,\u00a01967), but it cools down when the latent energy or transpiration is used for evaporating water instead of cooling plant surfaces. Further, algorithms based on canopy temperature are strongly correlated with quantifiable results from crops (Colaizzi,\u00a0O'Shaughnessy, Evett, & Howell, 2012), such as yield, water efficiency use, seasonal evapotranspiration, leaf water potential at noon, irrigation rates, and damage caused by herbicides.\n\nThe Intelligent Environmental Knowledgeable system (i-ekbase)\n                           1\n                        \n                        \n                           1\n                           \n                              http://iekbase.com/.\n                         is an autonomous big data analytics engine running a CLOUD system. i-ekbase is an easy-to-use fully automated geographic information system (GIS). It primarily focuses on precision agricultural and biodiversity monitoring applications, automatically integrating data from various satellites with local weather data, farmers\u2019 knowledge, and applying Machine Learning techniques to create a data-driven future for global agriculture (Dutta\u00a0et\u00a0al., 2014). Fig.\u00a02\n                         illustrates the i-ekbase visual interactive system based on big data integration over large farming areas.\n\nThe i-ekbase is regularizing satellite remote sensing for all-purpose precision agricultural monitoring on a mobile device, for greater benefit to global agriculture community, and for increasing agriculture business profitability. The system services provide weekly or daily large area-wise resource management map products, including normalized vegetation index (NDVI), soil moisture, biomass, surface temperature, vegetation landscape maps for supporting remote digital scouting, large area-wise farm monitoring and decision support system, and rapid intervention of a management issue.\n\nHerein, we used the i-ekbase system for capturing timely remote sensing imagery on the study site using Landsat (with a spatial resolution of 15\u202fm) and Sentinel (with a spatial resolution of 10\u202fm) satellites. Data were captured for 12 months for developing the experimental system.\n\nData that compose this image have over 14 thousand geo-referential points, which indicate a raster type structure, containing in each point or pixel that attributes for agricultural analysis. Given the size of the data, only a few lines are shown in Table\u00a01\n                        . Different types of software are available on the market, which can generate maps from .shp,.kml, or CSV archives, such as Surfer (Golden Software, Inc.), ArcView (ESRI), and Global Mapper (Global Mapper), all requiring payment. QGIS is an open code licensed under General Public License GNU and will be used herein for pre-processing and editing the archive provided by the web tool i-ekbase.\n\nAfter collecting the remote sensing data using the web tool i-ekbase (Table\u00a01), the information is pre-processed to filter the data that are not required by the decision-making system. Thus, only canopy temperature, upper layer soil moisture, NDVI, and coordinates are considered (Table\u00a02\n                        ).\n\nFor applying this approach on a commercial scale, remote sensing data required to describe the soil\u2013plant\u2013atmosphere relation can be acquired from satellite images (Moran,\u00a0Inoue, & Barnes, 1997) and airplanes (Fitzgerald, Lesch, Barnes, & Luckett, 2006; Wood, Taylor, & Godwin, 2003). However, high costs, spatial resolution, data frequency and data availability (Pinter et\u00a0al., 2003; Trout, Johnson, & Gartung, 2008), as well as satellite cloudless images (Barker,\u00a0Heeren, Neale, & Rudnick, 2018) are challenges for the correct execution of models based on remote sensing; these factors can limit the efficiency of VRI management in real time.\n\nRemote sensing data that accurately describe the soil\u2013plant\u2013atmosphere relationship was selected for the intelligent irrigation system at the crop location. In this stage, accurately choosing the best data is fundamental to ensure that the results are calculated correctly. A simple but promising approach uses culture coefficients from normalized differentiated variation indexes, combined with local climate data, to assume the amount of ETc (evapotranspiration) of variable crops almost at real time (Er-Raki et\u00a0al., 2007; Gonzalez-Dugo & Mateos, 2008; Hunsaker et\u00a0al., 2005).\n\nWith some consideration of the daily meteorological conditions, models based on remote sensing can be used in studies of water relations (Barker\u00a0et\u00a0al., 2018) in the soil\u2013plant\u2013atmosphere system and could become an easy-to-use and fast response tool. Canopy temperature is also an important parameter to manage irrigation and must be adjusted according to local crop conditions. From the location selected for cultivation and the type of crop to be irrigated, in relation to the data linked to the type of plant, a crop coefficient will be used together with information from satellite images. In this case, NDVI reading, upper layer soil moisture, and canopy temperature values will be used.\n\nThe crop area is a farm at Primavera do Leste, Mato Grosso state, Brazil, latitude 15\u00b014\u203224.73\u2032\u2032S and longitude 54\u00b00\u203253.29\u2032\u2032W. This area contains several crops, such as soy, cotton, and \u201csafrinha\u201d corn, irrigated by a central pivot. The delimited area is 140\u202fha, with a radius of 667\u00a0m (see Fig.\u00a03\n                        ). The area delimited by the red circle is irrigated with a central pivot, and the information used in this study is for a cultivation cycle of \u201csafrinha\u201d corn in 2015/2016. To irrigate \u201csafrinha\u201d corn means to provide minimum water conditions for the development of the crop. Corn is highly sensitive to drought. Therefore, the occurrence of a period of lower water intake by plants in critical moments for the development of the crop, from flowering to physiological maturation, can lead to the lower yield. For maximum yield, corn plantation needs approximately 650\u202fmm of water (Bergamaschi\u00a0et\u00a0al., 2001) during its cycle, which varies from 110 to 140 days in hybrids with an average cycle.\n\nPlant development is made evident by the images captured by remote sensing during growth. After analyzing the NDVI values contained in Fig.\u00a04\n                        , the similarity among values attributed to crop coefficient (Kc) can be verified (Hunsaker\u00a0et\u00a0al., 2005; and Kamble\u00a0et\u00a0al., 2013). As the crop develops, the leaf area increases, which makes it possible to establish a NDVI relationship.\n\nThis process is also described by Hunsaker\u00a0et\u00a0al.\u00a0(2005), with relations for calculating the basal crop coefficient (Kcb) for cotton as a function of NDVI. When each of the development phases of the crop is analyzed, two distinct areas are evident: one with little growth and another with average growth. From this differentiation, it is possible to build a water demand map as well as speed control maps. For the preliminary analysis, the daily average precipitation data made available by National Institute of Meteorology\n                           2\n                        \n                        \n                           2\n                           \n                              https://www.agritempo.gov.br/agritempo/jsp/Grafico/graficoMicrorregiao.jsp?siglaUF=MT.\n                         (INMET) were used. Data were collected from April to September 2016 in the municipality of Primavera do Leste, Mato Grosso state, Brazil. Fig.\u00a05\n                         illustrates the obtained data. Finally, precipitation readings recorded during the development of the crop under study corroborate with the premise of water stress due to the lack of rain, which would indicate the possibility of complementing the water demand with irrigation.\n\nOver the last 20 years, fuzzy systems have attracted considerable attention and have met great applicability in the agricultural domain, helping farmers to make the right decisions for their crops (Papageorgiou\u00a0et\u00a0al., 2016). For example, Bahat\u00a0et\u00a0al.\u00a0(2000) proposed a solution for an irrigation controller based on the fuzzy logic methodology with simple rules, making the system more attractive for farmers. Raj\u00a0and Kumar\u00a0(2005) observed that the integration of fuzzy logic and real-world irrigation planning problems are very useful, particularly with multiple specialists in a subjective data environment.\n\nUpon using fuzzy systems for decision-making concerning irrigation, Zhang,\u00a0Fei, Wei, Congcong, and Yuewei\u00a0(2011) reported that fuzzy logic does not require all the relevant information for solving the problem of water in irrigation. Bing,\u00a0Huifeng, and Xia\u00a0(2015) developed a fuzzy system of decision-making for solving uncertainties and non-linearity of the irrigation system, and the model showed high precision.\n\nThe system of fuzzy inference proposed by Almeida,\u00a0Vieira, Marques, Kiperstok, and Cardoso\u00a0(2013), in turn, provided a conceptual approach based on the multi-criteria decision-making process. This approach relates water use to environmental factors, such as drought, water exploration index, water use, population density, and wastewater treatment index, resulting in warnings about future water supply. Irrigation based on the fuzzy inference system presents better results than traditional methods. The fuzzy system will be used to infer the variations in the linear movement speed of the pivot according to satellite images. An intelligent system was developed, manipulating various data-driven approaches to create a control map.\n\nDue to the nature of the management of the study area, fuzzy systems are used herein to aid irrigation decision-making. Because a farmer's decisions are purely intuitive and knowledge-based gained over years of work, we chose not to describe the way the farm works explicitly. Another critical piece in the farmer's routine was that the pivot utilized extensive amount of time to perform a full turn. However, the central pivot irrigation system should operate 21\u202fh a day, with 3\u202fh for maintenance because high electricity prices are charged by the utility. Three input variables were used (NDVI, upper layer soil moisture, and canopy temperature) to infer the speed, which the central pivot has to reach to improve the irrigation level within the crop area, and to find an adequate speed for the pivot movement in relation to the amount of water coming out of the sprinklers.\n\nFuthermore, a decision unit or inference machine is implemented using the Mamdani method to conduct the rule-based inference operations with crisp input and crisp output. Mamdani fuzzy systems use fuzzy sets as a consequent rule; therefore, the inference method for a set of conjunctive rules for the rth rule will be given by the following condition:\n                           \n                              (1)\n                              \n                                 \n                                    I\n                                    f\n                                    \n                                    \n                                       x\n                                       1\n                                    \n                                    \n                                    i\n                                    s\n                                    \n                                    \n                                       A\n                                       1\n                                       k\n                                    \n                                    \n                                    a\n                                    n\n                                    d\n                                    \n                                    \n                                       x\n                                       2\n                                    \n                                    \n                                    i\n                                    s\n                                    \n                                    \n                                       A\n                                       2\n                                       k\n                                    \n                                    ,\n                                    \n                                    t\n                                    h\n                                    e\n                                    n\n                                    \n                                    \n                                       y\n                                       k\n                                    \n                                    \n                                    i\n                                    s\n                                    \n                                    \n                                       B\n                                       k\n                                    \n                                    \n                                    f\n                                    o\n                                    r\n                                    \n                                    k\n                                    =\n                                    1\n                                    ,\n                                    2\n                                    ,\n                                    3\n                                    ,\n                                    \u22ef\n                                    ,\n                                    r\n                                    .\n                                 \n                              \n                           \n                        \n                     \n\nWithin the objective proposed for the developed system, once linguistic variables are applied to the output of fuzzy inference systems, it becomes fitter for modeling the human reflection process. By doing so, the interface of the system becomes more straightforward and natural. In the first stage of development, the water layer provided by the irrigation system is considered constant. The database that defines the association functions of sets used in the fuzzy rules is implemented according to Table\u00a03\n                        \n                         and Fig.\u00a06\n                        .\n\nRemote sensing data allow building the universe of discourse for each input variable and therefore change the database into linguistic variables, as shown in Table\u00a03. Each input was previously limited to the discourse universe in question and associated to the grade of membership in each fuzzy set through specialized knowledge. Therefore, to obtain the grade of membership of a certain crisp input, one must search for this value in the fuzzy system knowledge.\n\nThe fuzzification of the decision-making system in Fig.\u00a06 helps to visualize the corresponding membership functions, considering these intervals as the discourse universe of the variables. Triangular membership functions were chosen because they simplify the calculation of the fuzzy inference mechanism and couple to the fuzzy rules IF-THEN (Wang,\u00a01997). Well distributed triangular membership functions change input data into fuzzy values (low, average, and high), as shown in Fig.\u00a06a, as well as values for soil moist and NDVI (Fig. 6b and c, respectively).\n\nFuzzy outputs, which represent the rotation speed of the central pivot, were built from five linguistic variables: very low (MB), low (B), normal (N), high (A), and very high (MA). All the sets were interpreted based on their membership functions, as shown in Fig.\u00a07\n                        . Several defuzzification methods have been proposed (Dubois & Prade,\u00a02000), of which CENTROID (area center or center of gravity) is more widely used. For this method, a clear value of the output variable is calculated by finding the variable for the center of gravity of the association function for the fuzzy value (Jang,\u00a0Sun, & Mizutani, 1997) as follows:\n                           \n                              (2)\n                              \n                                 \n                                    \n                                       u\n                                       *\n                                    \n                                    =\n                                    \n                                       \n                                          \n                                             \u2211\n                                             \n                                                j\n                                                =\n                                                1\n                                             \n                                             N\n                                          \n                                          \n                                             u\n                                             i\n                                          \n                                          \u00d7\n                                          \n                                             u\n                                             \n                                                o\n                                                u\n                                                t\n                                             \n                                          \n                                          \n                                             (\n                                             \n                                                u\n                                                i\n                                             \n                                             )\n                                          \n                                       \n                                       \n                                          \n                                             \u2211\n                                             \n                                                j\n                                                =\n                                                1\n                                             \n                                             N\n                                          \n                                          \n                                             u\n                                             \n                                                o\n                                                u\n                                                t\n                                             \n                                          \n                                          \n                                             (\n                                             \n                                                u\n                                                i\n                                             \n                                             )\n                                          \n                                       \n                                    \n                                    ,\n                                 \n                              \n                           \n                        where uout\n                        (ui\n                        )\u2005is the area of a grade of membership modified by the fuzzy inference result and ui\n                        \u2005is the position of the centroid of the individual membership functions.\n\nFinally, the fuzzy rule relating to rotation speed contains 27 rules, as summarized in Table\u00a03. Therefore, the reading of the first line, for example, is IF NDVI\u00a0=\u00a0Low AND Canopy Temperature\u202f=\u202fLow AND Soil Moisture\u202f=\u202fLow THEN Rotation Speed\u202f=\u202fLow. This set of rules is based on basic knowledge of irrigation, according to the methodology adopted in Bernardo,\u00a0Soares, and Mantovani\u00a0(2006) and Silva\u00a0and Azevedo\u00a0(1998).\n\nThe rules were elaborated with the connective \u201cAND\u201d and are based on the premise that little leaf growth is due to water deficit in the soil (Boyer, 1968; Hsiao, 1973; Wright, 1977) along with high canopy temperature, which indicates low evapotranspiration, in other words, plants under water stress. Values of moisture close to the soil given by the web tool are local readings of spots with fewer leaves, making it possible to estimate its value.", "title": "Fuzzy control system for variable rate irrigation using remote sensing"}, "S0888613X15000845": {"highlights": ["We introduce foxPSL, the first end-to-end distributed implementation of PSL.", "Probabilistic Soft Logic (PSL) is a template language for hinge-loss MRFs.", "foxPSL is Fast: the MAP inference is", "7", "\u00d7", "\u2013", "12", "\u00d7", "faster than the state of the art.", "foxPSL is Optimized: it implements optimizations in grounding and lazy inference.", "foxPSL is eXtended: it extends PSL with a class system and existential quantifiers."], "abstract": "In this paper, we describe foxPSL, a fast, optimized and extended implementation of Probabilistic Soft Logic (PSL) based on the distributed graph processing framework Signal/Collect. PSL is one of the leading formalisms of statistical relational learning, a recently developed field of machine learning that aims at representing both uncertainty and rich relational structures, usually by combining logical representations with probabilistic graphical models. PSL can be seen as both a probabilistic logic and a template language for hinge-loss Markov Random Fields, a type of continuous Markov Random fields (MRF) in which Maximum a Posteriori inference is very efficient, since it can be formulated as a constrained convex minimization problem, as opposed to a discrete optimization problem for standard MRFs. From the logical perspective, a key feature of PSL is the capability to represent soft truth values, allowing the expression of complex domain knowledge, like degrees of truth, in parallel with uncertainty.\n                  \n                     foxPSL supports the full PSL pipeline from problem definition to a distributed solver that implements the Alternating Direction Method of Multipliers (ADMM) consensus optimization. It provides a Domain Specific Language that extends standard PSL with a class system and existential quantifiers, allowing for efficient grounding. Moreover, it implements a series of configurable optimizations, like optimized grounding of constraints and lazy inference, that improve grounding and inference time.\n                  We perform an extensive evaluation, comparing the performance of foxPSL to a state-of-the-art implementation of ADMM consensus optimization in GraphLab, and show an improvement in both inference time and solution quality. Moreover, we evaluate the impact of the optimizations on the execution time and discuss the trade-offs related to each optimization.", "title": "foxPSL: A Fast, Optimized and eXtended PSL implementation"}, "S1319157817301143": {"highlights": ["The proposed model is a novel framework for efficient storage and retrieval of e-healthcare data.", "It performs biometric authentication of the proposed framework using priority based parallel algorithm for providing a secure access to data.", "A speedup of 9 times as compared to the speedup of existing systems was achieved.", "The system achieves EER of 0.12, sensitivity of 0.98 and specificity of 0.95."], "abstract": "Advancements in the healthcare industry have given rise to the security threat to the ever growing e-medical data. The healthcare data management system records patient\u2019s data in different formats such as text, numeric, pictures and videos leading to data which is big and unstructured. Also, hospitals may have several branches in different geographical locations. Sometimes, for research purposes, there is a need to integrate patients\u2019 health data stored at different locations. In view of this, a cloud-based healthcare management system can be an effective solution for efficient health care data management. But the major concern of cloud-based healthcare system is the security aspect. It includes theft of identity, tax fraudulence, bank fraud, insurance frauds, medical frauds and defamation of high profile patients. Hence, a secure data access and retrieval is needed in order to provide security of critical medical records in healthcare management system. Biometric based authentication mechanism is suitable in this scenario since it overcomes the limitations of token theft and forgetting passwords in the conventional token id-password mechanism used for providing security. It also has high accuracy rate for secure data access and retrieval. In the present paper, a cloud-based system for management of healthcare data BAMHealthCloud is proposed, which ensures the security of e-medical data access through a behavioral biometric signature-based authentication. Training of the signature samples for authentication purpose has been performed in parallel on Hadoop MapReduce framework using Resilient Backpropagation neural network. From rigorous experiments, it can be concluded that it achieves a speedup of 9 times, Equal error rate (EER) of 0.12, the sensitivity of 0.98 and specificity of 0.95. Performance comparison of the system with other state-of-art-algorithms shows that the proposed system preforms better than the existing systems in literature.", "title": "BAMHealthCloud: A biometric authentication and data management system for healthcare data in cloud"}, "S2589721719300212": {"highlights": ["Three simulation scenarios (ANN, MANFIS, and MANFIS+MNE) were executed.", "The MANFIS+MNE was recognized as prominent simulation scenario.", "The effect of treatments on the parameters was nonlinearly synergetic/antagonism.", "Physical perception of simulation results enrich state of the art in this domain."], "abstract": "Tendency towards computer simulations linked to agricultural machinery has enormously increased in recent years. In this regard, the principal contribution of current research was to develop soft computing simulation workplaces for performance prognostication of tractor-implement system in plowing process. Two neuro-fuzzy strategies based on multiple adaptive neuro-fuzzy inference systems (MANFIS) scenario and the MANFIS coupled with multiple nonlinear equations (MNE) scenario were executed in the workplace. Additionally, neural strategy based on artificial neural network (ANN) scenario was also fulfilled in the workplace. Operational variables of plowing depth (10\u201330\u202fcm), forward speed (2\u20136\u202fkm/h), and tillage implement type (moldboard, disk, and chisel plow) were considered as the workplace inputs and ten performance parameters were taken as the workplace outputs. According to the obtained prognostication accuracy, simulation time, and user-friendly configuration of three scenarios (ANN, MANFIS, and MANFIS+MNE), the MANFIS+MNE was recognized as the prominent simulation scenario. According to the MANFIS+MNE workplace results, for each tillage implement, the compound effect of plowing depth and forward speed on some performance parameters (required draft force of implement, tractor rear wheel slip, fuel consumption per working hour, specific volumetric fuel consumption, tractor drawbar power, energy requirement for tillage implement, overall energy efficiency, and tractor tractive efficiency) was nonlinearly synergetic. However, it was nonlinearly antagonism in case of specific draft force and fuel consumption per tilled area. The MANFIS+MNE workplace simulation results provide opportunity for technical farmer associations involved in the decision-making of agricultural machinery management in order to gain exhaustive fundamental insights into the compound effect of plowing depth and forward speed on performance of tractor-implement systems in plowing process.\n               \n            \n\ncoefficient of non-uniformity (%)\n\ncoefficient of variation (%)\n\nimplement field efficiency (%)\n\nenergy requirement for tillage implement (MJ/ha)\n\nfuel consumption per tilled area (L/ha)\n\nforward speed (km/h)\n\ngross traction force (kN)\n\nworking hour (h)\n\nimplement field capacity (ha/h)\n\nmean of used data\n\nmean of absolute values of simulation residual errors\n\nmean relative deviation modulus (%)\n\nnumber of used data\n\nnet traction force (kN)\n\noverall energy efficiency (%)\n\nplowing depth (m)\n\nith performance parameter\n\nmaximum value of performance parameter\n\nminimum value of performance parameter\n\naverage of obtained performance parameter\n\nith obtained performance parameter\n\nith simulated performance parameter\n\ncoefficient of determination\n\nroot mean square error\n\ndriving wheel slip (%)\n\nstandard deviation\n\nspecific draft force (kN/m2)\n\nspecific volumetric fuel consumption (L/kW h)\n\ntractor drawbar power (kW)\n\ntractor fuel consumption (L)\n\ntractor tractive efficiency (%)\n\nforward speed of outer radius of the fifth wheel (km/h)\n\nforward speed of outer radius of rear driving wheel of the tractor (km/h)\n\nimplement working width (m)\n\ndry weight of stubble per unit surface area (Lb/acre)\n\npercentage of stubble cover (%)", "title": "Reliable execution of a robust soft computing workplace found on multiple neuro-fuzzy inference systems coupled with multiple nonlinear equations for exhaustive perception of tractor-implement performance in plowing process"}, "S0957417417301306": {"highlights": ["We derive a linear classifier for heteroscedastic linear discriminant analysis.", "The proposed scheme efficiently minimises the Bayes error for binary classification.", "A local neighbourhood search is also proposed for non-normal distributions.", "The proposed schemes are experimentally validated on twelve datasets."], "abstract": "Under normality and homoscedasticity assumptions, Linear Discriminant Analysis (LDA) is known to be optimal in terms of minimising the Bayes error for binary classification. In the heteroscedastic case, LDA is not guaranteed to minimise this error. Assuming heteroscedasticity, we derive a linear classifier, the Gaussian Linear Discriminant (GLD), that directly minimises the Bayes error for binary classification. In addition, we also propose a local neighbourhood search (LNS) algorithm to obtain a more robust classifier if the data is known to have a non-normal distribution. We evaluate the proposed classifiers on two artificial and ten real-world datasets that cut across a wide range of application areas including handwriting recognition, medical diagnosis and remote sensing, and then compare our algorithm against existing LDA approaches and other linear classifiers. The GLD is shown to outperform the original LDA procedure in terms of the classification accuracy under heteroscedasticity. While it compares favourably with other existing heteroscedastic LDA approaches, the GLD requires as much as 60 times lower training time on some datasets. Our comparison with the support vector machine (SVM) also shows that, the GLD, together with the LNS, requires as much as 150 times lower training time to achieve an equivalent classification accuracy on some of the datasets. Thus, our algorithms can provide a cheap and reliable option for classification in a lot of expert systems.", "title": "Linear classifier design under heteroscedasticity in Linear Discriminant Analysis"}, "S0888613X13002478": {"highlights": ["The simplest possible logic of uncertainty capable of accounting for unknown propositions in the language.", "A new simple completeness proof that does not borrow from modal logic methods.", "The connection with uncertainty theories like possibility and belief functions.", "The connection with the M\u00f6bius transform."], "abstract": "The semantics of modal logics for reasoning about belief or knowledge is often described in terms of accessibility relations, which is too expressive to account for mere epistemic states of an agent. This paper proposes a simple logic whose atoms express epistemic attitudes about formulae expressed in another basic propositional language, and that allows for conjunctions, disjunctions and negations of belief or knowledge statements. It allows an agent to reason about what is known about the beliefs held by another agent. This simple epistemic logic borrows its syntax and axioms from the modal logic KD. It uses only a fragment of the S5 language, which makes it a two-tiered propositional logic rather than as an extension thereof. Its semantics is given in terms of epistemic states understood as subsets of mutually exclusive propositional interpretations. Our approach offers a logical grounding to uncertainty theories like possibility theory and belief functions. In fact, we define the most basic logic for possibility theory as shown by a completeness proof that does not rely on accessibility relations.", "title": "A simple logic for reasoning about incomplete knowledge"}, "S0957417414005478": {"highlights": ["Graph has been used to regularize nonnegative matrix factorization (NMF).", "However, noisy features and nonlinear distributed data effect the graph construction.", "We proposed to integrate feature selection and multi-kernel learning to this problem.", "Novel algorithms are developed to learn feature/kernel weights and NMF parameters."], "abstract": "Nonnegative matrix factorization (NMF), a popular part-based representation technique, does not capture the intrinsic local geometric structure of the data space. Graph regularized NMF (GNMF) was recently proposed to avoid this limitation by regularizing NMF with a nearest neighbor graph constructed from the input data set. However, GNMF has two main bottlenecks. First, using the original feature space directly to construct the graph is not necessarily optimal because of the noisy and irrelevant features and nonlinear distributions of data samples. Second, one possible way to handle the nonlinear distribution of data samples is by kernel embedding. However, it is often difficult to choose the most suitable kernel. To solve these bottlenecks, we propose two novel graph-regularized NMF methods, AGNMF\n                        FS\n                      and AGNMF\n                        MK\n                     , by introducing feature selection and multiple-kernel learning to the graph regularized NMF, respectively. Instead of using a fixed graph as in GNMF, the two proposed methods learn the nearest neighbor graph that is adaptive to the selected features and learned multiple kernels, respectively. For each method, we propose a unified objective function to conduct feature selection/multi-kernel learning, NMF and adaptive graph regularization simultaneously. We further develop two iterative algorithms to solve the two optimization problems. Experimental results on two challenging pattern classification tasks demonstrate that the proposed methods significantly outperform state-of-the-art data representation methods.", "title": "Feature selection and multi-kernel learning for adaptive graph regularized nonnegative matrix factorization"}, "S0921889016305292": {"highlights": ["Traditional approaches to the ethics of robotics are often distant from innovation practices and contexts of use.", "We list key concerns of ethics of healthcare robots.", "Collaborative and embedded ethics can help address ethics of healthcare robotics.", "Responsible research and innovation (RRI) offers a broad array of tools to ensure acceptability of technology.", "RRI in ICT can point out how social concerns can be incorporated."], "abstract": "How can we best identify, understand, and deal with ethical and societal issues raised by healthcare robotics? This paper argues that next to ethical analysis, classic technology assessment, and philosophical speculation we need forms of reflection, dialogue, and experiment that come, quite literally, much closer to innovation practices and contexts of use. The authors discuss a number of ways how to achieve that. Informed by their experience with \u201cembedded\u201d ethics in technical projects and with various tools and methods of responsible research and innovation, the paper identifies \u201cinternal\u201d and \u201cexternal\u201d forms of dialogical research and innovation, reflections on the possibilities and limitations of these forms of ethical\u2013technological innovation, and explores a number of ways how they can be supported by policy at national and supranational level.", "title": "Ethics of healthcare robotics: Towards responsible research and innovation"}, "S0888613X13002892": {"highlights": ["Lattice-valued doubly labeled transition systems (LDLTSs) to model systems with quantitative information.", "Lattice-valued similarity between LDLTSs.", "Logical characterization of lattice-valued similarity.", "Robustness and compositionality of lattice-valued similarity."], "abstract": "During the last decades, a large amount of multi-valued transition systems, whose transitions or states are labeled with specific weights, have been proposed to analyze quantitative behaviors of reactive systems. To set up a unified framework to model and analyze systems with quantitative information, in this paper, we present an extension of doubly labeled transition systems in the framework of residuated lattices, which we will refer to as lattice-valued doubly labeled transition systems (LDLTSs). Our model can be specialized to fuzzy automata over complete residuated lattices, fuzzy transition systems, and multi-valued Kripke structures. In contrast to the traditional yes/no approach to similarity, we then introduce lattice-valued similarity between LDLTSs to measure the degree of closeness of two systems, which is a value from a residuated lattice. Further, we explore the properties of robustness and compositionality of the lattice-valued similarity. Finally, we extend the Hennessy\u2013Milner logic to the residuate lattice-valued setting and show that the obtained logic is adequate and expressive with lattice-valued similarity.", "title": "Simulation for lattice-valued doubly labeled transition systems"}, "S0925231218308798": {"highlights": ["New features for real-time spam detection on Twitter.", "A new dataset of tweets for spam-detection.", "A real-time spam detection method that performs better than existing systems.", "Our analysis has shown that human spammers and social bot spammers behave similarly."], "abstract": "Online Social Media platforms, such as Facebook and Twitter, enable all users, independently of their characteristics, to freely generate and consume huge amounts of data. While this data is being exploited by individuals and organisations to gain competitive advantage, a substantial amount of data is being generated by spam or fake users. One in every 200 social media messages and one in every 21 tweets is estimated to be spam. The rapid growth in the volume of global spam is expected to compromise research works that use social media data, thereby questioning data credibility. Motivated by the need to identify and filter out spam contents in social media data, this study presents a novel approach for distinguishing spam vs.\u00a0non-spam social media posts and offers more insight into the behaviour of spam users on Twitter. The approach proposes an optimised set of features independent of historical tweets, which are only available for a short time on Twitter. We take into account features related to the users of Twitter, their accounts and their pairwise engagement with each other. We experimentally demonstrate the efficacy and robustness of our approach and compare it to a typical feature set for spam detection in the literature, achieving a significant improvement on performance. In contrast to prior research findings, we observe that an average automated spam account posted at least 12 tweets per day at well defined periods. Our method is suitable for real-time deployment in a social media data collection pipeline as an initial preprocessing strategy to improve the validity of research data.", "title": "Detection of spam-posting accounts on Twitter"}, "S0963868717304353": {"highlights": ["Increasing cyber risks demand proactive decisions for cybersecurity development.", "Significant delays exist in building capabilities for mitigating cyber incidents.", "Management experience alone does not compensate for uncertainties of events.", "Training is vital to learning about complexities and making proactive decisions.", "Management flight simulators prove to be effective training tools."], "abstract": "We developed a simulation game to study the effectiveness of decision-makers in overcoming two complexities in building cybersecurity capabilities: potential delays in capability development; and uncertainties in predicting cyber incidents. Analyzing 1479 simulation runs, we compared the performances of a group of experienced professionals with those of an inexperienced control group. Experienced subjects did not understand the mechanisms of delays any better than inexperienced subjects; however, experienced subjects were better able to learn the need for proactive decision-making through an iterative process. Both groups exhibited similar errors when dealing with the uncertainty of cyber incidents. Our findings highlight the importance of training for decision-makers with a focus on systems thinking skills, and lay the groundwork for future research on uncovering mental biases about the complexities of cybersecurity.", "title": "Decision-making and biases in cybersecurity capability development: Evidence from a simulation game experiment"}, "S0933365718304846": {"highlights": ["Case-Based Reasoning (CBR) classifies a new patient on the basis of older, known, patients.", "Most medical CBR approaches are black-box algorithms.", "We propose a visual approach for CBR, mixing quantitative and qualitative aspects.", "Our approach can also be executed as an automatic algorithm."], "abstract": "Case-Based Reasoning (CBR) is a form of analogical reasoning in which the solution for a (new) query case is determined using a database of previous known cases with their solutions. Cases similar to the query are retrieved from the database, and then their solutions are adapted to the query. In medicine, a case usually corresponds to a patient and the problem consists of classifying the patient in a class of diagnostic or therapy. Compared to \u201cblack box\u201d algorithms such as deep learning, the responses of CBR systems can be justified easily using the similar cases as examples. However, this possibility is often under-exploited and the explanations provided by most CBR systems are limited to the display of the similar cases.\n                  In this paper, we propose a CBR method that can be both executed automatically as an algorithm and presented visually in a user interface for providing visual explanations or for visual reasoning. After retrieving similar cases, a visual interface displays quantitative and qualitative similarities between the query and the similar cases, so as one can easily classify the query through visual reasoning, in a fully explainable manner. It combines a quantitative approach (visualized by a scatter plot based on Multidimensional Scaling in polar coordinates, preserving distances involving the query) and a qualitative approach (set visualization using rainbow boxes). We applied this method to breast cancer management. We showed on three public datasets that our qualitative method has a classification accuracy comparable to k-Nearest Neighbors algorithms, but is better explainable. We also tested the proposed interface during a small user study. Finally, we apply the proposed approach to a real dataset in breast cancer. Medical experts found the visual approach interesting as it explains why cases are similar through the visualization of shared patient characteristics.", "title": "Explainable artificial intelligence for breast cancer: A visual case-based reasoning approach"}, "S146708951630077X": {"highlights": ["Reduction of the amount of false positives of traditional fraud detection", "Prototype combining the red flag approach with process mining.", "Visualizing the as-is process instance of a business process with the corresponding red flags", "15 of 35 fraud cases were identified in the dataset.", "False positive rate 0.37% in the analyzed dataset"], "abstract": "Fraud detection often includes analyzing large datasets of enterprise resource planning systems to locate irregularities. Analysis of the datasets often results in a large number of false positives, that is, entries wrongly identified as fraud. The aim of our research is to reduce the number of false positives by combining the red flag-based approach with process mining. The red flag approach presents hints for unusual behavior, whereas process mining reconstructs and visualizes the as-is business process from the underlying dataset. The combination of these two techniques allows for identification and subsequent visualization of possible fraudulent process instances with the corresponding red flags. We exemplarily applied our new approach to the purchase-to-pay business process to successfully identify 15 of 31 fraud cases in our dataset. Our false positive rate was 0.37%, which is considerably lower than rates reported in similar research papers.", "title": "Reducing false positives in fraud detection: Combining the red flag approach with process mining"}, "S1474034619301855": {"highlights": ["A big data platform for day-ahead prediction of building heating and cooling demands using IoT sensors.", "Data-driven predictive model based on hybrids of k-means clustering and artificial neural network.", "Correlation analysis to determine input variables to data-driven predictive model.", "Prediction is made in each thermal zone with involvement of IoT sensors.", "Mean absolute percentage error is 3% and 8% for training and testing cases."], "abstract": "The emerging technologies of the Internet of Things (IoT) and big data can be utilised to derive knowledge and support applications for energy-efficient buildings. Effective prediction of heating and cooling demands is fundamental in building energy management. In this study, a 4-layer IoT-based big data platform is developed for day-ahead prediction of building energy demands, while the core part is the hybrid machine learning-based predictive model. The proposed energy demand predictive model is based on the hybrids of k-means clustering and artificial neural network (ANN). Due to different temperatures of walls, windows, grounds, roofs and indoor air, various IoT sensors are installed at different locations of the building. To determine the input variables to the hybrid machine learning-based predictive model, correlation analysis is adopted. Through clustering analysis, the characteristic patterns of daily weather profile are identified. Thus, the annual profile is classified into several featuring groups. Each group of weather profile, along with IoT sensor readings, building operating schedules as well as heating and cooling demands, is used to train the sub-ANN predictive models. Due to the involvement of IoT sensors, the overall prediction accuracy can be improved. It is found that the mean absolute percentage error of energy demands prediction is 3% and 8% in training and testing cases, respectively.\n               \n            \n\ncluster centroid\n\ncluster centroid subset\n\ncluster centroid dataset\n\nsquared error of two variables\n\nnumber of hour in the day\n\nnumber of the neuron in input layer of ANN model\n\nnumber of the neuron in hidden layer of ANN model\n\nnumber of the cluster in k-means clustering\n\nquantity of neurons in the hidden layer of ANN model\n\ntotal quantity of clusters\n\nquantity of days in a year\n\nglobal horizontal radiation (kJ\u202fh\u22121\u202fm\u22122)\n\nschedule\n\ntemperature (\u00b0C)\n\nenergy demand (kJ\u202fh\u22121)\n\npredicted energy demand (kJ\u202fh\u22121)\n\nclustering result\n\nweighting factor in ANN model\n\nelement in vector Y\n                     \n\ninput vector of ANN model\n\ndatabase of ANN model\n\ninput vector of k-means clustering\n\ndatabase of k-means clustering\n\neuclidean distance\n\ncorrelation coefficient\n\ninertia of internal energy\n\ncooling\n\ndry-bulb\n\noffice equipment\n\nnumber of the hour in the year\n\ninfiltration\n\nindoor air\n\ninside surface\n\nheating\n\ninternal\n\nnumber of the day in the year\n\nnumber of the building surface\n\nlighting\n\noccupant\n\noutside surface\n\nsolar\n\ntransmission\n\nventilation\n\nartificial neuron network\n\ninternet of things\n\nmean absolute percentage error\n\nsupport vector machine", "title": "Development of an IoT-based big data platform for day-ahead prediction of building heating and cooling demands"}, "S0957417418307632": {"highlights": ["MCDM has been useful to overcome the choice problem in mining and mineral processing.", "AHP has been the most used MCDM technique in this area of research.", "A large proportion of the published papers make use of hybrid methods.", "This is the first review on the use of MCDM for the choice problem in this area."], "abstract": "Despite the fact that the potential of multi-criteria decision making (MCDM) to overcome a variety of problems in mining and mineral processing has been widely recognised, no literature review in these fields has been conducted. This manuscript addresses this issue by providing a comprehensive overview of the applications and trends of MCDM methods for the choice problem (i.e., determining the best option from a set) in mining and mineral processing. 90 articles published between 1999 and 2017 were selected following a searching methodology and eligibility criteria detailed in this manuscript. In addition, for the purpose of the survey, different types of selection problems were identified. The results show that there are two phases of growth in the application of MCDM techniques to the choice problem in mining and mineral processing. The first phase, from 1999 to 2007, shows a very low number of publications with only a moderate increase by the end, whereas the second phase, from 2007 to 2017, shows a significant growth in the number of published articles. The review also shows that the most addressed problem has been the selection of mining methods, while the Analytical Hierarchy Process (AHP) has been the most used MCDM method. The rise in the application of hybrid MCDM methods is also discussed. This review paper provides insight into the current state of applications of MCDM in mining and mineral processing and discusses pathways for future research directions in the development of MCDM methods that would benefit these fields.", "title": "Multi-criteria decision making for the choice problem in mining and mineral processing: Applications and trends"}, "S0957417414006253": {"highlights": ["We present a new perspective to tag suggestion and treat it as a translation process.", "We propose two methods to estimate the translation probabilities.", "Our methods can solve the problem of vocabulary gap.", "Our methods are effective and robust compared with other methods.", "Our methods are relatively simple and efficient, which makes them practical."], "abstract": "The task of social tag suggestion is to recommend tags automatically for a user when he or she wants to annotate an online resource. In this study, we focus on how to make use of the text description of a resource to suggest tags. It is intuitive to select significant words from the text description of a source as the suggested tags. However, since users can arbitrarily annotate any tags to a resource, tag suggestion suffers from the vocabulary gap issue \u2014 the appropriate tags of a resource may be statistically insignificant or even do not appear in the corresponding description. In order to solve the vocabulary gap issue, in this paper we present a new perspective on social tag suggestion. By considering both a description and tags as summaries of a given resource composed in two languages, tag suggestion can be regarded as a translation from description to tags. We propose two methods to estimate the translation probabilities between words in descriptions and tags. Based on the translation probabilities between words and tags estimated for a large collection of description-tags pairs, we can suggest tags according to the words in a resource description. Experiments on real-world datasets indicate that our methods outperform other methods in precision, recall and F-measure. Moreover, our methods are relatively simple and efficient, which makes them practical for Web applications.", "title": "Estimating translation probabilities for social tag suggestion"}, "S0888613X13002934": {"highlights": ["We define inconsistency management policies (IMPs) for real world applications.", "We show how IMPs relate to belief revision postulates, CQA, and relational algebra operators.", "We present several approaches to efficiently implement an IMP-based framework."], "abstract": "Though inconsistency management in databases and AI has been studied extensively for years, it does not allow the user to specify how he wants to resolve inconsistencies. In real-world applications, users may want to manage or resolve inconsistencies based not only on the data, but their own knowledge of the risks involved in decision making based on faulty data. Each user should be empowered to use reasonable policies to deal with his data and his mission needs. In this paper, we start by providing an axiomatic definition of inconsistency management policies (IMPs) that puts this power in the hands of users. Any function satisfying these axioms is an IMP. We then define three broad families of IMPs, and derive several results that show (i) how these policies relate to postulates for the revision of belief bases and to recent research in the area of consistent query answering, and (ii) how they interact with standard relational algebra operators. Finally, we present several approaches to efficiently implement an IMP-based framework.", "title": "Policy-based inconsistency management in relational databases"}, "S095741741830808X": {"highlights": ["Anomaly detection with signal reconstruction and residuals analysis.", "Reduced computation time, due to use of training data clustering.", "Applied on 14 imbalanced datasets, including recent data from a marine diesel engine in operation.", "Regional credibility estimation used in the residuals analysis."], "abstract": "We propose novel modifications to an anomaly detection methodology based on multivariate signal reconstruction followed by residuals analysis. The reconstructions are made using Auto Associative Kernel Regression (AAKR), where the query observations are compared to historical observations called memory vectors, representing normal operation. When the data set with historical observations grows large, the naive approach where all observations are used as memory vectors will lead to unacceptable large computational loads, hence a reduced set of memory vectors should be intelligently selected. The residuals between the observed and the reconstructed signals are analysed using standard Sequential Probability Ratio Tests (SPRT), where appropriate alarms are raised based on the sequential behaviour of the residuals.\n                  The modifications we introduce include: a novel cluster based method to select memory vectors to be considered by the AAKR, which gives an extensive reduction in computation time; a generalization of the distance measure, which makes it possible to distinguish between explanatory and response variables; and a regional credibility estimation used in the residuals analysis, to let the time used to identify if a sequence of query vectors represents an anomalous state or not, depend on the amount of data situated close to or surrounding the query vector.\n                  We demonstrate how the anomaly detection method and the proposed modifications can be successfully applied for anomaly detection on a set of imbalanced benchmark data sets, as well as on recent data from a marine diesel engine in operation.", "title": "Efficient on-line anomaly detection for ship systems in operation"}, "S2590188519300137": {"highlights": ["Introducing the extraction of actionable knowledge from social networks involving node attributes.", "Formulating the action extraction process as an optimization problem.", "Extracting mostly qualitative actions in terms of cost and effectiveness.", "Exploiting heuristics to extract actions more efficiently."], "abstract": "Actionable Knowledge Discovery has attracted much interest lately. It is almost a new paradigm shift toward mining more usable and more applicable knowledge in each specific domain. An action is a new tool in this research area that suggests some changes to the user to gain a profit in his/her domain. Currently, most of action mining methods rely on simple data which describes each object independently. Since social data has more complex structure due to the relationships between individuals, a major problem is that such structural information is not taken into account in the action mining process. This leads to miss some useful knowledge and profitable actions. Consequently, more effective methods are needed for mining actions.\n                  The main focus of this work is to extract cost-effective actions from social networks in which nodes have attributes. The actions suggest optimal changes in nodes\u2019 attributes that are likely to result in changing labels of users to more desired one when they are applied. We develop an action mining method based on Random Walks that naturally combines the information from the network structure with nodes attributes. We formulate action mining as an optimization problem where the goal is to learn a function that varies the values of nodes\u2019 attributes which in turn affect edges\u2019 weights in the network so that the labels of intended individuals are likely to take the desired label while minimizing the cost of incurring the changes. Experiments confirm that the proposed approach outperforms the current state-of-the-art in action mining.", "title": "Extracting actionable knowledge from social networks with node attributes"}, "S107158191930076X": {"highlights": ["Genesis of research into online personalisation.", "Drawing a bow from Machine Learning evaluation methodology to the theories of cognitive science.", "Identification of emerging topics within the integrated research domain.", "Future research agenda from the viewpoints of different disciplines."], "abstract": "Research on understanding, developing and assessing personalisation systems is spread over multiple disciplines and builds on methodologies and findings from several different research fields and traditions, such as Artificial Intelligence (AI), Machine Learning (ML), Human\u2013Computer Interaction (HCI), and User Modelling based on (applied) social and cognitive psychology. The fields of AI and ML primarily focus on the optimisation of personalisation applications, and concentrate on creating ever more accurate algorithmic decision makers and prediction models. In the fields of HCI and Information Systems, scholars are primarily interested in the phenomena around the use and interaction with personalisation systems, while Cognitive Science (partly) delivers the theoretical underpinnings for the observed effects. The aim and contribution of this work is to put together the pieces about the impact of personalisation and recommendation systems from these different backgrounds in order to formulate a research agenda and provide a perspective on future developments.", "title": "Measuring the impact of online personalisation: Past, present and future"}, "S1875952116300209": {"highlights": ["Affective haptics in entertainment.", "Expressive haptic sensations.", "Mood music in film entertainment.", "Prototyping.", "Users evaluation of multimodal experience."], "abstract": "This is an exploratory work aimed at enhancing mood music in film entertainment. We present the design and implementation of a haptic wearable prototype system which aims to amplify mood music in film through haptic sensations (vibrotactile feedback). This approach also could potentially have implications for hearing-impaired audiences, providing a new enriched emotional experience while watching a movie. This paper reports on a set of three studies conducted to assess whether vibrotactile stimuli are able to enhance moods. Preliminary findings show that vibrotacile stimuli at low intensity and low frequency induce a sense of calmness in users, whereas vibrotactile stimuli at low intensity but higher frequency increased excitement. The combination of high intensity and high frequency vibrotactile stimuli heightened tension on the other hand. These findings support our position that vibrotactile feedback could be used to enrich the emotional aspects of cinematic experience through haptic sensations.", "title": "Mood Glove: A haptic wearable prototype system to enhance mood music in film"}, "S1071581914001268": {"highlights": ["Author-Highlights", "We have examined which metadata cues are used when deciding to consume content.", "The online experiment used Twitter content and users as its subject.", "Users prefer content from someone with whom they already have a relationship.", "Users prefer content judged by others to have value (based on number of retweets).", "Clear metadata signals can affect decision making in content consumption."], "abstract": "Social micro-blogging systems such as Twitter are designed for rapid and informal communication from a large potential number of participants. Due to the volume of content received, human users must typically skim their timeline of received content and exercise judgement in selecting items for consumption, necessitating a selection process based on heuristics and content meta-data. This selection process is not well understood, yet is important due to its potential use in content management systems.\n                  In this research we have conducted an open online experiment in which participants are shown quantitative and qualitative meta-data describing two pieces of Twitter content. Without revealing the text of the tweet, participants are asked to make a selection. We observe the decisions made from 239 surveys and discover insights into human behaviour on decision making for content selection. We find that for qualitative meta-data consumption decisions are driven by online friendship and for quantitative meta-data the largest numerical value presented influences choice. Overall, the \u2018number of retweets\u2019 is found to be the most influential quantitative meta-data, while displaying multiple cues about an author\u05f3s identity provides the strongest qualitative meta-data. When both quantitative and qualitative meta-data is presented, it is the qualitative meta-data (friendship information) that drives selection. The results are consistent with application of the Recognition heuristic, which postulates that when faced with constrained decision-making, humans will tend to exercise judgement based on cues representing familiarity. These findings are useful for future interface design for content filtering and recommendation systems.", "title": "Human content filtering in Twitter: The influence of metadata"}, "S0933365716301026": {"highlights": ["We propose a method for smoothing recognition results of NBI endoscopic video frames.", "It is robust to defocused frames by using defocus information extracted from frames.", "We develop a particle filter with the Dirichlet distribution.", "The Rayleigh distribution is used for the defocus information and the likelihood.", "Experimental results are shown with synthetic and real NBI endoscopic videos."], "abstract": "Background and objective\n                  A computer-aided system for colorectal endoscopy could provide endoscopists with important helpful diagnostic support during examinations. A straightforward means of providing an objective diagnosis in real time might be for using classifiers to identify individual parts of every endoscopic video frame, but the results could be highly unstable due to out-of-focus frames. To address this problem, we propose a defocus-aware Dirichlet particle filter (D-DPF) that combines a particle filter with a Dirichlet distribution and defocus information.\n               \n               \n                  Methods\n                  We develop a particle filter with a Dirichlet distribution that represents the state transition and likelihood of each video frame. We also incorporate additional defocus information by using isolated pixel ratios to sample from a Rayleigh distribution.\n               \n               \n                  Results\n                  We tested the performance of the proposed method using synthetic and real endoscopic videos with a frame-wise classifier trained on 1671 images of colorectal endoscopy. Two synthetic videos comprising 600 frames were used for comparisons with a Kalman filter and D-DPF without defocus information, and D-DPF was shown to be more robust against the instability of frame-wise classification results. Computation time was approximately 88ms/frame, which is sufficient for real-time applications. We applied our method to 33 endoscopic videos and showed that the proposed method can effectively smoothen highly unstable probability curves under actual defocus of the endoscopic videos.\n               \n               \n                  Conclusion\n                  The proposed D-DPF is a useful tool for smoothing unstable results of frame-wise classification of endoscopic videos to support real-time diagnosis during endoscopic examinations.", "title": "Defocus-aware Dirichlet particle filter for stable endoscopic video frame recognition"}, "S0736584516300606": {"highlights": ["This paper aims to establish an accurate measurement technique using Laser Radar for wind turbine blade inspection.", "Degrees of Freedom are used for data point transformation.", "B-Spline curves are constructed to compare with the complex curved surface profiles of the CAD blade.", "Experimental procedures and data transformations are proposed for future industrial implementation."], "abstract": "Large-scale offshore wind turbine blades need careful dimensional inspection at the production stage. This paper aims to establish an accurate measurement technique using Coherent Laser Radar technology combined with B-Spline point generation and alignment. Through varying the Degrees of Freedom (DoF), used for data point transformation, within the Spatial Analyser software package, erroneous inspection results generated by unconstrained blade flexing can be eradicated. The paper concludes that implementing a single B-Spline point generation and alignment method, whilst allowing transformation with DoF in X, Y and Rz, provides confidence to wind turbine blade manufacturers that inspection data is accurate. The experimental procedure described in this paper can also be applied to the precision inspection of other large-scale non-rigid, unconstrained objects.", "title": "Investigating the measurement of offshore wind turbine blades using coherent laser radar"}, "S0888613X14000619": {"highlights": ["We explore strategic two-player games with payoffs given by McNaughton functions.", "Sufficient conditions for the existence of finite Nash equilibria are provided.", "The algorithm for computing such equilibria is presented.", "The result directly generalizes to n-player strategic games."], "abstract": "The aim of the paper is to explore strategic reasoning in strategic games of two players with an uncountably infinite space of strategies the payoff of which is given by McNaughton functions\u2014functions on the unit interval which are piecewise linear with integer coefficients. McNaughton functions are of a special interest for approximate reasoning as they correspond to formulas of infinitely valued Lukasiewicz logic. The paper is focused on existence and structure of Nash equilibria and algorithms for their computation. Although the existence of mixed strategy equilibria follows from a general theorem (Glicksberg, 1952) [5], nothing is known about their structure neither the theorem provides any method for computing them. The central problem of the article is to characterize the class of strategic games with McNaughton payoffs which have a finitely supported Nash equilibrium. We give a sufficient condition for finite equilibria and we propose an algorithm for recovering the corresponding equilibrium strategies. Our result easily generalizes to n-player strategic games which don't need to be strictly competitive with a payoff functions represented by piecewise linear functions with real coefficients. Our conjecture is that every game with McNaughton payoff allows for finitely supported equilibrium strategies, however we leave proving/disproving of this conjecture for future investigations.\n               \n            \n\nStrategic considerations of players in the theory of noncooperative games [20] represent one of the classical examples of reasoning under uncertainty. In this paper we focus on a particular class of games, where the goals of players can be expressed as a formula of a formal language. Typically we assume that the formula represents a claim and the goal of one player is to show that the claim is true, while the goal of the other one is to disprove it. Truth or falsity of the claim depend on parameters which players can control, such as the values of atomic formulas in the case the language in question is that of propositional logic. Each of the players can influence values of some parameters, while the remaining ones are under the control of the other player. Informally, we can imagine that a player makes a statement \u201cthere is a situation, which I can demonstrate by choosing appropriate values for the parameters under my control, in which the claim is true/false (independently of the remaining parameters)\u201d.\n\nThis kind of game is well-known in literature. In [8] the assertion in question is expressed in classical propositional logic and parameters are Boolean variables divided into disjoint sets, each of which is under the control of one of the players.\n\nFrom the logical point of view, we shall deal with a more general set-up in which the goals of players might generally be satisfied only up to some degree. Reasoning with claims evaluated on a non-dichotomic scale is the natural domain of many-valued logics [7], which offer versatile tools to model the statements which are not just true or false, but which can take an intermediate truth value. Although we are considering games of two players with each of them controlling only a single propositional variable, the complexity of strategic considerations increases radically as the space of strategies is a continuum. This is in sharp contrast with the finite space considered in Boolean games. Marchioni and Wooldridge [11] present a generalization of Boolean games towards many-valued logics similar to our approach\u2014the goals of players are represented by a formula in \u0141ukasiewicz logic. In comparison to our approach they admit only finitely many truth values, but allow any finite number of players. Moreover, the game they introduce need not be strictly competitive.\n\nThe extension to uncountably-many truth-values has two important features from the viewpoint of game modeling and representation. First, the continuum of truth values enables us to capture a much larger space of payoff functions than with the Boolean games. Second, it also introduces a new kind of uncertainty into game-theoretical reasoning. Probability is standard equipment used in game theory\u2014it appears naturally when the notion of a mixed strategy is introduced as randomizing over deterministic choices of (pure) strategies. Introducing many-valued framework, on the other hand, provides a broader scale for approximate reasoning about strategies: the players have to consider combining probability with graded truth values.", "title": "Optimal strategic reasoning with McNaughton functions"}, "S0963868717302615": {"highlights": ["Six debates on how organizations realize value from big data are identified.", "Portability and interconnectivity are socio-technical features of big data.", "Cross-level interactions influence big data value realization.", "An integrated model of big data value realization is suggested."], "abstract": "Big data has been considered to be a breakthrough technological development over recent years. Notwithstanding, we have as yet limited understanding of how organizations translate its potential into actual social and economic value. We conduct an in-depth systematic review of IS literature on the topic and identify six debates central to how organizations realize value from big data, at different levels of analysis. Based on this review, we identify two socio-technical features of big data that influence value realization: portability and interconnectivity. We argue that, in practice, organizations need to continuously realign work practices, organizational models, and stakeholder interests in order to reap the benefits from big data. We synthesize the findings by means of an integrated model.", "title": "Debating big data: A literature review on realizing value from big data"}, "S0925231213010916": {"highlights": ["An efficient training algorithm for a dendrite morphological neural network.", "Convergence in a finite number of steps.", "Perfect classification of the training data.", "No overlap between hyper-cubes with distinct class labels.", "The algorithm can be applied to classification problems of p classes and n attributes."], "abstract": "This paper introduces an efficient training algorithm for a dendrite morphological neural network (DMNN). Given p classes of patterns, C\n                     \n                        k\n                     , k=1, 2, \u2026, p, the algorithm selects the patterns of all the classes and opens a hyper-cube HC\n                     \n                        n\n                      (with n dimensions) with a size such that all the class elements remain inside HC\n                     \n                        n\n                     . The size of HC\n                     \n                        n\n                      can be chosen such that the border elements remain in some of the faces of HC\n                     \n                        n\n                     , or can be chosen for a bigger size. This last selection allows the trained DMNN to be a very efficient classification machine in the presence of noise at the moment of testing, as we will see later. In a second step, the algorithm divides the HC\n                     \n                        n\n                      into 2\n                        n\n                      smaller hyper-cubes and verifies if each hyper-cube encloses patterns for only one class. If this is the case, the learning process is stopped and the DMNN is designed. If at least one hyper-cube HC\n                     \n                        n\n                      encloses patterns of more than one class, then HC\n                     \n                        n\n                      is divided into 2\n                        n\n                      smaller hyper-cubes. The verification process is iteratively repeated onto each smaller hyper-cube until the stopping criterion is satisfied. At this moment the DMNN is designed. The algorithm was tested for benchmark problems and compare its performance against some reported algorithms, showing its superiority.", "title": "Efficient training for dendrite morphological neural networks"}, "S2590188519300149": {"highlights": ["Propose a new feature selection method.", "The method combines kernel canonical correlation analysis and mutual information.", "Incomplete Cholesky Decomposition is used to approximate the kernel matrix.", "Experimental results show the better performance of the proposed method."], "abstract": "This paper proposes a filter-based feature selection method by combining the measurement of kernel canonical correlation analysis (KCCA) with the mutual information (MI)-based feature selection method, named mRMJR-KCCA. The mRMJR-KCCA maximizes the relevance between the feature candidate and the target class labels and simultaneously minimizes the joint redundancy between the feature candidate and the already selected features in the view of KCCA. To improve the computation efficiency, we adopt the Incomplete Cholesky Decomposition to approximate the kernel matrix in implementing the KCCA in mRMJR-KCCA for larger-size datasets. The proposed method is experimentally evaluated on 13 classification-associated datasets. Compared with certain popular feature selection methods, the experimental results demonstrate the better performance of the proposed mRMJR-KCCA.", "title": "Mutual information inspired feature selection using kernel canonical correlation analysis"}, "S0888613X14000474": {"highlights": ["Extend the light-weight DL ELOR to allow subjective probabilities.", "Compute generalization inferences for a probabilistic description logic.", "Empirical evaluation of a prototypical tool."], "abstract": "Description Logics (DLs) are a well-established family of knowledge representation formalisms. One of its members, the DL \n                        ELOR\n                      has been successfully used for representing knowledge from the bio-medical sciences, and is the basis for the OWL 2 EL profile of the standard ontology language for the Semantic Web. Reasoning in this DL can be performed in polynomial time through a completion-based algorithm.\n                  In this paper we study the logic Prob-\n                        ELOR\n                     , that extends \n                        ELOR\n                      with subjective probabilities, and present a completion-based algorithm for polynomial time reasoning in a restricted version, Prob-\n                        \n                           \n                              ELOR\n                           \n                           \n                              c\n                           \n                           \n                              01\n                           \n                        \n                     , of Prob-\n                        ELOR\n                     . We extend this algorithm to computation algorithms for approximations of (i) the most specific concept, which generalizes a given individual into a concept description, and (ii) the least common subsumer, which generalizes several concept descriptions into one. Thus, we also obtain methods for these inferences for the OWL 2 EL profile. These two generalization inferences are fundamental for building ontologies automatically from examples. The feasibility of our approach is demonstrated empirically by our prototype system Gel.", "title": "Completion-based generalization inferences for the Description Logic ELOR with subjective probabilities"}, "S0957417417308138": {"highlights": ["A novel feature extraction technique (3D-LESH) for 3D image analysis is proposed.", "Application of proposed technique to detect cancer.", "Successful experimentation on TCGA-BRCA breast cancer MRI dataset.", "Achieved maximum classification accuracy of 99% to detect breast cancer.", "Achieved maximum classification accuracy of 95% to detect breast cancer stages."], "abstract": "In this paper, we present a novel feature extraction technique, termed Three-Dimensional Local Energy-Based Shape Histogram (3D-LESH), and exploit it to detect breast cancer in volumetric medical images. The technique is incorporated as part of an intelligent expert system that can aid medical practitioners making diagnostic decisions. Analysis of volumetric images, slice by slice, is cumbersome and inefficient. Hence, 3D-LESH is designed to compute a histogram-based feature set from a local energy map, calculated using a phase congruency (PC) measure of volumetric Magnetic Resonance Imaging (MRI) scans in 3D space. 3D-LESH features are invariant to contrast intensity variations within different slices of the MRI scan and are thus suitable for medical image analysis.\n                  The contribution of this article is manifold. First, we formulate a novel 3D-LESH feature extraction technique for 3D medical images to analyse volumetric images. Further, the proposed 3D-LESH algorithmis, for the first time, applied to medical MRI images. The final contribution is the design of an intelligent clinical decision support system (CDSS) as a multi-stage approach, combining novel 3D-LESH feature extraction with machine learning classifiers, to detect cancer from breast MRI scans. The proposed system applies contrast-limited adaptive histogram equalisation (CLAHE) to the MRI images before extracting 3D-LESH features. Furthermore, a selected subset of these features is fed into a machine-learning classifier, namely, a support vector machine (SVM), an extreme learning machine (ELM) or an echo state network (ESN) classifier, to detect abnormalities and distinguish between different stages of abnormality. We demonstrate the performance of the proposed technique by its application to benchmark breast cancer MRI images. The results indicate high-performance accuracy of the proposed system (98%\u00b10.0050, with an area under a receiver operating charactertistic curve value of 0.9900\u202f\u00b1\u202f0.0050) with multiple classifiers. When compared with the state-of-the-art wavelet-based feature extraction technique, statistical analysis provides conclusive evidence of the significance of our proposed 3D-LESH algorithm.", "title": "Three-Dimensional Local Energy-Based Shape Histogram (3D-LESH): A Novel Feature Extraction Technique"}, "S0736584514000295": {"highlights": ["A cable feeder tool for robotized cable winding has been developed and constructed.", "Experiments validating automated cable winding assembly in this tool are presented.", "The functions of the tool is explained in detail and validated through experiments.", "An Uppsala University Wave Energy Converter cable wound stator is used as the reference.", "The cable feeder tool can be used for different stator designs, winding patterns and cables."], "abstract": "Cable winding is an alternative technology to create stator windings in large electrical machines. Today such cable winding is performed manually, which is very repetitive, time-consuming and therefore also expensive. This paper presents the design, function and control system of a developed cable feeder tool for robotized stator cable winding. The presented tool was able to catch a cable inside a cable guiding system and to grab the cable between two wheels. One of these wheels was used to feed cable through the feeder. A control system was integrated in the tool to detect feeding slippage and to supervise the feeding force on the cable. Functions to calculate the cable feed length, to release the cable from the tool and for positional calibration of the stator to be wound were also integrated in the tool. In validating the function of the cable feeder tool, the stator of the linear generator used in the Wave Energy Converter generator developed at Uppsala University was used as an example. Through these experiments, it was shown that the developed robot tool design could be used to achieve automated robotized cable winding. These results also complied with the cycle time assumptions for automated cable winding from earlier research. Hence, it was theoretically indicated that the total winding cycle time for one Uppsala University Wave Energy Converter stator could be reduced from about 80h for manual winding with four personnel to less than 20h in a fully developed cable winding robot cell. The same robot tool and winding automation could also be used, with minor adjustments, for other stator designs.", "title": "A cable feeder tool for robotized cable winding"}, "S0888613X15000882": {"highlights": ["Two classes of errors in binary data tables (formal contexts) are studied.", "Finding errors based on computing an implication base leads to intractable solution.", "Finding errors based on closure computation allows for a polynomial algorithm.", "Finding errors in a data table row (object intent) is described and illustrated.", "Experiments demonstrate the efficiency of finding errors via closure computation."], "abstract": "Errors in implicative theories coming from binary data are studied. First, two classes of errors that may affect implicative theories are singled out. Two approaches for finding errors of these classes are proposed, both of them based on methods of Formal Concept Analysis. The first approach uses the cardinality minimal (canonical or Duquenne\u2013Guigues) implication base. The construction of such a base is computationally intractable. Using an alternative approach one checks possible errors on the fly in polynomial time via computing closures of subsets of attributes. Both approaches are interactive, based on questions about the validity of certain implications. Results of computer experiments are presented and discussed.", "title": "Interactive error correction in implicative theories"}, "S0921889015000846": {"highlights": ["A probabilistic approach for task-specific category based grasping is proposed.", "The grasp stability is maximized probabilistically over shape uncertainty.", "The approach integrates information over all training objects for better generalization.", "The technique can cope with a sparser training set than most data-driven methods.", "Only incomplete point clouds obtained from a single RGB-D image are needed."], "abstract": "The problem of finding stable grasps has been widely studied in robotics. However, in many applications the resulting grasps should not only be stable but also applicable for a particular task. Task-specific grasps are closely linked to object categories so that objects in a same category can be often used to perform the same task. This paper presents a probabilistic approach for task-specific stable grasping of objects with shape variations inside the category. An optimal grasp is found as a grasp that is maximally likely to be task compatible and stable taking into account shape uncertainty in a probabilistic context. The method requires only partial models of new objects for grasp generation and only few models and example grasps are used during the training stage. The experiments show that the approach can use multiple models to generalize to new objects in that it outperforms grasping based on the closest model. The method is shown to generate stable grasps for new objects belonging to the same class as well as for similar in shape objects of different categories.", "title": "Category-based task specific grasping"}, "S0933365717305067": {"highlights": ["This survey paper presents recent works proposing neural network models for cancer prediction related problems. All the considered works used gene expression datasets to experiment the proposed models.", "The survey is distinguished from previous works by analysing the contributions that included three basic components which are: Neural networks, gene expression datasets and cancer prediction. The survey also presents technical details related to data preprocessing, model configuration, learning parameters and the evaluation metrics which give the reader ideas about recent approaches.", "We grouped the considered works according to the neural network functionality in the model. Starting with presenting preprocessing techniques, then the models configuration and evaluation metrics and a summary at the end.", "A discussion for better future practice was given at the end to highlight some practical issues that can be considered to increase future models predictability."], "abstract": "Neural networks are powerful tools used widely for building cancer prediction models from microarray data. We review the most recently proposed models to highlight the roles of neural networks in predicting cancer from gene expression data. We identified articles published between 2013\u20132018 in scientific databases using keywords such as cancer classification, cancer analysis, cancer prediction, cancer clustering and microarray data. Analyzing the studies reveals that neural network methods have been either used for filtering (data engineering) the gene expressions in a prior step to prediction; predicting the existence of cancer, cancer type or the survivability risk; or for clustering unlabeled samples. This paper also discusses some practical issues that can be considered when building a neural network-based cancer prediction model. Results indicate that the functionality of the neural network determines its general architecture. However, the decision on the number of hidden layers, neurons, hypermeters and learning algorithm is made using trail-and-error techniques.", "title": "A survey of neural network-based cancer prediction models from microarray data"}, "S0142061518336305": {"highlights": ["Partial discharge (PD) can be initiated in XLPE cable system by superimposed impulses.", "The initiated PD may extinguish or persist actively under AC voltage after impulses.", "PD under impulse depends on local electric field, defects condition and aging status.", "Multiple impulses may decrease PD inception voltage or accelerate the aging process."], "abstract": "In practice, cross-linked polyethylene (XLPE) power cables can be subjected to alternating voltage with superimposed impulse transients. Such impulse transients may initiate partial discharges (PD) in insulation defects even below AC inception voltage. An initiated PD may persist under AC, which will cause insulation degradation. This paper investigates the PD behavior in MV XLPE cable accessories under impulse transients. Different scenarios of PD behavior are measured, described and analyzed. Based on the results, the effects of impulse transients on PD are summarized.", "title": "The effects of superimposed impulse transients on partial discharge in XLPE cable joint"}, "S1875952118300260": {"highlights": ["Practice of emotion-regulation using biofeedback improves performance on a decision-making task in serious games.", "Visual and gameplay biofeedback presentation in serious games supports emotion-regulation skill.", "Serious games have been validated as an effective platform for practicing emotion-regulation."], "abstract": "Evidence shows that emotions critically influence human decision-making. Therefore, emotion-regulation using biofeedback has been extensively investigated. Nevertheless, serious games have emerged as a valuable tool for such investigations set in the decision-making context. This review sets out to investigate the scientific evidence regarding the effects of practicing emotion-regulation through biofeedback on the decision-making performance in the context of serious games. A systematic search of five electronic databases (Scopus, Web of Science, IEEE, PubMed Central, Science Direct), followed by the author and snowballing investigation, was conducted from a publication\u2019s year of inception to October 2018. The search identified 16 randomized controlled experiment/quasi-experiment studies that quantitatively assessed the performance on decision-making tasks in serious games, involving students, military, and brain-injured participants. It was found that the participants who raised awareness of emotions and increased the skill of emotion-regulation were able to successfully regulate their arousal, which resulted in better decision performance, reaction time, and attention scores on the decision-making tasks. It is suggested that serious games provide an effective platform validated through the evaluative and playtesting studies, that supports the acquisition of the emotion-regulation skill through the direct (visual) and indirect (gameplay) biofeedback presentation on decision-making tasks.", "title": "Practicing emotion-regulation through biofeedback on the decision-making performance in the context of serious games: A systematic review"}, "S0933365717304402": {"highlights": ["We present an openEHR based approach to design interoperable Clinical Decision-Support Systems.", "We describe data modelling and integration, terminology binding and querying, and system design.", "We investigate the feasibility by evaluating the technical capabilities of the system on real clinical data sets."], "abstract": "Background\n                  Clinical decision-support systems (CDSS) are designed to solve knowledge-intensive tasks for supporting decision-making processes. Although many approaches for designing CDSS have been proposed, due to high implementation costs, as well as the lack of interoperability features, current solutions are not well-established across different institutions. Recently, the use of standardized formalisms for knowledge representation as terminologies as well as the integration of semantically enriched clinical information models, as openEHR Archetypes, and their reuse within CDSS are theoretically considered as key factors for reusable CDSS.\n               \n               \n                  Objective\n                  We aim at developing and evaluating an openEHR based approach to achieve interoperability in CDSS by designing and implementing an exemplary system for automated systemic inflammatory response syndrome (SIRS) detection in pediatric intensive care.\n               \n               \n                  Methods\n                  We designed an interoperable concept, which enables an easy integration of the CDSS across different institutions, by using openEHR Archetypes, terminology bindings and the Archetype Query Language (AQL). The practicability of the approach was tested by (1) implementing a prototype, which is based on an openEHR based data repository of the Hannover Medical School (HaMSTR), and (2) conducting a first pilot study.\n               \n               \n                  Results\n                  We successfully designed and implemented a CDSS with interoperable knowledge bases and interfaces by reusing internationally agreed-upon Archetypes, incorporating LOINC terminology and creating AQL queries, which allowed retrieving dynamic facts in a standardized and unambiguous form. The technical capabilities of the system were evaluated by testing the prototype on 16 randomly selected patients with 129 days of stay, and comparing the results with the assessment of clinical experts (leading to a sensitivity of 1.00, a specificity of 0.94 and a Cohen\u2019s kappa of 0.92).\n               \n               \n                  Conclusions\n                  We found the use of openEHR Archetypes and AQL a feasible approach to bridge the interoperability gap between local infrastructures and CDSS. The designed concept was successfully transferred into a clinically evaluated openEHR based CDSS. To the authors\u2019 knowledge, this is the first openEHR based CDSS, which is technically reliable and capable in a real context, and facilitates clinical decision-support for a complex task. Further activities will comprise enrichments of the knowledge base, the reasoning processes and cross-institutional evaluations.", "title": "An interoperable clinical decision-support system for early detection of SIRS in pediatric intensive care using openEHR"}, "S0921889017302439": {"highlights": ["Develop a neuroanatomically grounded spiking neural network for visual attention with a word learning capability.", "Demonstrates that a label could be associated with a salient object via Spike-Timing Dependent Plasticity in a simple system.", "Provides a proof-of-concept case for the integration of biologically inspired neural networks with robotics for basic language acquisition."], "abstract": "Recent advances in behavioural and computational neuroscience, cognitive robotics, and in the hardware implementation of large-scale neural networks, provide the opportunity for an accelerated understanding of brain functions and for the design of interactive robotic systems based on brain-inspired control systems. This is especially the case in the domain of action and language learning, given the significant scientific and technological developments in this field. In this work we describe how a neuroanatomically grounded spiking neural network for visual attention has been extended with a word learning capability and integrated with the iCub humanoid robot to demonstrate attention-led object naming. Experiments were carried out with both a simulated and a real iCub robot platform with successful results. The iCub robot is capable of associating a label to an object with a \u2018preferred\u2019 orientation when visual and word stimuli are presented concurrently in the scene, as well as attending to said object, thus naming it. After learning is complete, the name of the object can be recalled successfully when only the visual input is present, even when the object has been moved from its original position or when other objects are present as distractors.", "title": "Visual attention and object naming in humanoid robots using a bio-inspired spiking neural network"}, "S0957417417307662": {"highlights": ["A non-sequential method for classifying sounds is proposed.", "The procedure relies on featuring frame sounds using MPEG-7 parameters.", "Several machine learning classifiers are compared and the decision tree is selected.", "It has been applied to classify anuran sounds as an indicator of global warming."], "abstract": "Several biological research studies have shown that the number of individuals of certain species of anurans in a specific geographical region, and the evolution of this number over time, can be used as an indicator of climate change. To detect the presence of anurans, Wireless Sensor Networks (WSNs) are usually deployed with the aim of obtaining bio-acoustic information in a set covering numerous locations. However, the identification of the anuran species from a huge number of recordings usually involves an overwhelming task that has to be undertaken by expert and intelligent systems. Previous studies into this issue have proposed several classification techniques with a common approach: they all take into account the sequential characteristic of sounds by considering syllables or other kinds of vocal segments. In noisy sounds, as it is usually the case in recordings made in natural habitats, segmentation of the signal is no straightforward task and may cause low classification accuracy. To override this problem, a new non-sequential approach is proposed in this paper. It is based on considering very small pieces of sounds (frames) each of which is then classified without considering preceding or subsequent information. Up to nine frame-based classifiers are explored in this paper and their performances are compared to the most commonly used sequential classifier: the Hidden Markov Model (HMM). Additionally, for featuring the frames, many choices have been described, although the application of the Mel Frequency Cepstral Coefficients (MFCCs) has probably become the most common method. In this work, an alternative methodology is suggested: the use of a set of MPEG-7 parameters, which offers a normalized solution with a much greater semantic content. The experimental results have shown that the proposed method clearly outperforms the HMM, thereby showing the non-sequential classification of anuran sounds to be feasible. From among the algorithms tested, the decision-tree classifier has shown the best performance with an overall classification success rate of 87.30%, which is an especially striking result considering that the analyzed sounds were affected by a decidedly noisy background.", "title": "Non-sequential automatic classification of anuran sounds for the estimation of climate-change indicators"}, "S0925231219309191": {"highlights": ["A collaborative binary-real DE is developed for optimization problem with mixed variables.", "A two-stage approach is presented for optimizing simultaneously ANN architecture and weights.", "The proposed approach can fast gain ANNs with compact architecture and good generalization ability."], "abstract": "This paper presents a two-stage approach, denoted as CBRDE-LM, to evolve the architecture and weights of feedforward artificial neural networks. In the first stage, a collaborative binary-real differential evolution (CBRDE) is used to optimize simultaneously network architecture and connection weights of an ANN by a specific individual representation and evolutionary scheme, in which the structure is indirectly represented as binary coding and connection weights are directly encoded by real-valued coding. In the second stage, based on the resulting architecture and weights of an ANN, Levenberg-Marquardt (LM) backpropagation algorithm is adopted for fine-tuning ANN weights. The performance of the two-stage approach has been evaluated on several benchmarks. The results demonstrate that the two-stage approach can fast produce compact ANNs with good generalization ability at low computational cost.", "title": "Evolving feedforward artificial neural networks using a two-stage approach"}, "S0957417417307881": {"highlights": ["We propose IagoDroid, a novel evasion attack against static analysis.", "IagoDroid successfully swaps the classification of 28 of 29 malware families.", "IagoDroid can defeat the classifier modifying only a single feature.", "Our countermeasure detects potential evasions between 90% and 99%.", "IagoDroid and all the data used in the paper are publicly available."], "abstract": "Machine learning classification algorithms are widely applied to different malware analysis problems because of their proven abilities to learn from examples and perform relatively well with little human input. Use cases include the labelling of malicious samples according to families during triage of suspected malware. However, automated algorithms are vulnerable to attacks. An attacker could carefully manipulate the sample to force the algorithm to produce a particular output. In this paper we discuss one such attack on Android malware classifiers. We design and implement a prototype tool, called IagoDroid, that takes as input a malware sample and a target family, and modifies the sample to cause it to be classified as belonging to this family while preserving its original semantics. Our technique relies on a search process that generates variants of the original sample without modifying their semantics. We tested IagoDroid against RevealDroid, a recent, open source, Android malware classifier based on a variety of static features. IagoDroid successfully forces misclassification for 28 of the 29 representative malware families present in the DREBIN dataset. Remarkably, it does so by modifying just a single feature of the original malware. On average, it finds the first evasive sample in the first search iteration, and converges to a 100% evasive population within 4 iterations. Finally, we introduce RevealDroid*, a more robust classifier that implements several techniques proposed in other adversarial learning domains. Our experiments suggest that RevealDroid* can correctly detect up to 99% of the variants generated by IagoDroid.", "title": "Picking on the family: Disrupting android malware triage by forcing misclassification"}, "S0888613X1300203X": {"highlights": ["Paper presents new results on the concept of Kuznetsov independence.", "Concept deals with interval-valued expectations, sets of probability distributions.", "Paper shows relationships with other concepts of independence.", "Paper derives algorithm for computation of lower expectations.", "Paper discusses conditional Kuznetsov independence."], "abstract": "Kuznetsov independence of variables X and Y means that, for any pair of bounded functions \n                        f\n                        (\n                        X\n                        )\n                      and \n                        g\n                        (\n                        Y\n                        )\n                     , \n                        E\n                        [\n                        f\n                        (\n                        X\n                        )\n                        g\n                        (\n                        Y\n                        )\n                        ]\n                        =\n                        E\n                        [\n                        f\n                        (\n                        X\n                        )\n                        ]\n                        \u22a0\n                        E\n                        [\n                        g\n                        (\n                        Y\n                        )\n                        ]\n                     , where \n                        E\n                        [\n                        \u22c5\n                        ]\n                      denotes interval-valued expectation and \u22a0 denotes interval multiplication. We present properties of Kuznetsov independence for several variables, and connect it with other concepts of independence in the literature; in particular we show that strong extensions are always included in sets of probability distributions whose lower and upper expectations satisfy Kuznetsov independence. We introduce an algorithm that computes lower expectations subject to judgments of Kuznetsov independence by mixing column generation techniques with nonlinear programming. Finally, we define a concept of conditional Kuznetsov independence, and study its graphoid properties.", "title": "Kuznetsov independence for interval-valued expectations and sets of probability distributions: Properties and algorithms"}, "S0952197617302610": {"highlights": ["Artificial Intelligence techniques were applied for small boats radar detection.", "Doppler radars and the constrained-GLR test were analysed and used as references.", "MLPs, RBFNNs and SONNs were proposed and validated using simulated and real data.", "SONNs improved radar Doppler performance and approximated the constrained-GLR test.", "SONN computational cost study proved its feasibility in real time applications."], "abstract": "Artificial intelligence techniques were applied for detecting small moving targets in maritime clutter environments. Neural detectors are considered to approximate the Neyman\u2013Pearson (NP) in composite hypothesis testing problems. Sub-optimum approaches based on the Constrained Generalized Likelihood Ratio (CGLR) were analysed, and compared to conventional implementations based on Doppler filtering that are designed to filter clutter and improve the Signal-to-Interference Ratio, and Constant False Alarm Rate techniques. The CGLR performance was significantly better at the expense of a high computational cost. As a solution, neural network training sets were designed for approximating the NP detector. The detection of small boats in Gaussian clutter was the defined case study in order to assume the design hypothesis of the conventional solutions and to study their performance under their most favourable conditions. Detection schemes were evaluated using real radar data. Neural solutions based on Second Order Neural Networks provide the best results, being able to approximate the CGLR with a significantly low computational cost compatible with real-time operations.", "title": "Artificial intelligence techniques for small boats detection in radar clutter. Real data validation"}, "S0004370214001143": {"highlights": ["We aim to improve Interactive Machine Learning by influencing the human teacher.", "We propose Teaching Guidance: instructions for teachers, to improve their input.", "Teaching Guidance is derived from optimal or heuristic teaching algorithms.", "We performed experiments to compare human teaching with and without teaching guidance.", "We found that Teaching Guidance substantially improves the data provided by teachers."], "abstract": "We propose using computational teaching algorithms to improve human teaching for machine learners. We investigate example sequences produced naturally by human teachers and find that humans often do not spontaneously generate optimal teaching sequences for arbitrary machine learners. To elicit better teaching, we propose giving humans teaching guidance, which are instructions on how to teach, derived from computational teaching algorithms or heuristics. We present experimental results demonstrating that teaching guidance substantially improves human teaching in three different problem domains. This provides promising evidence that human intelligence and flexibility can be leveraged to achieve better sample efficiency when input data to a learning system comes from a human teacher.", "title": "Eliciting good teaching from humans for machine learners"}, "S0888613X13002430": {"highlights": ["An axiomatic definition of information granularity has been developed.", "Four operators on granular structures have been presented.", "The lattice model is a mechanism for studying set-based granular computing."], "abstract": "Set-based granular computing plays an important role in human reasoning and problem solving. Its three key issues constitute information granulation, information granularity and granular operation. To address these issues, several methods have been developed in the literature, but no unified framework has been formulated for them, which could be inefficient to some extent. To facilitate further research on the topic, through consistently representing granular structures induced by information granulation, we introduce a concept of knowledge distance to differentiate any two granular structures. Based on the knowledge distance, we propose a unified framework for set-based granular computing, which is named a lattice model. Its application leads to desired answers to two key questions: (1) what is the essence of information granularity, and (2) how to perform granular operation. Through using the knowledge distance, a new axiomatic definition to information granularity, called generalized information granularity is developed and its corresponding lattice model is established, which reveal the essence of information granularity in set-based granular computing. Moreover, four operators are defined on granular structures, under which the algebraic structure of granular structures forms a complementary lattice. These operators can effectively accomplish composition, decomposition and transformation of granular structures. These results show that the knowledge distance and the lattice model are powerful mechanisms for studying set-based granular computing.", "title": "Set-based granular computing: A lattice model"}, "S014206151730220X": {"highlights": ["The measuring circuit in a PD set-up may affect the waveform of recorded PD pulses.", "Ground inductance of the measuring circuit leads to an oscillatory response.", "A symmetrical and concentric PD set-up minimize the effect of the measuring circuit.", "This test platform contributes to repeatability and comparison between measurements."], "abstract": "Partial discharge (PD) measurements are an effective tool for insulation assessment of high-voltage (HV) equipment widely used in both HV laboratories and in field tests. This paper presents the design of a test platform for electrical detection of partial discharges that contribute to the understanding of the phenomena. The test set-up comprises a collection of electrodes for the production of artificial PD sources frequently found in HV equipment, such as positive corona, negative corona, surface discharges, internal discharges, floating component and free moving particle. The test set-up has been designed in such a way that the gaps and clearances can be adjusted to modify the discharge characteristics, e.g. the discharge inception voltage, amplitude, repetition rate, etc. Besides, the platform has a symmetrical and radial arrangement of the PD sources around the coupling capacitor of the PD measuring systems with contribute to reduce the effect of the measuring circuit on the measurements.\n                  Relevant characteristics of the presented design is that the sensing of the PD signals is done by a high frequency current transformer (HFCT) with a wide bandwidth and the acquisition of the signals by a digital oscilloscope. A software tool was designed for the purpose of processing of the digitalized signals which proved to be an excellent workbench for studying the performance of clustering techniques.", "title": "A new design of a test platform for testing multiple partial discharge sources"}, "S0888613X14000346": {"highlights": ["We develop an approach for fault diagnosis in dynamic and hybrid domains.", "Our approach is designed with resource constrained systems in mind.", "Fault dimensions are handled in an integrated way.", "Extensive experimental data shows our approach as both fast and accurate.", "Our approach has been the top performer in three of four diagnostics competitions."], "abstract": "System failures, for example in electrical power systems, can have catastrophic impact on human life and high-cost missions. Due to an electrical fire in Swissair flight 111 on September 2, 1998, all 229 passengers and crew on board sadly lost their lives. A battery failure most likely took place on the Mars Global Surveyor, which unfortunately last communicated with Earth and thus ended its mission on November 2, 2006. Fault diagnosis techniques that seek to hinder similar accidents in the future are being developed in this article. We present comprehensive fault diagnosis methods for dynamic and hybrid domains with uncertainty, and validate them using electrical power system data. Our approach relies on the use of Bayesian networks, which model the electrical power system, compiled to arithmetic circuits. We handle in an integrated way varying fault dynamics (both persistent and intermittent faults), fault progression (both abrupt and drift faults), and fault behavior cardinality (both discrete and continuous behaviors). Our work has resulted in a software system for fault diagnosis, ProDiagnose, that has been the top performer in three of the four international diagnostics competitions in which it participated. In this paper we comprehensively present our methods as well as novel and extensive experimental results on data from a NASA electrical power system.", "title": "Diagnosis for uncertain, dynamic and hybrid domains using Bayesian networks and arithmetic circuits"}, "S1071581915001238": {"highlights": ["Sketch-a-Scratch is an abstract interactive object for multisensory texture exploration.", "Only nonvisual feedback induces significant behavioral variations in a steering task over a texture.", "Regardless of the richness of feedback, a virtual texture is experienced differently from the real one."], "abstract": "A tool for the multisensory stylus-based exploration of virtual textures was used to investigate how different feedback modalities (static or dynamically deformed images, vibration, sound) affect exploratory gestures. To this end, we ran an experiment where participants had to steer a path with the stylus through a curved corridor on the surface of a graphic tablet/display, and we measured steering time, dispersion of trajectories, and applied force. Despite the variety of subjective impressions elicited by the different feedback conditions, we found that only nonvisual feedback induced significant variations in trajectories and an increase in movement time. In a post-experiment, using a paper-and-wood physical realization of the same texture, we recorded a variety of gestural behaviors markedly different from those found with the virtual texture. With the physical setup, movement time was shorter and texture-dependent lateral accelerations could be observed. This work highlights the limits of multisensory pseudo-haptic techniques in the exploration of surface textures.", "title": "Multisensory texture exploration at the tip of the pen"}, "S0963868716301639": {"highlights": ["We develop a method for Value Based Compliance analysis of information security.", "We develop a set of design principles for a Value Based Compliance analysis method.", "We analyse value conflicts behind information security non-compliance.", "We provide a hands-on guide to Value Based Compliance analysis."], "abstract": "Employees\u2019 poor compliance with information security policies is a perennial problem. Current information security analysis methods do not allow information security managers to capture the rationalities behind employees\u2019 compliance and non-compliance. To address this shortcoming, this design science research paper suggests: (a) a Value-Based Compliance analysis method and (b) a set of design principles for methods that analyse different rationalities for information security. Our empirical demonstration shows that the method supports a systematic analysis of why employees comply/do not comply with policies. Thus we provide managers with a tool to make them more knowledgeable about employees\u2019 information security behaviours.", "title": "Towards analysing the rationale of information security non-compliance: Devising a Value-Based Compliance analysis method"}, "S0142061518336731": {"highlights": ["A platform for process data analytics utilizing industry 4.0 software tools.", "Integration of the data analytics platform with the process automation system.", "Data-driven soft sensors to predict syngas heating value and hot flue gas temperature."], "abstract": "Industry 4.0 and Industrial Internet of Things (IIoT) technologies are rapidly fueling data and software solutions driven digitalization in many fields notably in industrial automation and manufacturing systems. Among the several benefits offered by these technologies, is the infrastructure for harnessing big-data, machine learning (ML) and cloud computing software tools, for instance in designing advanced data analytics platforms. Although, this is an area of increased interest, the information concerning the implementation of data analytics in the context of Industry4.0 is scarcely available in scientific literature. Therefore, this work presents a process data analytics platform built around the concept of industry 4.0. The platform utilizes the state-of-the-art IIoT platforms, ML algorithms and big-data software tools. The platform emphasizes the use of ML methods for process data analytics while leveraging big-data processing tools and taking advantage of the currently available industrial grade cloud computing platforms. The industrial applicability of the platform was demonstrated by the development of soft sensors for use in a waste-to-energy (WTE) plant. In the case study, the work studied data-driven soft sensors to predict syngas heating value and hot flue gas temperature. Among the studied data-driven methods, the neural network-based NARX model demonstrated better performance in the prediction of both syngas heating value and flue gas temperature. The modeling results showed that, in cases where process knowledge about the process phenomena at hand is limited, data-driven soft sensors are useful tools for predictive data analytics.", "title": "Industry 4.0 based process data analytics platform: A waste-to-energy plant case study"}, "S0888613X14001741": {"highlights": ["A parallel between qualitative monotonic set-functions and imprecise probability.", "A capacity is an upper necessity measure and a lower possibility measure.", "Sugeno integral is a lower possibility integral.", "A bridge between capacities and the neighborhood semantics of non-regular modal logics."], "abstract": "This paper studies the structure of qualitative capacities, that is, monotonic set-functions, when they range on a finite totally ordered scale equipped with an order-reversing map. These set-functions correspond to general representations of uncertainty, as well as importance levels of groups of criteria in multiple-criteria decision-making. We show that any capacity or fuzzy measure ranging on a qualitative scale can be viewed both as the lower bound of a set of possibility measures and the upper bound of a set of necessity measures (a situation somewhat similar to the one of quantitative capacities with respect to imprecise probability theory). We show that any capacity is characterized by a non-empty class of possibility measures having the structure of an upper semi-lattice. The lower bounds of this class are enough to reconstruct the capacity, and the number of them is characteristic of its complexity. An algorithm is provided to compute the minimal set of possibility measures dominating a given capacity. This algorithm relies on the representation of the capacity by means of its qualitative M\u00f6bius transform, and the use of selection functions of the corresponding focal sets. We provide the connection between Sugeno integrals and lower possibility measures. We introduce a sequence of axioms generalizing the maxitivity property of possibility measures, and related to the number of possibility measures needed for this reconstruction. In the Boolean case, capacities are closely related to non-regular modal logics and their neighborhood semantics can be described in terms of qualitative M\u00f6bius transforms.", "title": "Representing qualitative capacities as families of possibility measures"}, "S1071581918305123": {"highlights": ["There are at least nine different ways of functionalising badges.", "The uncovered functionalisations only partly align with prior theorisations.", "Badge design details foster but do not determine different functionalisations.", "Users\u2019 functionalisations impact their experience, motivation and behaviour.", "The functional significance-framework is useful for understanding gamification."], "abstract": "Do game design elements like badges have one, fixed motivational effect or can they have several different? Self-Determination Theory suggests that people situationally appraise the functional significance or psychological meaning of a given stimulus, which can result in different motivational states, but there is little empirical work observing actual functionalisations of game design elements. We therefore conducted a qualitative in-the-wild diary and interview study with 81 university students who reported on their experiences with badges on two popular gamified online learning platforms, Khan Academy and Codecademy. Participants functionalised badges in nine distinct ways that only partially align with prior theory. Functionalisations shaped experience and motivation and prompted function-aligned behaviour. Badge design details fostered but did not determine different functionalisations, while no user or context characteristics were identified that reliably linked to particular functionalisations. We conclude that future research may need to conceptualise game design elements in a more differentiated way to capture what aspects support different motivational functions.", "title": "Collecting Pok\u00e9mon or receiving rewards? How people functionalise badges in gamified online learning environments in the wild"}, "S0963868717302706": {"highlights": ["Focus on post-adoption, an important area that we need to better understand.", "Explicating how and why trust in IT influences post-adoptive behavior (mediation).", "Taking a theory-driven approach to studying post-adoption, which is rarely done.", "Refraining from using adoption theories such as TAM in the post-adoption context.", "Introduction of bootstrapping as an advanced test of mediation to IS research."], "abstract": "Since the underutilization of technology often prevents organizations from reaping expected benefits from IT investments, an increasing body of literature studies how to elicit value-added, post-adoptive IT use behaviors. Such behaviors include extended and innovative feature use, both of which are exploratory in nature and can lead to improved work performance. Since these exploratory behaviors can be risky, research has directed attention to trust in technology as an antecedent to post-adoptive IT use. In parallel, research has examined how computer self-efficacy relates to post-adoptive IT use. While such research has found that both trust and efficacy can lead to value-added IT use and that they might do so interdependently, scant research has examined the interplay between these antecedents to post-adoptive IT use. Drawing on the Model of Proactive Work Behavior with a focus on its predictions about trust and efficacy, we develop a research model that integrates trust in technology and computer self-efficacy in the post-adoption context. Our model suggests that the two concepts are interdependent such that trust-related impacts on post-adoptive use behaviors unfold via computer-related self-efficacy beliefs. Contemporary tests of mediation on data from more than 350 respondents provided support for our model. Hence, our findings begin to open the black box by which trust-related impacts on post-adoptive behaviors unfold, revealing computer self-efficacy as an important mediating factor. In doing so, this study furthers understanding of how, and why, trust matters in post-adoptive usage, enabling strategic change management by elucidating the \u201cfit\u201d between technological characteristics and post-adoptive usage.", "title": "How and why trust matters in post-adoptive usage: The mediating roles of internal and external self-efficacy"}, "S0888613X1300217X": {"highlights": ["A novel cognitive system model is established based on formal concept analysis.", "An efficient algorithm is provided to transform among information granules.", "An experimental computing program is designed and two cases are employed as case study."], "abstract": "In this paper, a novel cognitive system model is established based on formal concept analysis to exactly describe human cognitive processes. Two new operators, extent\u2013intent and intent\u2013extent, are introduced between an object and its attributes. By analyzing the necessity and sufficient relations between the object and some of its attributes, the information granule concept is investigated in human cognitive processes. Furthermore, theories of transforming arbitrary information granule into necessary, sufficient, sufficient and necessary information granules are addressed carefully. Algorithm of the transformation is constructed, by which we can provide an efficient approach to the conversion among information granules. To interpret and help understand the theories and algorithm, an experimental computing program is designed and two cases is employed as case study. Results of the small scale case are calculated by the method presented in this paper. The large-scale case is calculated by the experimental computing program and validated by the proposed algorithm. The considered framework can provide a novel convenient tool for artificial intelligence researches.", "title": "A novel cognitive system model and approach to transformation of information granules"}, "S0957417415004674": {"highlights": ["Two new feature selection methods are proposed based on joint mutual information.", "The methods use joint mutual information with maximum of the minimum criterion.", "The methods address the problem of selection of redundant and irrelevant features.", "The methods are evaluated using eleven public data sets and five competing methods.", "The proposed JMIM method outperforms five competing methods in terms of accuracy."], "abstract": "Feature selection is used in many application areas relevant to expert and intelligent systems, such as data mining and machine learning, image processing, anomaly detection, bioinformatics and natural language processing. Feature selection based on information theory is a popular approach due its computational efficiency, scalability in terms of the dataset dimensionality, and independence from the classifier. Common drawbacks of this approach are the lack of information about the interaction between the features and the classifier, and the selection of redundant and irrelevant features. The latter is due to the limitations of the employed goal functions leading to overestimation of the feature significance.\n                  To address this problem, this article introduces two new nonlinear feature selection methods, namely Joint Mutual Information Maximisation (JMIM) and Normalised Joint Mutual Information Maximisation (NJMIM); both these methods use mutual information and the \u2018maximum of the minimum\u2019 criterion, which alleviates the problem of overestimation of the feature significance as demonstrated both theoretically and experimentally. The proposed methods are compared using eleven publically available datasets with five competing methods. The results demonstrate that the JMIM method outperforms the other methods on most tested public datasets, reducing the relative average classification error by almost 6% in comparison to the next best performing method. The statistical significance of the results is confirmed by the ANOVA test. Moreover, this method produces the best trade-off between accuracy and stability.", "title": "Feature selection using Joint Mutual Information Maximisation"}, "S0142061516317628": {"highlights": ["The classification map, quoted in Standards, is affected by the signal to noise ratio.", "Variation in acquisition parameters affects clusters in the classification map.", "PD sources are clustered only if the signals have a high signal to noise ratio.", "When noise is high, diverse PD sources clusters tend to merge into a single cluster."], "abstract": "The acquisition parameters of an unconventional Partial Discharge (PD) measuring system affect the way the PD pulses are recorded and in turn, the results of the data processing. The noise based on the oscilloscope\u2019s vertical resolution is a feature of the sampled signal that is always present when a digital acquisition system is used. In PD unconventional systems, several parameters such as the sampling frequency Fs, the acquisition time T, the number of samples N and the vertical resolution VR of the digitizer result in a wide oscilloscope-based noise variation, that could be quantified by the signal to noise ratio (snr).\n                  The classification map is a tool that came available with the development of unconventional systems, that due to their wide bandwidth are able to resolve PD pulses in time and apply clustering techniques for PD source separation. The equivalent time Teq\n                      and equivalent bandwidth Weq\n                     , used to plot the classification map, attempts to extract features of the PD pulses to form clusters so that classification of sources can be achieved. The classification map is based on the ability of separating PD sources by resorting to the parameters Teq\n                      and Weq\n                     , that are believed to show significant differences for distinct PD sources, while they are clearly consistent for the same source.\n                  This paper conducts a set of theoretical analysis and laboratory measurements to evaluate the influence of the oscilloscope-based noise on the results of Teq\n                      and Weq\n                     . The results proved that the classification map is heavily influenced by the signal to noise ratio.", "title": "Effect of acquisition parameters on equivalent time and equivalent bandwidth algorithms for partial discharge clustering"}, "S1071581918300041": {"highlights": ["The User Engagement Scale (UES) measures self-reported user engagement.", "We refined the factor structure of the UES using mirt for the R statistics program.", "We developed a new short form of the UES (UES-SF).", "The full UES and UES-SF were validated with a new data set.", "We offer guidance for adopting the UES and UES-SF in other studies."], "abstract": "User engagement (UE) and its measurement have been of increasing interest in human-computer interaction (HCI). The User Engagement Scale (UES) is one tool developed to measure UE, and has been used in a variety of digital domains. The original UES consisted of 31-items and purported to measure six dimensions of engagement: aesthetic appeal, focused attention, novelty, perceived usability, felt involvement, and endurability. A recent synthesis of the literature questioned the original six-factors. Further, the ways in which the UES has been implemented in studies suggests there may be a need for a briefer version of the questionnaire and more effective documentation to guide its use and analysis. This research investigated and verified a four-factor structure of the UES and proposed a Short Form (SF). We employed contemporary statistical tools that were unavailable during the UES\u2019 development to re-analyze the original data, consisting of 427 and 779 valid responses across two studies, and examined new data (N=344) gathered as part of a three-year digital library project. In this paper we detail our analyses, present a revised long and short form (SF) version of the UES, and offer guidance for researchers interested in adopting the UES and UES-SF in their own studies.", "title": "A practical approach to measuring user engagement with the refined user engagement scale (UES) and new UES short form"}, "S0957417417303779": {"highlights": ["An automatic channel selection for seizure detection is proposed.", "Computational efficiency is improved by 49.4%, while maintaining accuracy close to 96.5%.", "Mean detection delay is improved by 400\u00a0ms to 2.77s without degrading specificity.", "Seizure onsets are detected at 91.95% sensitivity and 94.05% specificity."], "abstract": "Detecting seizure using brain neuroactivations recorded by intracranial electroencephalogram (iEEG) has been widely used for monitoring, diagnosing, and closed-loop therapy of epileptic patients, however, computational efficiency gains are needed if state-of-the-art methods are to be implemented in implanted devices. We present a novel method for automatic seizure detection based on iEEG data that outperforms current state-of-the-art seizure detection methods in terms of computational efficiency while maintaining the accuracy. The proposed algorithm incorporates an automatic channel selection (ACS) engine as a pre-processing stage to the seizure detection procedure. The ACS engine consists of supervised classifiers which aim to find iEEG channels which contribute the most to a seizure. Seizure detection stage involves feature extraction and classification. Feature extraction is performed in both frequency and time domains where spectral power and correlation between channel pairs are calculated. Random Forest is used in classification of interictal, ictal and early ictal periods of iEEG signals. Seizure detection in this paper is retrospective and patient-specific. iEEG data is accessed via Kaggle, provided by International Epilepsy Electro-physiology Portal. The dataset includes a training set of 6.5 h of interictal data and 41\u00a0min in ictal data and a test set of 9.14 h. Compared to the state-of-the-art on the same dataset, we achieve 2 times faster in run-time seizure detection. The proposed model is able to detect a seizure onset at 89.40% sensitivity and 89.24% specificity with a mean detection delay of 2.63\u00a0s for the test set. The area under the ROC curve (AUC) is 96.94%, that is comparable to the current state-of-the-art with AUC of 96.29%.", "title": "Supervised learning in automatic channel selection for epileptic seizure detection"}, "S0957417416303050": {"highlights": ["We present a model to analyse online group identities on textual conversations.", "Our model applies data mining, NLP and sylometric techniques.", "Our model detects the salience of group identities with 95% accuracy.", "Our model is able to distinguish group identities from others with 84% accuracy.", "We identify features that may enable mal-actors to manipulate online groups."], "abstract": "The Internet has provided people with new ways of expressing not only their individuality but also their collectivity i.e., their group affiliations. These group identities are the shared sense of belonging to a group. Online contact with others who share the same group identity can lead to cooperation and, even, coordination of social action initiatives both online and offline. Such social actions may be for the purposes of positive change, e.g., the Arab Spring in 2010, or disruptive, e.g., the England Riots in 2011. Stylometry and authorship attribution research has shown that it is possible to distinguish individuals based on their online language. In contrast, this work proposes and evaluates a model to analyse group identities online based on textual conversations amongst groups. We argue that textual features make it possible to automatically distinguish between different group identities and detect whether group identities are salient (i.e., most prominent) in the context of a particular conversation. We show that the salience of group identities can be detected with 95% accuracy and group identities can be distinguished from others with 84% accuracy. We also identify the most relevant features that may enable mal-actors to manipulate the actions of online groups. This has major implications for tools and techniques to drive positive social actions online or safeguard society from disruptive initiatives. At the same time, it poses privacy challenges given the potential ability to persuade or dissuade large groups online to move from rhetoric to action.", "title": "Flash mobs, Arab Spring and protest movements: Can we analyse group identities in online conversations?"}, "S0921889017306164": {"highlights": ["An optimal control framework is introduced in robot table tennis to generate strikes.", "Inverse kinematics or a fixed plane to compute joint trajectories are not needed.", "Two optimization approaches are presented that encode different styles of playing.", "The parameters of the ball prediction models are estimated from demonstrations.", "Extensive experiments are shown in simulation and on our robot table tennis platform."], "abstract": "In highly dynamic tasks that involve moving targets, planning is necessary to figure out when, where and how to intercept the target. In robotic table tennis in particular, motion planning can be very challenging due to time constraints, dimension of the search space and joint limits. Conventional planning algorithms often rely on a fixed virtual hitting plane to construct robot striking trajectories. These algorithms, however, generate restrictive strokes and can result in unnatural strategies when compared with human playing. In this paper, we introduce a new trajectory generation framework for robotic table tennis that does not involve a fixed hitting plane. A free-time optimal control approach is used to derive two different trajectory optimizers. The resulting two algorithms, Focused Player and Defensive Player, encode two different play-styles. We evaluate their performance in simulation and in our robot table tennis platform with a high speed cable-driven seven DOF robot arm. The algorithms return the balls with a higher probability to the opponent\u2019s court when compared with a virtual hitting plane based method. Moreover, both can be run online and the trajectories can be corrected with new ball observations.", "title": "Online optimal trajectory generation for robot table tennis"}, "S0888613X15000511": {"highlights": ["We describe the marginal filter for activity recognition using symbolic models.", "The marginal filter allows fine-grained activity recognition using wearable sensors.", "We identify and discuss advantages over particle filters for symbolic models."], "abstract": "Recognising everyday activities including information about the context requires to handle large state spaces. The usage of wearable sensors like six degree of freedom accelerometers increases complexity even more. Common approaches are unable to maintain an accurate belief state within such complex domains. We show how marginal filtering can overcome limitations of standard particle filtering and efficiently infer the context of actions. Symbolic models of human behaviour are used to recognise activities in two different settings with different state space sizes. Based on these scenarios we compare the marginal filter to the standard particle filter. An evaluation shows that the marginal filter performs comparably in small state spaces but outperforms the particle filter in large state spaces.", "title": "Marginal filtering in large state spaces"}, "S2590188519300034": {"highlights": ["A novel multi-module neural network system is proposed.", "The system is proposed for imbalanced heartbeats classification.", "Three methods are introduced to solve imbalance problem.", "Extensive experiments confirm the effectiveness of the presented system."], "abstract": "In this paper, a novel multi-module neural network system named MMNNS is proposed to solve the imbalance problem in electrocardiogram (ECG) heartbeats classification. Four submodules are designed to construct the system: preprocessing, imbalance problem processing, feature extraction and classification. Imbalance problem processing module mainly introduces three methods: BLSM, CTFM and 2PT, which are proposed from three aspects of resampling, data feature and algorithm respectively. BLSM is used to synthesize virtual samples linearly around the minority samples. CTFM consists of DAE-based feature extraction part and QRS-based feature selection part, in which selected features and complete features are applied to determine the heartbeat class simultaneously. The processed data are fed into a convolutional neural network (CNN) by applying 2PT to train and fine-tune. MMNNS is trained on MIT-BIH Arrhythmia Database following AAMI standard, using intra-patient and inter-patient scheme, especially the latter which is strongly recommended. The comparisons with several state-of-the-art methods using standard criteria on three datasets demonstrate the superiority of MMNNS for improving detection of heartbeats and addressing imbalance in ECG heartbeats classification.", "title": "A novel multi-module neural network system for imbalanced heartbeats classification"}, "S0933365717306152": {"highlights": ["A Bayesian network is proposed to assess causality of adverse drug reaction reports.", "Validation was done with three cohorts of reports from a pharmacovigilance centre.", "A simplified assessment matrix is derived to be used by notifiers upon reporting.", "Time to assessment by the pharmacovigilance team is expected to decrease.", "Notifiers\u2019 engagement is expected to increase from the faster feedback given."], "abstract": "In pharmacovigilance, reported cases are considered suspected adverse drug reactions (ADR). Health authorities have thus adopted structured causality assessment methods, allowing the evaluation of the likelihood that a drug was the causal agent of an adverse reaction. The aim of this work was to develop and validate a new causality assessment support system used in a regional pharmacovigilance centre. A Bayesian network was developed, for which the structure was defined by experts while the parameters were learnt from 593 completely filled ADR reports evaluated by the Portuguese Northern Pharmacovigilance Centre medical expert between 2000 and 2012. Precision, recall and time to causality assessment (TTA) was evaluated, according to the WHO causality assessment guidelines, in a retrospective cohort of 466 reports (April\u2013September 2014) and a prospective cohort of 1041 reports (January\u2013December 2015). Additionally, a simplified assessment matrix was derived from the model, enabling its preliminary direct use by notifiers. Results show that the network was able to easily identify the higher levels of causality (recall above 80%), although struggling to assess reports with a lower level of causality. Nonetheless, the median (Q1:Q3) TTA was 4 (2:8) days using the network and 8 (5:14) days using global introspection, meaning the network allowed a faster time to assessment, which has a procedural deadline of 30 days, improving daily activities in the centre. The matrix expressed similar validity, allowing an immediate feedback to the notifiers, which may result in better future engagement of patients and health professionals in the pharmacovigilance system.", "title": "Causality assessment of adverse drug reaction reports using an expert-defined Bayesian network"}, "S1071581918301794": {"highlights": ["We investigate the relationship between aesthetic perception and icon successfulness.", "Total of 2276 icon evaluations from 569 participants comprised the data.", "Aesthetic perceptions were measured via semantic differential (22 adjective pairs).", "Success was measured via overall score, willingness to click, download and buy.", "Results show which perceptions should be enhanced to create successful icons."], "abstract": "Mobile app markets have been touted as fastest growing marketplaces in the world. Every day thousands of apps are published to join millions of others on app stores. The competition for top grossing apps and market visibility is fierce. The way an app is visually represented can greatly contribute to the amount of attention an icon receives and to its consequent commercial performance. Therefore, the icon of the app is of crucial importance as it is the first point of contact with the potential user/customer amidst the flood of information. Those apps that fail to arouse attention through their icons danger their commercial performance in the market where consumers browse past hundreds of icons daily. Using semantic differential scale (22 adjective pairs), we investigate the relationship between consumer perceptions of app icons and icon successfulness, measured by 1) overall evaluation of the icon, 2) willingness to click the icon, 3) willingness to download the imagined app and, 4) willingness to purchase the app. The study design was a vignette study with random participant (n\u202f=\u202f569) assignment to evaluate 4 icons (n\u202f=\u202f2276) from a total of pre-selected 68 game app icons across 4 categories (concrete, abstract, character and text). Results show that consumers are more likely to interact with app icons that are aesthetically pleasing and convey good quality. Particularly, app icons that are perceived unique, realistic and stimulating lead to more clicks, downloads and purchases.", "title": "An icon that everyone wants to click: How perceived aesthetic qualities predict app icon successfulness"}, "S1071581918301277": {"highlights": ["Continuous feedback on the state and behavior of automation that informs operators of the evolving relationship between system performance and operating limits, designed with appropriate attention to visual and cognitive costs, is able to promote proactive operator responses to automation failures and accurate mental models of system processes.", "Modality and feature complexity are key design decisions of continuous feedback that govern resulting visual and cognitive costs associated with use of these displays while driving.", "In-vehicle automated systems should be designed to inform instead of alert drivers to automation failures."], "abstract": "Objective\n                  This study evaluates the benefits and costs associated with providing drivers continuous feedback on the limits and behavior of imperfect vehicle control automation.\n               \n               \n                  Background\n                  In-vehicle automated systems remove drivers from active vehicle control, often at the expense of timely interventions when failures occur. Discrete warnings, as a type of feedback to inform drivers about automated system behavior, fail to keep drivers aware of its proximity to operating limits.\n               \n               \n                  Method\n                  In a fixed-based simulator, 48 drivers drove using Adaptive Cruise Control (ACC)\u2014a form of control automation that maintains a set speed, or a set headway if the vehicle encounters a slower moving vehicle. A first experiment compared ACC with discrete warnings to ACC with continuous information, which indicated moment-to-moment ACC state relative to its operating limits. Three display conditions, designed to provide non-obtrusive, ecologically-valid information, were evaluated in a second experiment: 1) a visual interface; 2) an auditory interface; and 3) a combined visual-auditory interface.\n               \n               \n                  Results\n                  Drivers provided with continuous feedback relied more appropriately on ACC than did those with discrete warnings. Continuous feedback increased the frequency of proactive responses to automation failures and improved system understanding. Of the three displays, the combined visual-auditory interface performed the best.\n               \n               \n                  Conclusion\n                  Continuous feedback helped communicate to drivers the evolving relationship between system performance and operating limits.\n               \n               \n                  Application\n                  Displays for increasingly automated vehicles should inform about the automation's situation-specific behavior rather than simply alert drivers to failures and/or the need to resume vehicle control in order to promote appropriate understanding and trust.", "title": "Keeping the driver in the loop: Dynamic feedback to support appropriate use of imperfect vehicle control automation"}, "S2589721719300236": {"highlights": ["Progress of optical non-destructive techniques on small berry fruits is reviewed.", "Potential use of some relatively novel techniques is discussed.", "Possible trends in optical non-destructive techniques are presented."], "abstract": "Small berries including strawberry and blueberry are extensively consumed fruits with great economic values due to their characteristic flavor and appearance as well as potential health benefits. This review elaborated the optical non-destructive techniques viz. Vis-NIR spectroscopy, computer vision system, hyperspectral imaging, multispectral imaging, laser-induced method and thermal imaging, and their applications for quality and safety control of small berry fruits. The discussion regarding the photoacoustic technique, X-ray technique, Terahertz spectroscopy, odor imaging, micro-destructive testing and smart mobile terminal-based analyzer was also presented. Furthermore, we proposed our personal understanding of the technical challenges and further trends for these optical non-destructive techniques: 1) owing to the relatively low detection limit, the so-called micro-destructive techniques may be alternative to the traditional non-destructive techniques in both practical and fundamental research; 2) we suggest that the research articles like \u201ccollecting data first, and then modeling the relevant properties of agricultural products by machine learning\u201d should be less produced in related fields. That's because such research methods are likely to be suspected of \u201ccheating\u201d. It is recommended that some modeling competitions can be carried out in the agricultural engineering field to avoid or reduce the \u201ccheating\u201d model.", "title": "Optical non-destructive techniques for small berry fruits: A review"}, "S1071581917300332": {"highlights": ["Citizen science participants prefer task designs with greater variety and autonomy.", "This does not translate into better performance for either data quality or quantity.", "Simpler task designs led to a greater volume of data being produced.", "Interfaces that afforded the most direct capture of data led to better quality data.", "Trade-offs exist between data volume and accuracy and between preference and productivity."], "abstract": "Virtual citizen science platforms allow non-scientists to take part in scientific research across a range of disciplines. What they ask of volunteers varies considerably in terms of task type, variety, user judgement required and user freedom, which has received little direct investigation. A study was performed with the Planet Four: Craters project to investigate the effect of task workflow design on both volunteer experience and the scientific results they produce. Participants' feedback through questionnaire responses indicated a preference for interfaces providing greater autonomy and variety, with free-text responses suggesting that autonomy was the more important. This did not translate into improved performance however, with the most autonomous interface not resulting in significantly better performance in data volume, agreement or accuracy compared to other less autonomous interfaces. The interface with the least number of task types, variety and autonomy resulted in the greatest data coverage. Agreement, both between participants and with the expert equivalent, was significantly improved when the interface most directly afforded tasks that captured the required underlying data (i.e. crater position or diameter). The implications for the designers of virtual citizen science platforms is that they have a balancing act to perform, weighing up the importance of user satisfaction, the data needs of the science case and the resources that can be committed both in terms of time and data reduction.", "title": "Task Workflow Design and its impact on performance and volunteers' subjective preference in Virtual Citizen Science"}, "S0142061518318660": {"highlights": ["Component condition and S/S reliability are used to inform DSR.", "S/S reliability depends on asset condition, S/S configuration and upstream network.", "Condition-based failure rates are derived from component health indices.", "Customer interruption costs are a function of outage duration and customer type.", "The proposed method is successfully demonstrated on two distribution systems."], "abstract": "Component condition and substation (S/S) reliability have a material impact on the cost of customer interruptions in electricity distribution systems (DSs). However, these factors are not usually considered within distribution system reconfiguration (DSR) problem formulations, because of the lack of a readily available methodology. This paper presents such a method, making use of component condition scores which are now mandatory for distribution system operators (DSOs) in the UK. Based on these condition scores, condition-based failure rate can be calculated for each component. S/S reliability is a function of component condition, S/S configuration and the network upstream of the S/Ss. The reliability of the S/S then has an impact on the reliability indices of each load point (LP) it supplies. These factors are combined to deliver a better informed algorithm for DSR, which is verified through its application on two DSs. The annual savings, compared to the formulation that neglects component condition and S/S reliability, can be in the order of tens of thousands of U.S. dollars for a single DS.\n               \n            \n\nfailure rate model parameters\n\ncost coefficient for losses (180 $/kW [23], expressed in today\u2019s U.S. dollars)\n\ninterruption cost of load point (LP) p due to failure event j ($/kW)\n\nannual cost of active power losses ($/yr)\n\ntotal expected customer interruption cost (ECOST) of the network ($/yr)\n\nECOST for failure events in the primary distribution system (DS) ($/yr)\n\nECOST for failure events at substations and the upstream network ($/yr)\n\nECOST of load point (LP) p due to failure event j ($/yr)\n\nenergy price ($/kWh)\n\nnodal current injection at node i, at iteration k\n                     \n\ncurrent of branch k\n                     \n\ncurrent rating of branch k\n                     \n\ncurrent injection at node L2, at iteration k\n                     \n\nbranch L current at iteration k\n                     \n\naverage load of LP p (MW)\n\nloss load factor\n\nannual cost of losses ($/yr)\n\nnumber of LPs\n\nnumber of buses\n\nnumber of possible failure events for LP p\n                     \n\nnumber of branches\n\nprobability that a circuit breaker fails to open when required\n\nactive power losses (calculated at peak load) (kW)\n\noverall penalty term forcing the objective function to infinite, if there is a constraint violation\n\npenalty term for loop constraints\n\npenalty term for operational constraints\n\nresistance of branch k\n                     \n\nrepair time (hr)\n\nmaintenance outage time (hr)\n\ninterruption duration of LP p due to failure event j (hr)\n\ncomplex power injection at node i\n                     \n\ntotal cost considering the annual cost of losses and the ECOST for the primary DS only, i.e. Loss Cost\u202f+\u202fECOST1 ($/yr)\n\ntotal cost considering the annual cost of losses and the total ECOST, i.e. Loss Cost\u202f+\u202fECOST ($/yr)\n\nvoltage at node i, at iteration k-1\n\nminimum and maximum voltage limits, respectively\n\nstate vector\n\nsum of all shunt elements at node i\n                     \n\ncondition score (p.u.)\n\nseries impedance of branch L\n                     \n\nfailure rate (f/yr) [for lines/cables (f/yr\u00b7km)]\n\nmaintenance outage rate (out/yr)\n\nactive failure rate (f/yr) [for lines/cables (f/yr\u00b7km)]\n\npermanent (total) failure rate (f/yr) [for lines/cables (f/yr\u00b7km)]\n\nfailure rate of failure event j", "title": "A method to include component condition and substation reliability into distribution system reconfiguration"}, "S2590188519300150": {"highlights": ["First report to consider maintenance and dynamic demand in machine layout design.", "Comprehensive review on the uncertainties, routing flexibility in layout design.", "Describe the development of the Genetic Algorithm-based layout design (GALD) tool.", "Investigations on the corrective, preventative and combined maintenance regimes.", "Compare material flow distances from the designs with various maintenance scenario."], "abstract": "The layout of manufacturing facilities has a large impact on manufacturing performance. The layout design process produces a block plan that shows the relative positioning of resources that can be developed into a detailed layout drawing. The total material handling distance is commonly used for measuring material flow. Manufacturing systems are subject to external and internal uncertainties including demand and machine breakdowns. Uncertainty and the rerouting of material flows have an impact on the material handling distance. No previous research has integrated robust machine layout design through multiple periods of dynamic demand with machine maintenance planning. This paper presents a robust machine layout design tool that minimises the material flow distance using a Genetic Algorithm (GA), taking into account demand uncertainty and machine maintenance. Experiments were conducted using eleven benchmark datasets that considered three scenarios: preventive maintenance (PM), corrective maintenance (CM) and both PM and CM. The results were analysed statistically. The effect of several maintenance scenarios including the ratio of the number of machines with period-based PM (PPM) to the number with production quantity-based PM (QPM), the percentage of machines with CM (%CM), and a combination of PMM/QPM ratios and %CM on material flow distance were examined. The results show that designing robust layouts considering maintenance resulted in shorter material flow distances. The distance was decreased by 30.91%, 9.8%, and 20.7% for the PM, CM, and both PM/CM scenarios, respectively. The PPM/QPM ratios, %CM, and a combination of PPM/QPM and %CM had significantly resulted in the material flow distance on almost all datasets.", "title": "Robust machine layout design under dynamic environment: Dynamic customer demand and machine maintenance"}, "S0957417415005473": {"highlights": ["Provide linkage between changes in volume semantic terms and subsequent market moves.", "Sell short at higher prices resulted from decreased appearance of negative words.", "Buy or take long positions resulted from increased appearance of positive words.", "StockTwits contains valuable information and precede trading activity in the market."], "abstract": "Growing evidence is suggesting that postings on online stock forums affect stock prices, and alter investment decisions in capital markets, either because the postings contain new information or they might have predictive power to manipulate stock prices. In this paper, we propose a new intelligent trading support system based on sentiment prediction by combining text-mining techniques, feature selection and decision tree algorithms in an effort to analyze and extract semantic terms expressing a particular sentiment (sell, buy or hold) from stock-related micro-blogging messages called \u201cStockTwits\u201d. An attempt has been made to investigate whether the power of the collective sentiments of StockTwits might be predicted and how the changes in these predicted sentiments inform decisions on whether to sell, buy or hold the Dow Jones Industrial Average (DJIA) Index. In this paper, a filter approach of feature selection is first employed to identify the most relevant terms in tweet postings. The decision tree (DT) model is then built to determine the trading decisions of those terms or, more importantly, combinations of terms based on how they interact. Then a trading strategy based on a predetermined investment hypothesis is constructed to evaluate the profitability of the term trading decisions extracted from the DT model. The experiment results based on 122-tweet term trading (TTT) strategies achieve a promising performance and the (TTT) strategies dramatically outperform random investment strategies. Our findings also confirm that StockTwits postings contain valuable information and lead trading activities in capital markets.", "title": "Quantifying StockTwits semantic terms\u2019 trading behavior in financial markets: An effective application of decision tree algorithms"}, "S1071581915000270": {"highlights": ["Identifies a gap in \u2018scale of audience\u2019 and \u2018scale of normative ambition\u2019 in urban computing.", "Proposes a design approach using an actor\u2013network understanding of scaling.", "Examines a case study of normative prototypes that reshape the issue of aircraft noise.", "Suggests a new scope and role for the designer as part of the networks they build."], "abstract": "While urban computing has often been envisaged as bridging place, technology and people, there is a gap between the micro-level of urban computing which focuses on the solitary user with technological solutions and the macro-level which proposes grand visions of making better cities for the public. The gap is one of scale of audience as well as scale of normative ambition. To bridge this gap the paper proposes a transdisciplinary approach that brings together actor\u2013network theory with critical and participatory design to create prototypes that engage people and build publics. The theoretical discussion examines a way of thinking about size as performative and shiftable through practical design methods. The micro/macro prototyping approach is demonstrated via an empirical case study of a series of provocative prototypes which attempt to build a material public around the issue of community noise at Heathrow airport. The paper suggests that this approach allows issues to be followed and engaged with, and their dynamics re-designed across different scales. This proposes a new role and scope for the researcher/designer as proactively engaging in normative shaping and supporting of real world settings which bridge place, technology and people.\n               \n            \n\nThe aim of this text is to locate a conceptual gap in urban computing and propose a transdisciplinary approach to address this gap and define a new role and scope for urban computing. The notion of transdisciplinarity I am working with in this text is taken from Nowotny (2006) who proposes that transdisciplinarity needs to provide a transgressive and socially robust knowledge that engages with and supports publics.\n\nThe paper addresses an area of computing that has been termed urban computing or urban informatics. While there are some differences between these terms (Foth et al., 2011, p. 5) they both conceptualise this area as an encounter among three entities: \u201cplace, technology, and people\u201d (p. 2). It is the combination of these disparate entities which makes urban computing unique. Urban computing as first described by Kindberg et al. (2007) focuses on the possibilities and challenges of \u201cthe integration of computing, sensing, and actuation technologies into everyday urban settings and lifestyles\u201d (p. 18). This computing is taken out of the home or office and taken to the \u201cstreets, squares, pubs, shops, buses, and caf\u00e9s\u2014any space in the semi-public realms of our towns and cities\u201d (Kindberg et al., 2007). These complex physical and social settings involve a fluid and diverse range of users who enter and leave the urban space at different times of the day. The seminal text The street as platform (Hill, 2008) describes an urban environment where people\u05f3s digital practices result in data flows which mesh with the physical elements of the city and create a dense bustle of humans and machines on the street, which becomes a platform for technological development and experimentation. Kindberg et al. (2007) argue that what makes urban computing different from pervasive computing is that it takes place in dynamics contexts with fluid user groups.\n\nThese descriptions of urban computing position it as a holistic bridging practice and propose it as more than just a subset of computing: it is a distinct space in its own right with specific methodologies. In order to fulfil this role of bridging, Shlovski and Chang (2006) raise the need for an engagement with other disciplines: \u201cwe are not calling for technology designers to become urban planners and social scientists, but we do suggest that there is a wealth of research in these areas that needs to be taken into account when designing new technologies\u201d (p. 28). While urban computing aims to be a transdisciplinary practice there is a conceptual gap in the way it addresses issues of scale.\n\nTo identify this gap I will briefly sketch a taxonomy of urban computing practices and rhetorics. The classification I propose is based on two different types of scale, one of audience and one of normative ambition. In the diagram shown in Fig. 1\n                      the y-axis represents a scale of audience which runs from addressing individuals to publics, while the x-axis represents a scale of normative ambition which extends from limited ambitions to large scale normative ambitions. A micro-vision in this taxonomy represents a focus on individual people and individual technologies as a limited notion of transformation. In contrast a macro-vision describes a focus on social publics and proposes large scale normative transformation of the city.\n\nTo explain this taxonomy I will briefly glance across some of the literature of urban computing. One typical micro-vision scenario is the following: \u201ca user is in a (potentially unknown) city and would like to organise a day/night by visiting some places, attending a music concert, etc. Therefore, s/he would like to plan his/her movement to his/her destinations\u201d (Valle et al., 2010, p. 165). I describe this as a micro-vision since the user is framed as a solitary individual and disconnected from a social environment where they might ask other people for advice. While this scenario could be scaled up towards a mass of individuals, the fundamental assumption of the scenario is the asocial individual. In another scenario Zheng et al. (2014) describe the practical potential of urban computing for institutional management of the city by dealing with challenges such as \u201cair pollution, increased energy consumption and traffic congestion\u201d (p. 2). While this formulation rhetorically addresses big challenges, the paper is focussed on technological problems of integration and data management. I argue that this is also a micro-vision since it stays largely within the realm of the technical and does not offer large scale transformative proposals of the city.\n\nIn contrast there are other texts within urban computing that describe broader visions of the city as collective and which try to change the city deliberately. Dourish et al. (2007), for example, argue that the city is constituted through collective flows of people as social phenomena. de Waal (2011) focuses on what he terms \u2018urban imaginaries\u2019. He identifies a series of these imaginaries such as the \u2018city of services\u2019, the \u2018psychogeographic city\u2019 which consists of sensation and experience, the \u2018city as operating system\u2019 allowing real time management, or the \u2018city as commons\u2019. For de Waal these are fundamental visions of the city that practitioners are using to direct urban computing projects and thus transform the city. Iveson (2011) identifies multiple visions of citizenship when looking at systems that target urban graffiti by either informing authorities, allowing collective discussion or creating simulated graffiti. Iveson asks \u201cwhat is the vision of a good citizen and the good city that they seek to enact?\u201d (p. 56). These authors offer visions of urban computing for cities as collective structures and not as aggregations of atomised individuals. They make value judgements and offer an opinion-based assessment of the kind of city they want to create with urban computing. In this sense they are large scale normative ambitions for transformation and I therefore describe them as macro-visions.\n\nMy use of the terms micro and macro is not intended to indicate that one is better than another, but rather to delineate that they are very different visions of urban computing. Using this taxonomy the majority of technically focussed literature clusters in the micro-corner, while the rhetorical and theoretical visions cluster in the macro-area. While the scales I have drawn are intended to be continuous, urban computing seems to exist as two clusters with a large gap between them. On the micro-level we have computing that considers its role to be the practical design of technologies for individual users, while the macro-level consists of theoretical visions of future urbanism. This gap indicates that there is a conceptual problem in scaling between physical devices and abstract notions of a public good. I argue that this results in technical devices that are largely designed for the concept of the individual and it is left to commercial mass aggregation to build atomised public spaces.\n\nThis paper argues for a different approach to scaling which can bridge the gap between micro and macro through material technologies that are specifically designed as transformative visions of the city. The text proposes a model of micro/macro prototyping which focuses on scaling as transformative and transgressive. This approach allows material technologies to be considered at the same time as the macro and collective level. The paper will describe the theoretical underpinnings of this approach, its methods, and through an empirical case study identifies its potential and current limitations.\n\nThis approach builds on the work of Paul Dourish and colleagues (Williams and Dourish, 2006; Dourish et al., 2007; Williams et al., 2009; Dourish and Bell, 2011) who over many years have introduced concepts from social science into urban computing. This work has identified the conceptual blind spots of urban computing, such as groups of people who are privileged or excluded by computing. Their approach points towards ethnographic and inclusive design methods to reach more diverse groups of people. This text extends this approach by using the literature of science and technology studies (STS) and a subfield called actor\u2013network theory (ANT) to discuss the role that design can play in \u2018socio-technical prototyping\u2019 (Hansen, 2006) in constructing and supporting publics that gather around issues. The notion of socio-technical used throughout this text describes the way the social and the technical are inseparable and intertwined.\n\nI want to start at an explicitly macro-level to think about collectives of people in terms of publics. The history of the concept is long and complex and a full discussion is beyond the scope of this text. Yet I want to focus on one of the historical approaches based on a reading of John Dewey\u05f3s \u2018The Public and Its Problems\u2019 (Dewey, 1927) by the philosopher Marres (2005a). Dewey (1927) proposed that \u201cthe public consists of all those who are affected by the indirect consequences of transactions, to such an extent that it is deemed necessary to have those consequences systematically cared for\u201d (p. 15). Rather than a singular and pre-existing public which consists of masses of individuals, Dewey proposes a series of multiple publics which emerge in response to specific issues. These publics form from people who do not necessarily know each other but who come together around a common shared issue. In this understanding, publics arise when the official institutional apparatus does not successfully manage a controversial issue and a public needs to assemble in order to address the issue itself. These kinds of publics do not necessarily consist of huge numbers of people: their only limit is the importance of the issue, so they could perhaps be thought of as an issue pressure group. A Deweyan public \u201cconsists of actors who are jointly implicated in an issue, but who do not belong to the same social world, so this is why they must get organised into a political community if they are to address the issue in question\u201d (Marres, 2005a,p. 10). Marres (2005b) describes the tight integration between publics and issues using the pithy phrase \u2018no issue, no public\u2019. Crucially for Marres, issues do not spontaneously form publics. What is required is a variety of material infrastructure or \u2018objects of politics\u2019 (Marres, 2005a), which communicate and articulate these issues. Dewey focussed on the importance of telecommunications for organising these kinds of issue publics. Marres (2013) extends this line of reasoning to argue that these devices of public construction require a particular kind of design and are not just haphazardly given things. She argues that publics can be purposefully constructed through devices which allow people to be affected by an issue and create connections that emerge as networks. Marres (2012) does not define any particular type of technical device but describes them as enmeshing personal emotion with an issue which results in \u2018material publics\u2019 being formed.\n\nI am going to take a diversion into a transdisciplinary field called actor\u2013network theory (ANT) to understand how objects acquire the power to shape our lives at an individual and collective level. ANT has evolved a rich language for thinking about people\u05f3s interactions with objects and the way devices can become powerful and acquire their own agency. In ANT the key concept is the \u2018actor\u2019, which is used to describe humans in the sense of the human subject, as well as nonhumans such as technologies that can in certain situations function as actors. The concept of the actor describes the way that something can have an effect on the world and transform the world around itself. In this formulation of actors, ANT does not differentiate between humans and nonhumans. The best way to think about this is via a humble example given by Latour (1991) who describes how a hotel key fob functions as an actor due to its bulky form and weight. \u201cCustomers no longer leave their room keys: instead they get rid of an unwieldy object that deforms their pockets. If they conform to the manager\u05f3s wishes, it is not because they read the sign, not because they are particularly well-mannered. It is because they cannot do otherwise. They don\u05f3t even think about it\u201d (p. 105). In this example the hotel manager does not have to talk to every guest and remind them to leave their door key at the reception when they leave the hotel. This function has been delegated to the bulky key fob. ANT suggests that objects are designed in such a way that they perform normative and even moral roles and include \u2018scripts\u2019 that dictate their usage. For example, seat belts are material artefacts that attempt to keep us safe in a car crash, but to fulfil this function they have to constrain people in the way they use their car. Seat belts are also legislative objects that are enforced by the state on behalf of a collective public good. ANT suggests that in our daily lives we are constantly surrounded by objects that have a variety of values inscribed into them even though we rarely think about them in moral terms. Objects are normative and have agendas which might not even be the designer\u05f3s but those of a whole range of other entities and clients.\n\nANT offers a concept of size that is not about physical form but about association. Actor\u2013networks are built through processes of \u2018enrolment\u2019 and \u2018translation\u2019 where one actor manages to persuade other entities to join its actor\u2013network. The more engaging a particular situation or issue becomes, the more entities are enrolled and the larger the actor\u2013network appears to be. All actors are themselves actor\u2013networks and made up of smaller actors. Actor\u2013networks are unstable and constantly at risk of collapsing back to the component parts that constitute them. For example, the social media site Facebook is often treated as a large actor and more important than a platform such as Orkut. Is this because one has a higher financial value, uses a larger number of servers or claims more users? ANT asks the researcher to \u201cdetect how many participants are gathered in a thing to make it exist and to maintain its existence\u201d (Latour, 2004, p. 246). In the case of Facebook this would involve analysing a range of socio-technical elements, such as techniques for inviting \u2018friends\u2019, the management of media coverage and means of raising financial investment. The aim is to identify the specific ways that scale is translated and maintained which allows some actors to appear bigger than others. Callon and Latour (1981) argue that we should not take claims of size at face value: \u201cno actor is bigger than another except by means of a transaction (a translation) which must be examined\u201d (pp. 280\u2013281). Thus ANT suggests that translations of scale do not happen by themselves, but that they require work.\n\nThe tasks of enrolment and translation of scale involve the re-arrangement of concepts, material objects and groups of people. I am proposing that this activity is a particular kind of socio-technical design that I am calling micro/macro prototyping. Its main mode of action is enrolling new entities in order to shift the size of an actor, this is what I call \u2013 scaling between micro and macro. This involves the building of technical prototypes that act as the locus for a gathering together networks of humans and nonhumans. This approach builds on Suchman\u05f3s generative notion of the prototype as \u201cworking artefacts; artefacts whose significance is not given in advance, but is discovered through the unfolding activity of co-operative design-in-use\u201d (Suchman et al., 2002, p. 172). This calls for a specific kind of relational prototype that is completed at the point of usage with people, in a context and around an issue. For Suchman the prototype is a \u201cperformative artefact that works to align multiple, discontinuous social worlds\u201d (p. 175). Micro/macro prototyping uses these performative artefacts to carry out scaling. In Fig. 2\n                        , the shape on the x-axis represents prototypes that have been designed with deliberate values and aim at large scale normative visions. The shape on the y-axis represents a translation from addressing individuals towards publics. Yet micro/macro prototyping is not static but an oscillating process of scaling. It does not address stable publics because it aims to facilitate the construction of new publics.\n\nThis section examines how objects can be designed to confront people with normative positions which allow scaling towards larger issues. Marres (2013) calls for an experimental design practice which involve the\u201cdeliberate investment of non-humans with moral and political capacities\u201d (p. 7). Critical design (Dunne, 1999) and speculative design (Sterling, 2009) harness the uncanny potential of objects to address people in affective ways and direct them towards relational positions with objects and issues. Critical design starts from a position of building \u2018value fictions\u2019 (Dunne, 1999), which embody explicit agendas and take the form of physical objects which \u201cforce a decision onto the user, revealing how limited choices are usually hard-wired into products for us\u201d (Dunne and Raby, 2001, p. 46). An example is Dunne and Raby\u05f3s \u2018Placebo Project\u2019, 2001 (Dunne and Raby, 2002) which was experimental furniture that was lent to people to place in their homes. These were highly designed and finished objects, yet their utility was not obvious or predetermined. People were asked to live with these curious objects and to reflect on the way they affected their lives. The designers focussed on documenting the sensory minutiae of participants\u2019 reactions and the unusual relationships that people formed with the objects. Rather than tool and user relationships, these objects created an ambiguous design space where objects gained a quasi-animate quality which was both unsettling and engaging. The idea was that the users would surprise themselves and become \u201cprotagonist and co-producer of narrative experiences rather than the passive consumer of [a] product\u05f3s meaning\u201d (Dunne and Raby, 2001, p. 46). From an ANT perspective the objects could be seen as actors that prompt the participants to position themselves in relation to the objects by either rejecting them or adopting them. If the participants are engaged by an object then they let it join their home environment. In this way the objects and participants mutually enrol each other to form an actor\u2013network.\n\n\n                        Sterling (2009) extends this approach with speculative design, which constructs future narratives that blend social and technological alternatives. In this approach, solid and believable design objects function as \u201cdiegetic prototypes to suspend disbelief about change\u201d (Bosch, 2012, para. 3). Sterling (2009) argues \u201cit\u05f3s not a kind of fiction. It\u05f3s a kind of design. It tells worlds rather than stories\u201d. This approach uses the critical design object and expands it to initiate collective discussions about contentious issues such as genetic modification. I see this approach as an attempt to generate issue objects through the radical compression of issues into material objects, in which the viewer is then encouraged to re-inflate into issues. It is worth being somewhat cautious, though, of how well these objects function in terms of issue articulation and transformation. A number of commentators have expressed worries that some of this work is didactic without offering empowering solutions (Kiem, 2013; Gonzatto et al., 2013; Thackara, 2013; Prada and Oliveira, 2014). One problem is that many of the objects of critical and speculative design exist only within art gallery settings and do not become actively involved in facilitating material publics.\n\nThere is a subgroup of designers from participatory design (PD) who use normative objects in everyday settings to gather and support publics. This design practice started in Scandinavia in the 1980s in the context of trade union-sponsored research around supporting democracy at work, which led to transformations in workplace relations through organisational and material interventions. A historical example which is interesting in terms of scaling is the \u2018Balao\u2019, an experimental ship built in 1972. The physical structure of the ship was changed to reduce the segregation between the sailors and officers by increasing communal areas and providing egalitarian accommodation. On an organisational level, sailors were encouraged to train in a range of positions on the ship and meetings were held to collectively allocate tasks that needed to be carried out. The idea was that this was a new experimental floating democracy within the confines of a cargo ship. Lezaun (2011) argues that the main innovation of the project was in the \u2018radical process of social miniaturisation\u2019, which managed to prototype a society within the confines of a ship. Interestingly the sociologists and designers who initiated the project wanted to extend the project beyond the micro-society on the ship: \u201cBalao was a social scientific miniature, but also a vehicle for the generation of gigantic phenomena, out of any proportion to the physical size or institutional significance of the experiment itself\u201d (Lezaun, 2011, p. 557). The sociologists had hoped that these experimental ships would function as demonstrative examples which would transform wider publics. Lezaun argues that the experiment did not have the hoped-for expansion effect because it organised a mini-society inside the artificial capsule of a ship, which made it difficult to translate to the wider world.\n\nCurrent work in this approach is moving away from insular experiments towards being embedded in urban contexts. The Malm\u00f6 Living Labs collaborate with companies, and the public and civic sector as well as local groups and individuals, in order to \u201cestablish long-term relationships, to allow participants to become active co-creators, and to make it so that what is being designed enters their real life context\u201d (Bj\u00f6rgvinsson et al., 2010, p. 42). They use an ANT understanding of infrastructure (Star and Ruhleder, 1996) as socio-technical and have turned this concept into a design method they call infrastructuring. Unlike the theorists I described earlier, networks are not merely studied but built, hence the addition of the \u2018-ing\u2019 ending which turns infrastructure into a verb. The aim is to combine people and material into socio-technical infrastructure. In this design method, \u201ctechnology connects to wider systems of socio-material relation in the form of collective interweaving of people, objects and processes\u201d (Bj\u00f6rgvinsson et al., 2010, p. 44). This approach has been used by a range of designers (Ehn, 2008; Dantec and DiSalvo, 2013) for whom it presents a practical way of building collectives through design practice. Dantec and DiSalvo (2013) describe this method as \u201cproviding scaffolding for affective bonds that are necessary for the construction of publics\u201d (p. 260). The method is similar to critical and speculative design where \u201cthe activities of design[\u2026] worked to produce the objects that ultimately expressed the conditions of an issue or the desired outcome of the issue. That is, through PD, objects were created to which attachments could form. This is not to say that emotions, beliefs, or desires were shaped by design, but rather that design provided structures to which emotions, beliefs, and desires might adhere and thus be sustained\u201d (Dantec and DiSalvo, 2013). What infrastructuring offers is a practical and participatory way of designing around real world controversial issues. The design object becomes a way to materialise a multi-layered understanding of an issue and use it as a scaffold for people\u05f3s emotions in order to gather a public.\n\nThis section examines an empirical case study that uses a micro/macro prototyping approach within a real world context. The aim is to offer an ethnographic snapshot of how this approach combines an ANT concept of scale, the critical design of normative objects and the participatory design of scaffolds in order to build material publics.\n\nThe case study is part of a multi-year ethnographic research project which uses urban computing to engage with the issue of aircraft noise around Heathrow airport in London. Noise caused by aircraft taking off and landing is a highly emotive issue and there is opposition from local residents to the current level of noise as well as the proposed expansion of the airport. This opposition extends to the political level where the airport expansion is seen as a national election-winning or losing topic. Aircraft noise is a highly technical issue involving complex models which try to predict the exposure for the area and inform the regulatory procedures of the airport. According to the institutions creating the models, the level of noise exposure is highly predictable with a minuscule margin of error. Yet many of the local residents I came into contact with feel they are being lied to and systematically marginalised by these institutional monitoring procedures. The residents are a diverse group that includes many that are well-informed about the legislation of noise and regulation procedures of the airport. A significant number of residents are interested in carrying out their own noise monitoring to collect evidence and put pressure on political representatives. Some are very technically able and interested in designing their own monitoring equipment.\n\nHow can one design for this mix of technologies, legislation, expertise, opinions and experience? A technical\u2014micro-approach might be to design more detailed noise models, while a macro-approach might focus on survey methods that capture people\u05f3s experiences in a more granular way. My argument is that the problem of noise is precisely the compartmentalisation between micro and macro, technical and social. We can see this via the example of the \u2018Schultz curve\u2019 (Schultz, 1978) which tries to establish a correlation between decibel dosage and universal community annoyance. Variations of this curve have become enshrined in noise regulation as universal predictors of community annoyance. Yet acousticians such as Fidell (2003) argue that the \u2018Schultz curve\u2019 is actually a highly unsuitable metric since \u201cdecisions about the award of billions of dollars of federal subsidies to construct airport and highway infrastructure [\u2026] ostensibly rest on the shape of a purely descriptive fitting function, unsupported by quantitative, theory-based, or other systematic understanding of the origins and mechanisms of community reaction to transportation noise\u201d (pp. 3009\u20133010). Instead Fidell proposes empirical approaches based on spontaneous self-reporting by residents of their complaints. These would be enabled by computing which allows for geolocation and visualisation (Fidell, 2003, p. 3013). I suggest that this shift towards systems that interweave people and technology is an acknowledgement that community noise is socio-technical and not just an engineering problem. This means that this topic is a rich area for urban computing to explore with experimental prototypes that reshape the boundaries of what is technical and social.\n\nThe researcher/designer\u05f3s goal in the case study was twofold. The first was to understand how micro/macro prototyping might be able to engage with local residents to understand the existing framings of noise as technical, experiential and political. The second goal was to start a process of infrastructuring and co-designing a range of tools to support a new material public around noise.\n\nI designed four prototypes based on my observations of the way the issue was being framed by residents and other spokespeople in Heathrow. Each of the prototypes is a physical object as well as a hypothesis, or more specifically a proposition \u2013 a normative articulation of how the noise issue should be handled. The aim of the prototypes is to be provocative and not necessarily to seek the participants\u2019 approval of the designs. Rather like critical design, the goal is to trigger responses from the participants and open up the framings of noise for both the researcher and participants. The values that the prototypes embody do not necessarily reflect my own but are a distillation of existing discussions.\n\nEach of the devices has a name which summarises the propositions: \u2018I speak your feelings\u2019, \u2018I display noise publicly\u2019, \u2018I make someone responsible\u2019, \u2018I turn noise into numbers\u2019. Naming the devices in this way reinforces the idea that each one is a unique actor with its own distinct position. The prototypes were made in a short timeframe, so the physical finish is not as refined as that of critical design objects which are created for art galleries. Instead the designs were intended as an iterative part of a continuing process of engagement with a local group of people. The requirement was for the prototypes to function technically and conceptually in order to connect tangibly and emotionally with the participants and confront them with the propositions.\n\nThe following vignette describes the workshop in which the prototype devices were used by nine local residents from Isleworth. The participants did not know each other and were invited to attend the workshop via a pressure organisation which opposes the expansion of the airport. The workshop was held at a local community centre which is positioned under the flight path. This meant that during the 2.5-h workshop, aeroplanes could be heard overhead at regular intervals. While the noise level was not enough to disrupt conversation, it created a material reminder of the issue that was being addressed.\n\nThe prototype in Fig. 3\n                         consists of an Arduino micro-controller, an electret microphone, an amplification circuit and an LCD screen. The device continuously samples the voltage sensed by the microphone and translates this as text to the LCD screen. Instead of decibel numbers, the screen displays the current sound situation using a scale of emotive words: silent, quiet, audible, loud, very loud, extremely loud and painful.\n\nThe prototype is based on the observation that institutions frame noise as technical and measurable, while many local residents use a highly emotive language to describe their own experiences. Both these framings coexist in the public dialogue, yet they do not seem to be directly comparable and operate in their own domains. The proposition of the prototype is to bring them together in the form of a machine that talks in emotive and experiential terms on behalf of humans. The aim is to uncover possible design directions for future devices in terms of how they should relate to existing languages for talking about noise.\n\nWhen the device was presented to the group the reactions were very diverse. Some of the participants used the prototype as a catalyst to talk about the way noise affected them without referring to decibel numbers. These participants identified a range of factors that influenced their experiences including noise frequency, personal tiredness as well as differences between mechanical and human noise. One participant summed up the discussion with \u201cit\u05f3s not just decibels, there is something else in there as well\u201d. Yet interestingly the prototype had an antagonising effect on two of the participants who found the device highly frustrating. One of them said, \u201cI think it would be completely chaotic if you just had people\u05f3s feelings about it[noise]. What would you do with that data? You have got to have an objective reference\u201d. Before the prototype was introduced, the group had been cohesive and there had been little disagreement. Yet once the prototype was demonstrated, the group quickly divided over the importance of an objective metric. Those participants who felt engaged by the idea of an alternative language for noise were intrigued by the device and chose to think with and beyond the function of the prototype, and suggested other ways a technology could talk about experience such as measuring physiological stress in the body. The oddness of the device seemed to give these participants the liberty to talk about their experiences in an open and revealing way that included subtle descriptions of how noise acted on their daily lives. For me the discussion suggested that measurement should be an important part of any future prototype. Yet there seems to be a conceptual space for measuring noise using alternative means and metrics such as physiological stress or other environmental indicators.\n\nThe prototype in Fig. 4\n                         consists of a visual mockup of a large noise meter and display mounted on the outside of a local building in Isleworth. The image was printed as an A3 colour photograph and given to each participant to look at. I explained that the device would flash brightly when a specified noise level was exceeded.\n\nThe prototype is based on two notions. The first is my observation that the housing under the flightpath looks like any other suburban area, and that there are no visible references like posters or public signs to the noise problem overhead. The second is the idea that noise should be a communal issue of concern rather than a problem faced by individuals. The proposition of the prototype is to materialise noise as an object in public space. It is designed to spark debate among the residents and encourage them to join a pressure group. The prototype is intended to prompt tactical questions of how to raise the issue locally and engage more residents.\n\nDuring the workshop, I introduced the prototype as something that could be mounted on the participants\u2019 houses and might be a way to engage their neighbours. In the discussion it quickly emerged that they were not keen to fix the device on their home. Instead they suggested that it should become a \u2018norm\u2019 to have it installed on public buildings including offices and schools in the area. One of the participants stated that there could be negative consequences to mounting it on one\u05f3s own house: \u201cI don\u05f3t want to be a downer on this, but we do have to bear in mind that people think that campaigning and emphasising the noise problem - is giving them a problem. Because it affects the value of their house and they might be wanting to sell their house and they don\u05f3t want to be labeled as a problem area. And we have found that schools have quite remarkably low levels of interest because they get money out of the airport for various activities and they don\u05f3t want to be seen as the wrong school to send your child to\u201d. After the participant had said this, a number of others nodded and voiced agreement. It appears that the prototype made the participants uncomfortable since it would publicly identify them as troublemakers. Rather than generating local solidarity, the prototype was perceived as potentially victimising individuals or institutions that were speaking up about noise.\n\nWhile the prototype was not popular, it was successful in opening up the complex micro/macro-dynamics of the issue and clarifying the ambiguous position that local people and organisations found themselves in. There appears to be a lot of pressure to leave noise to be managed by institutions rather than allowing concerned residents to do something about it themselves. Rather than just affecting individuals, the noise dynamic is shaping collective behaviour by introducing coercive expectations about how local people are supposed to respond.\n\nThe prototype in Fig. 5\n                         consists of an Arduino micro-controller, an electret microphone, an amplification circuit and a GSM mobile phone module. The device is set to send a pre-formatted SMS text to a mobile phone whenever a decibel level of 90dB(a) is exceeded.\n\nThe prototype is based on previous conversations with residents where I sensed a lack of clarity about who or what was responsible for the local noise pollution. During the discussions a whole range of entities were blamed from local and national politics, government agencies, the airport, individual airlines as well as capitalism in general. The provocation of the prototype is to force the participants to choose a single individual who is held directly responsible. The aim of the device is to obliquely ask about strategic goals and methods for a resident based noise monitoring project.\n\nWhen I introduced the prototype I showed the group the source code of the micro-controller and mentioned that the mobile number in the code could be changed to any phone number. A dramatic transformation in the atmosphere occurred, with all the participants suddenly laughing loudly, as they understood the implication of inserting somebody else\u05f3s number into the code. The participants excitedly discussed a range of potential entities that could have their phone number inserted into the source code. The potential candidates ranged from airport complaint lines, institutional bodies, local politicians in favour of airport expansion, national politicians as well as the prime minister himself. While a whole range of people were discussed, there was no consensus regarding who could be held directly accountable. What was interesting was that some participants in the group were keen on the confrontational approach of the prototype, while others felt the targeted text messages were too personal and wanted to make it more public by redirecting the messages to Twitter or automated hotlines. One participant said, \u201cI think tweeting may well be a more acceptable way of doing that and it\u05f3s in the public domain so you can see there have been 80 tweets at that time in the morning and it\u05f3s not going to a direct person\u201d. In contrast another participant extended the logic of the prototype by talking about mounting loudspeakers outside a politician\u05f3s house to wake them up when the flight noise starts at 4:30 in the morning.\n\nThe most interesting aspect of the prototype was the way its directness and antagonistic proposition triggered a strong emotional response from the participants. Throughout the workshop the participants focussed their discussions and visual attention on the function of the prototype. Whenever voices were raised or a plane flew overhead, the device would send a SMS message which would be received with loud bleeps and the group would respond with laughter. This prototype proved to be the most interactive and performative. It allowed the participants to scale from the micro-context of the device towards the possible political impact as it sent a continuous stream of text messages to a remote representative. The prototype directly connected grassroots noise monitoring with a political actor by cutting out the institutional middlemen. The diverse range of reactions by the participants shows that any device designed to support this group cannot adopt a pure form of address but has to capture and materialise the diversity of participant positions.\n\nThis prototype consists of an Arduino micro-controller, an electret microphone, an amplification circuit and an ethernet connection. The device uploads the measured sound pressure at regular intervals to an online repository where it is presented visually as a time series. The noise pattern of aircraft can be clearly identified as spikes on the online graph.\n\nThis prototype is the result of direct requests by residents for a static monitoring device that could be placed in their own home and used to provide evidence of their noise exposure. The device accepts the technical and institutional paradigm that noise can be measured by a microphone. The innovative proposition is to change where and how those measurements are taken as well as who is doing the measuring. The device is designed to be assembled and maintained by the residents themselves, thereby putting them in charge of collecting evidence of their own exposure.\n\nDuring the workshop, this prototype triggered the least discussion and provoked no disagreement among the group. The residents asked me questions about where it could be located in their house and whether future versions could adopt more sophisticated hardware for higher accuracy. The innovation of the prototype was its low cost and potential accuracy, which could allow a large network of local sensors to be set up to gather evidence for the group. Yet as a conceptual level, the prototype was not very innovative and seemed to be familiar to the participants. The prototype was treated more as a tool that could be used, rather than a provocation that needed to be discussed. At the end of the workshop when I offered to lend all the prototypes to the participants, half of the group immediately asked to set up this prototype in their house.\n\nThe activity with the prototypes took place towards the end of a larger workshop in which other sound monitoring tools had already been discussed. This meant that the impact of the prototypes could be compared with the discussion that had already taken place. The prototypes seemed to have a dramatic effect on the level of enthusiasm in the discussion with an increase in scope and complexity of topics. Each of the four prototypes communicated their own proposition and the participants were highly engaged and tended to expand beyond the functions of the devices. Yet the prototypes required facilitation. It was not enough to simply unveil the prototypes and step back. The devices required verbal introduction to describe their function, a physical demonstration and some limited coordination of the resulting conversations. The prototypes functioned by providing a performative focus, but the researcher/designer was still involved in the infrastructuring process which required alertness and enthusiasm.\n\nThere was a broad range of reactions to the prototypes, ranging from surprise and irritation to entertainment. Rather than creating a consensus, the prototypes created a kind of good-humoured \u2018dissensus\u2019. The idea that disagreement is a productive and essential part of democracy has been made by Mouffe (2000) and extended into critical and participatory design by Disalvo (2010) who argues that the goal of design should be to facilitate agonistic spaces where disagreement can be voiced to open up new themes and trajectories for action. The atmosphere in the workshop was not hostile but rather a targeted critical discussion on the best tactics and strategies for a community noise monitoring process. The prototypes acted as provocation pieces which allowed a group of people who had not previously met to enter into deep, personal and political discussions. From a participatory design perspective \u201cconstituting a public involves discovering and expressing the attachments of a particular group. Infrastructuring, as an activity of PD, is the work, then, of providing the means for discovering and expressing those attachments in order to convey the consequences of an issue and to enroll others in a cause\u201d (Dantec and DiSalvo, 2013, p. 255).\n\nFrom my perspective as an ethnographic researcher having worked in the Heathrow context for a year, the workshop uncovered local dynamics that I was not aware of and would have found difficult to articulate as verbal questions. The activity identified the ambiguous relationship the local residents have with institutions. The main insight was the radical rhetorical translations of scale and topic within the noise issue which ranged from electronic components, people\u05f3s experience of being woken by planes, schools scared to take public positions and the disengagement of politicians. The fluidity with which micro and macro were transversed and often collapsed is a key observation at the workshop. The prototypes did not create a unidirectional shift towards the macro-level of politics, economics or \u2018the people\u2019 but instead allowed the residents to uncover the noise issue as bouncing across scales without coming to rest in any particular register. Using the insights of ANT, the issue of noise is unstable and performative and shifts scale in relation to the particular viewpoint used to look at the issue. The noise issue can appear large and insurmountable when one maps all the different institutional actors that have been gathered together and yet can appear small and manageable when one examines electronic sensors.\n\nIt is here that I see the main benefit of using \u2018issue devices\u2019 to discuss noise as a \u2018device issue\u2019. The materiality of the prototypes allowed the noise discussion to have a material basis which enabled the micro/macro-scaling to take place during the workshop. It is this specificity in relation to a contentious issue which extends critical and speculative design approaches. Instead of fantastical future visions, the micro/macro prototypes offer tangible alternatives which change the size of the noise issue by adding new actors or removing existing ones. The effect of presenting a range of four different devices meant a variety of propositions could be explored, from the conceptual towards the immediately practical. The workshop was productive in suggesting future devices which could be based on diverse and perhaps even antagonistic understandings of noise \u2013 within a single device. The workshop also provides a warning for design methods which approach this kind of situation with a view to simplistic problem solving. Carrying out technical interventions into such a complex context could have highly unpredictable consequences.\n\nFinally the workshop set in motion the building of a noise monitoring group. After the workshop a number of participants emailed me about installing one of the \u2018I turn noise into numbers\u2019 prototypes in their own home. This resulted in one device being installed at one of the participants\u2019 homes for a period of several months. The data generated was of such interest that somebody who was not the prototype\u05f3s owner informed me when the device temporarily stopped working. Since then I have created a mailing list and held another workshop, which included people who wanted to build the next iteration of the device and have it set up in their home. This group includes technical developers, a sound artist, a researcher working on the impact of noise on bio-diversity, as well as participants from the original workshop. The current prototype is loosely based on \u2018I turn noise into numbers\u2019 and uses a Raspberry Pi computer with a USB microphone, which allows higher accuracy sound measurements that relate better to the official measurements. In addition the device creates a live audio stream of aircraft flights which people can listen to on the internet. The eventual goal is for a map interface that geolocates the devices and allows website visitors to listen to the plane noise inside people\u05f3s homes. This setup will hopefully give listeners a tangible and affective experience of the noise issue which will accompany the statistical data being gathered. This iteration of the device is based on feedback from the initial workshop as well as discussions with the pressure organisation who want to draw attention to the impact of the airport on the whole of London. Being able to demonstrate that aircraft noise occurs outside of the demarcated noise exposure area will allow the organisation to create a new public framing of the noise issue. The case study is ongoing and will hopefully lead to the deployment of dozens of devices around Heathrow and the building of a new material public.", "title": "Micro/macro prototyping"}, "S092188901400178X": {"highlights": ["We present a new robot pose prediction method for static stability estimation.", "The method approximates the terrain by least-squares planes to reduce the runtime.", "A stochastic version accounts for noise in the robot state and the terrain model.", "We systematically compared it with a physics simulation in many distinct scenarios.", "The new method is significantly faster and competitive in realistic situations."], "abstract": "Due to the advancements of robotic systems, they are able to be employed in more unstructured outdoor environments. In such environments the robot\u2013terrain interaction becomes a highly non-linear function. Several methods were proposed to estimate the robot\u2013terrain interaction: machine learning methods, iterative geometric methods, quasi-static and fully dynamic physics simulations. However, to the best of our knowledge there has been no systematic evaluation comparing those methods.\n                  In this paper, we present a newly developed iterative contact point estimation method for static stability estimation of actively reconfigurable robots. This new method is systematically compared to a physics simulation in a comprehensive evaluation. Both interaction models determine the contact points between robot and terrain and facilitate a subsequent static stability prediction. Hence, they can be used in our state space global planner for rough terrain to evaluate the robot\u2019s pose and stability. The analysis also compares deterministic versions of both methods to stochastic versions which account for uncertainty in the robot configuration and the terrain model. The results of this analysis show that the new iterative method is a valid and fast approximate method. It is significantly faster compared to a physics simulation while providing good results in realistic robotic scenarios.", "title": "Design and comparative evaluation of an iterative contact point estimation method for static stability estimation of mobile actively reconfigurable robots"}, "S0888613X13002466": {"highlights": ["We model decision under uncertainty in ASP and possibilistic ASP.", "We compute optimal decisions according to possibility theory-based, optimistic and pessimistic qualitative decision criteria.", "We provide ASP-based algorithms for computing the decision criteria.", "We provide possibilistic ASP-based algorithms for computing the decision criteria."], "abstract": "A qualitative approach to decision making under uncertainty has been proposed in the setting of possibility theory, which is based on the assumption that levels of certainty and levels of priority (for expressing preferences) are commensurate. In this setting, pessimistic and optimistic decision criteria have been formally justified. This approach has been transposed into possibilistic logic in which the available knowledge is described by formulas which are more or less certainly true and the goals are described in a separate prioritized base. This paper adapts the possibilistic logic handling of qualitative decision making under uncertainty in the Answer Set Programming (ASP) setting. We show how weighted beliefs and prioritized preferences belonging to two separate knowledge bases can be handled in ASP by modeling qualitative decision making in terms of abductive logic programming where (uncertain) knowledge about the world and prioritized preferences are encoded as possibilistic definite logic programs and possibilistic literals respectively. We provide ASP-based and possibilistic ASP-based algorithms for calculating optimal decisions and utility values according to the possibilistic decision criteria. We describe a prototype implementing the algorithms proposed on top of different ASP solvers and we discuss the complexity of the different implementations.", "title": "Using possibilistic logic for modeling qualitative decision: Answer Set Programming algorithms"}, "S1071581918304956": {"highlights": ["We developed 2 virtual cursors to assist link selection for people with motor impairments.", "A web-based study with 15 users was carried out to evaluate usability of cursors.", "Keyboard users benefited from both variants but especially from the cross cursor.", "Joystick and trackball users only benefited from the area cursor.", "Results suggest improvement on performance with frequent usage of virtual cursors."], "abstract": "People with motor impairments (MI) may face accessibility barriers when using computers due to their health conditions and therefore need to use alternative devices to a standard mouse for pointing and clicking in graphical user interfaces (GUI). In this study with users of different pointing devices, we evaluate 2 virtual cursors (the novel cross cursor and the standard area cursor) implemented for assisting link selection on the Web by reducing respectively cursor displacement and the precision required. Both cursor adaptations were developed for this work based on previous research, and have been compared with the original unassisted cursor in a web-based study with fifteen regular computer users applying their usual pointing device. Nine participants with MIs participated, including 4 using keyboards as an alternative pointing device, 4 joystick users and 1 trackball user. Six participants without MIs also participated in the study applying a standard mouse to complete the same experimental tasks. User interactions with the pointing device, as well as subjective assessments about the usability of the cursor variants tested were gathered from study participants. An in-depth analysis of point and click trajectories showed that virtual cursors improved the effectiveness and efficiency of most participants with MIs in link selection. Subjective assessments about cursor variants tested showed that a majority of participants with MIs generally preferred one of either the two virtual cursors to the original one for web navigation.", "title": "Evaluation of two virtual cursors for assisting web access to people with motor impairments"}, "S0921889017307546": {"highlights": ["We proposed algorithms both for black-box-opt and reinforcement learning problems", "We showed advanced methods in optimization theories can be applied to RL algorithms", "We revealed the relation between existing reinforcement learning methods"], "abstract": "In recent years, attention has been focused on the relationship between black-box optimization problem and reinforcement learning problem. In this research, we propose the Mirror Descent Search (MDS) algorithm which is applicable both for black box optimization problems and reinforcement learning problems. Our method is based on the mirror descent method, which is a general optimization algorithm. The contribution of this research is roughly twofold. We propose two essential algorithms, called MDS and Accelerated Mirror Descent Search (AMDS), and two more approximate algorithms: Gaussian Mirror Descent Search (G-MDS) and Gaussian Accelerated Mirror Descent Search (G-AMDS). This research shows that the advanced methods developed in the context of the mirror descent research can be applied to reinforcement learning problem. We also clarify the relationship between an existing reinforcement learning algorithm and our method. With two evaluation experiments, we show our proposed algorithms converge faster than some state-of-the-art methods.", "title": "Mirror descent search and its acceleration"}, "S0933365719302544": {"highlights": ["By taking a novel view of the utilization of four criterions: BI-RADS, Boyd, Tab\u00e1r, Wolfe, the mammographic risk assessment is conducted as a multi-label learning process.", "An associated multi-label fuzzy-rough feature selection algorithm is proposed to reduce the dimension of the data sets.", "By the nature of the four criterions, the practical significance of the association rules produced in the proposed approach is verified.", "Compared to the alternative single-label feature selection methods, the proposed algorithm provides superior performances in general."], "abstract": "Context and background\n                  Breast cancer is one of the most common diseases threatening the human lives globally, requiring effective and early risk analysis for which learning classifiers supported with automated feature selection offer a potential robust solution.\n               \n               \n                  Motivation\n                  Computer aided risk analysis of breast cancer typically works with a set of extracted mammographic features which may contain significant redundancy and noise, thereby requiring technical developments to improve runtime performance in both computational efficiency and classification accuracy.\n               \n               \n                  Hypothesis\n                  Use of advanced feature selection methods based on multiple diagnosis criteria may lead to improved results for mammographic risk analysis.\n               \n               \n                  Methods\n                  An approach for multi-criterion based mammographic risk analysis is proposed, by adapting the recently developed multi-label fuzzy-rough feature selection mechanism.\n               \n               \n                  Results\n                  A system for multi-criterion mammographic risk analysis is implemented with the aid of multi-label fuzzy-rough feature selection and its performance is positively verified experimentally, in comparison with representative popular mechanisms.\n               \n               \n                  Conclusions\n                  The novel approach for mammographic risk analysis based on multiple criteria helps improve classification accuracy using selected informative features, without suffering from the redundancy caused by such complex criteria, with the implemented system demonstrating practical efficacy.", "title": "Multi-criterion mammographic risk analysis supported with multi-label fuzzy-rough feature selection"}, "S2589721719300017": {"highlights": ["AlexNet-CNNs deep learning network was applied for pesticide detection of postharvest apples.", "The method is of short time consumption and good noise immunity property.", "The accuracy of the proposed method for apple pesticide detection was 99.09%."], "abstract": "Pesticide residue is an important factor that affects food safety. In order to achieve effective detection of pesticide residues in apples, a machine-vision-based segmentation algorithm and hyperspectral techniques were used to segment the foreground and background regions of the apple image. By calculating the roundness value and extracting the region with the highest roundness value in the connected region, a region of interest (ROI) mask was created for the apple. Four pesticides (chlorpyrifos, carbendazim and two mixed pesticides) and an inactive control were used at the same concentration of 100\u202fppm (except for the control group), and the hyperspectral region of the corresponding sample image was extracted by obtaining the different types of pesticide residues in the ROI masks. To increase the diversity of the samples and to expand the dataset, Gaussian white noise with a varying signal-to-noise ratio was added to each of the hyperspectral images of the apple. The number of samples was increased from four types of 12 samples to four types of 72 samples, giving 4608 hyperspectral data images in each category. The structure and parameters of a convolutional neural network (CNN) were determined using theoretical analysis and experimental verification. All the extracted hyperspectral images of apples were normalized to 227\u202f\u00d7\u202f227\u202f\u00d7\u202f3 pixels as the input of the CNN network for pesticide residue detection. There were 18,432 sample data of four types for 72 samples. Of these, 12,288 images were selected using a bootstrap sampling method as the training set, and 6144 as the test set, with no overlap. The test results show that when the number of training epochs was 10, the accuracy of the test set detection was 99.09%, and the detection accuracy of the single-band average image was 95.35%. A comparison with traditional k-nearest neighbor (KNN) and support vector machine classification algorithms showed that the detection accuracy for KNN was 43.75% and the average time was 0.7645\u202fs. These results demonstrate that our method is a small-sample, non-contact, fast, effective and low-cost technique that can provide effective pesticide residue detection in postharvest apples.", "title": "Fusion of machine vision technology and AlexNet-CNNs deep learning network for the detection of postharvest apple pesticide residues"}, "S1071581919300874": {"highlights": ["A transfer of control consists of a series of stages, like an interruption process.", "Fast human take-over of control might not be realistic in automated driving.", "Transfer of control can contain interleaving of driving and non-driving activities."], "abstract": "As vehicles of the future take on more of the driving responsibility and the role of the driver transitions into more of a monitoring capacity, the traditional notions of interruption and attention management needs to be reconsidered for automated vehicles. We argue that the transfer of control between the automated vehicle and the human driver can be considered as an interruption handling process, and that this process goes through a series of ten explicit stages. Each stage has its own characteristics and implications for practice and future research. Therefore, in this paper we identify for each stage what is known from theory, together with important implications for safety, design, and future research, especially for human-machine interaction. More generally, the framework makes explicit that it is not appropriate to think of transfer of control as a single event or even small set of events. The framework also highlights that it might not be realistic to expect human drivers to immediately respond correctly to a system initiated request to transfer control, given that humans interleave their attention between non-driving and driving tasks, and given that a transition constitutes of multiple stages. These nuances are accounted for in the framework.", "title": "Interrupted by my car? Implications of interruption and interleaving research for automated vehicles"}, "S0888613X13001679": {"highlights": ["Propose a unifying framework for monotonic dual decomposition algorithms.", "A new view from energy distribution ratios to analyze these algorithms.", "Introduce two energy distribution criteria for faster convergence.", "Exploit dynamic energy distribution ratios to optimize the local functions.", "Propose several improved algorithms that outperform the existing ones."], "abstract": "We consider the problem of finding the most probable explanation (also known as the MAP assignment) on probabilistic graphical models. The dual decomposition algorithms based on coordinate descent are efficient approximate techniques for this problem, where the local dual functions are constructed and optimized to monotonically increase the cost of the dual function. In this paper, we present a unifying framework for constructing and optimizing these local dual functions, and introduce an energy distribution view to analyze the convergence rates of these algorithms. To optimize the local dual functions, we first propose a new concept\u2014the energy distribution ratio\u2014to describe the features of the solutions, and then derive an explicit optimal solution, which covers most of the monotonic dual decomposition algorithms. It is shown that the differences of these algorithms lie in both the forms of the local dual functions and the settings of the energy distribution ratios, and the existing algorithms mainly focus on constructing compact and solvable local dual functions. In contrast, we study the impact of the energy distribution ratios and introduce two energy distribution criteria for fast convergence. Moreover, we exploit dynamic energy distribution ratios to optimize the local dual functions, and propose a series of improved algorithms. The experimental results on synthetic and real problems show the improved algorithms outperform the existing ones on the convergence performance.", "title": "Energy distribution view for monotonic dual decomposition"}, "S0888613X14001406": {"highlights": ["A truth model of Belnap valuations for bipolar propositions is proposed.", "Two truth normalization to reduce inconsistent cases are proposed.", "A calculus of bipolar belief measures for vague propositions is proposed.", "The differences with Atanassov's IFS and interval fuzzy sets are discussed."], "abstract": "This paper assumes that each proposition can be defined by a positive criterion together with a negative criterion. Then, within the framework of propositional logic, this paper proposes Belnap valuations as a truth model for bipolar propositions. The truth value of bipolar proposition is meant to be one of four values: absolutely true, absolutely false, borderline, and inconsistent. The borderline and inconsistent cases represent the truth-gap and truth-glut of a bipolar proposition, respectively. In order to reduce inconsistency two truth normalization methods, strong truth normalization and Kleene truth normalization, are proposed to approximate the original Belnap valuations. By integrating uncertainty of the true interpretations of bipolar propositions this paper introduces the following bipolar belief measures: positive and negative belief measures, lower and upper belief measures, and Kleene lower and upper belief measures. A mass function characterization of these bipolar belief measures are further explored. The relationship with Atanassov's intuitionistic fuzzy sets and interval fuzzy sets is also discussed in detail.", "title": "On truth-gaps, truth-gluts, and bipolar propositions"}, "S1071581914001232": {"highlights": ["Participatory Design (PD) requires nuanced concepts of accountability and rigour.", "Accountability and rigour are constructed through debate, critique and reflection.", "Our \"tool-to-think-with\" guides designers in systematic and critical reflection.", "We provide four lenses for reflection: epistemology, values, stakeholders, outcomes.", "The \"coherence\" between reflective perspectives indicates internal rigour of PD work."], "abstract": "The field of Participatory Design (PD) has greatly diversified and we see a broad spectrum of approaches and methodologies emerging. However, to foster its role in designing future interactive technologies, a discussion about accountability and rigour across this spectrum is needed. Rejecting the traditional, positivistic framework, we take inspiration from related fields such as Design Research and Action Research to develop interpretations of these concepts that are rooted in PD\u05f3s own belief system. We argue that unlike in other fields, accountability and rigour are nuanced concepts that are delivered through debate, critique and reflection. A key prerequisite for having such debates is the availability of a language that allows designers, researchers and practitioners to construct solid arguments about the appropriateness of their stances, choices and judgements.\n                  To this end, we propose a \u201ctool-to-think-with\u201d that provides such a language by guiding designers, researchers and practitioners through a process of systematic reflection and critical analysis. The tool proposes four lenses to critically reflect on the nature of a PD effort: epistemology, values, stakeholders and outcomes. In a subsequent step, the coherence between the revealed features is analysed and shows whether they pull the project in the same direction or work against each other. Regardless of the flavour of PD, we argue that this coherence of features indicates the level of internal rigour of PD work and that the process of reflection and analysis provides the language to argue for it. We envision our tool to be useful at all stages of PD work: in the planning phase, as part of a reflective practice during the work, and as a means to construct knowledge and advance the field after the fact. We ground our theoretical discussions in a specific PD experience, the ECHOES project, to motivate the tool and to illustrate its workings.", "title": "In pursuit of rigour and accountability in participatory design"}, "S0957417419302507": {"highlights": ["A multi-view text classification may be better than a simple text classification.", "Feature projection methods may outperform a multi-view text classification approach.", "The proposed ranking method allows for selecting the best classification model."], "abstract": "This study aims to propose (i) a multi-view text classification method and (ii) a ranking method that allows for selecting the best information fusion layer among many variations. Multi-view document classification is worth a detailed study as it makes it possible to combine different feature sets into yet another view that further improves text classification. For this purpose, we propose a multi-view framework for text classification that is composed of two levels of information fusion. At the first level, classifiers are constructed using different data views, i.e. different vector space models by various machine learning algorithms. At the second level, the information fusion layer uses input information using a features projection method and a meta-classifier modelled by a selected machine learning algorithm. A final decision based on classification results produced by the models positioned at the first layer is reached. Moreover, we propose a ranking method to assess various configurations of the fusion layer. We use heuristics that utilise statistical properties of F-score values calculated for classification results produced at the fusion layer. The information fusion layer of the classification framework and ranking method has been empirically evaluated. For this purpose, we introduce a use case checking whether companies\u2019 domains identify their innovativeness. The results empirically demonstrate that the information fusion layer enhances classification quality. The Friedman\u2019s aligned rank and Wilcoxon signed-rank statistical tests and the effect size support this hypothesis. In addition, the Spearman statistical test carried out for the obtained results demonstrated that the assessment made by the proposed ranking method converges to a well-established method named Hellinger - The Technique for Order Preference by Similarity to Ideal Solution (H-TOPSIS). Thus, the proposed approach may be used for the assessment of classifier performance.", "title": "Empirical evaluation of feature projection algorithms for multi-view text classification"}, "S0888613X13001722": {"highlights": ["A new framework for learning from imprecise/fuzzy data, based on the modification of loss functions in empirical risk minimization.", "We show that several well-known loss functions used in the literature can be seen as special cases of our generic model.", "We develop concrete instantiations of our framework for regression and classification problems.", "We compare our new proposal with related approaches from a conceptual point of view.", "We present first experimental results on synthetic data that suggest the effectiveness of our method in dealing with imprecise and fuzzy data."], "abstract": "Methods for analyzing or learning from \u201cfuzzy data\u201d have attracted increasing attention in recent years. In many cases, however, existing methods (for precise, non-fuzzy data) are extended to the fuzzy case in an ad-hoc manner, and without carefully considering the interpretation of a fuzzy set when being used for modeling data. Distinguishing between an ontic and an epistemic interpretation of fuzzy set-valued data, and focusing on the latter, we argue that a \u201cfuzzification\u201d of learning algorithms based on an application of the generic extension principle is not appropriate. In fact, the extension principle fails to properly exploit the inductive bias underlying statistical and machine learning methods, although this bias, at least in principle, offers a means for \u201cdisambiguating\u201d the fuzzy data. Alternatively, we therefore propose a method which is based on the generalization of loss functions in empirical risk minimization, and which performs model identification and data disambiguation simultaneously. Elaborating on the fuzzification of specific types of losses, we establish connections to well-known loss functions in regression and classification. We compare our approach with related methods and illustrate its use in logistic regression for binary classification.", "title": "Learning from imprecise and fuzzy observations: Data disambiguation through generalized loss minimization"}, "S1567422316300783": {"highlights": ["We developed methodological guidelines for management of business alliances.", "We implemented a platform for interoperability and collaborations.", "We developed a lightweight semantic search graph/network of interconnected entities.", "We have provided a proof of concept implementation of lightweight semantic search."], "abstract": "The networked enterprise is a short-term partnership of business organizations aimed at sharing the partners\u2019 services without restrictions on size or organizational structure. Our approach considers two software solutions developed for supporting the creation and maintenance of such business collaborations in interoperable networks. The first one addresses a business alliance formation based on combining competences, processes and services of several organizations into a single value chain. Our emphasis is mainly on the interoperability and security of the provided services. The second approach focuses on the collaboration between large enterprises with rich IT ecosystems and SMEs with poor or missing IT infrastructure. Interoperable data sharing is supported by light-weight semantics, while standard inter-SME communication is enriched to grant authentication among partners. Alternatives for enabling technologies for service orchestration, process modelling, and event routing are investigated for the solutions. Based on the evaluation results obtained from pilot testing of the system prototypes, we discuss the implications of the technologies on quality indicators such as usability, performance, and business applicability.", "title": "A process-oriented service infrastructure for networked enterprises"}, "S0957417415003346": {"highlights": ["Paper proposes the Fuzzy C-means++ method for improving the effectiveness and speed of the Fuzzy C-means algorithm.", "This method works by spreading the initial cluster representatives in the data space at initialization.", "The proposed algorithm achieves superior results on both artificially generated and real world data sets."], "abstract": "Fuzzy C-means has been utilized successfully in a wide range of applications, extending the clustering capability of the K-means to datasets that are uncertain, vague and otherwise hard to cluster. This paper introduces the Fuzzy C-means++ algorithm which, by utilizing the seeding mechanism of the K-means++ algorithm, improves the effectiveness and speed of Fuzzy C-means. By careful seeding that disperses the initial cluster centers through the data space, the resulting Fuzzy C-means++ approach samples starting cluster representatives during the initialization phase. The cluster representatives are well spread in the input space, resulting in both faster convergence times and higher quality solutions. Implementations in R of standard Fuzzy C-means and Fuzzy C-means++ are evaluated on various data sets. We investigate the cluster quality and iteration count as we vary the spreading factor on a series of synthetic data sets. We run the algorithm on real world data sets and to account for the non-determinism inherent in these algorithms we record multiple runs while choosing different k parameter values. The results show that the proposed method gives significant improvement in convergence times (the number of iterations) of up to 40 (2.1 on average) times the standard on synthetic datasets and, in general, an associated lower cost function value and Xie\u2013Beni value. A proof sketch of the logarithmically bounded expected cost function value is given.", "title": "Fuzzy C-means++: Fuzzy C-means with effective seeding initialization"}, "S0740818818302913": {"highlights": ["Creating different types of assessment tools can help meet the various needs of library makerspace patrons.", "A makerspace assessment matrix can support librarians in matching the educational needs of patrons with library data.", "All assessment tools have benefits and limitations, so a combination of tools is likely to be the best approach."], "abstract": "The emergence of maker culture has led to an increase of makerspaces across a variety of educational organizations, including public libraries. These makerspaces provide library patrons with new opportunities to learn and create through exploration, creation, and play. However, as the number of library makerspaces grows, so does the need for assessing learning in those same spaces. There is a small amount of research completed on assessing learning of makerspaces in public libraries. The researchers in this study examine patron use of a library makerspace through a theoretical framework based on modern assessment research. Soon after the study began, it was necessary to rethink the original research questions and methods in order to better understand how assessment could be effectively implemented. Findings include determining the scope of library makerspace participants and their assessment needs, potential assessments that can address those needs, and design implications for assessments in library makerspaces.", "title": "An assessment matrix for library makerspaces"}, "S0921889015300889": {"highlights": ["We propose a new method for loop closure detection for topological mapping.", "It uses relative spatial co-occurrence information to improve the performance.", "We augment BoW method with a dictionary of spatially co-occurring word pairs.", "A memory map data structure is used for storing and indexing word pairs.", "We incorporate best of the existing methods to provide state-of-the-art performance."], "abstract": "In this paper, we look into the problem of loop closure detection in topological mapping. The bag of words (BoW) is a popular approach which is fast and easy to implement, but suffers from perceptual aliasing, primarily due to vector quantization. We propose to overcome this limitation by incorporating the spatial co-occurrence information directly into the dictionary itself. This is done by creating an additional dictionary comprising of word pairs, which are formed by using a spatial neighborhood defined based on the scale size of each point feature. Since the word pairs are defined relative to the spatial location of each point feature, they exhibit a directional attribute which is a new finding made in this paper. The proposed approach, called bag of word pairs (BoWP), uses relative spatial co-occurrence of words to overcome the limitations of the conventional BoW methods. Unlike previous methods that use spatial arrangement only as a verification step, the proposed method incorporates spatial information directly into the detection level and thus, influences all stages of decision making. The proposed BoWP method is implemented in an on-line fashion by incorporating some of the popular concepts such as, K-D tree for storing and searching features, Bayesian probabilistic framework for making decisions on loop closures, incremental creation of dictionary and using RANSAC for confirming loop closure for the top candidate. Unlike previous methods, an incremental version of K-D tree implementation is used which prevents rebuilding of tree for every incoming image, thereby reducing the per image computation time considerably. Through experiments on standard datasets it is shown that the proposed methods provide better recall performance than most of the existing methods. This improvement is achieved without making use any geometric information obtained from range sensors or robot odometry. The computational requirements for the algorithm is comparable to that of BoW methods and is shown to be less than the latest state-of-the-art method in this category.", "title": "High performance loop closure detection using bag of word pairs"}, "S0957417417305353": {"highlights": ["The Analytic Hierarchy Process does not account for user profile disparities.", "A sensitivity analysis method is proposed to address these disparities.", "Inputs that most critically impact the aggregated group results are determined.", "Decision makers are now informed of the most influential elements of the process."], "abstract": "Decision makers often face complex problems, which can seldom be addressed well without the use of structured analytical models. Mathematical models have been developed to streamline and facilitate decision making activities, and among these, the Analytic Hierarchy Process (AHP) constitutes one of the most utilized multi-criteria decision analysis methods. While AHP has been thoroughly researched and applied, the method still shows limitations in terms of addressing user profile disparities. A novel sensitivity analysis method based on local partial derivatives is presented here to address these limitations. This new methodology informs AHP users of which pairwise comparisons most impact the derived weights and the ranking of alternatives. The method can also be applied to decision processes that require the aggregation of results obtained by several users, as it highlights which individuals most critically impact the aggregated group results while also enabling to focus on inputs that drive the final ordering of alternatives. An aerospace design and engineering example that requires group decision making is presented to demonstrate and validate the proposed methodology.\n               \n            \n\nPairwise comparison in the kth row and the lth column in a pairwise comparison table\n\nNormalized row geometric mean of the kth criterion in the pairwise comparison table input by user Pj\n                        \n                     \n\nRow geometric mean of the kth criterion in the comparison table input by user Pj\n                        \n                     \n\nPairwise comparison matrix input by user Pj\n                        \n                     \n\nError associated with element aij\n                        \n                     \n\nNormalized group row geometric mean for the kth criterion at the ith level under the criteria j\n                        \n                           i\u202f\u2212\u202f1\n                     \n\nGroup row geometric mean for the kth criterion at the ith level under the criteria j\n                        \n                           i\u202f\u2212\u202f1\n                     \n\nLargest eigenvalue of a pairwise comparison table\n\nConsistency Index of a pairwise comparison table\n\nNumber of criteria in level i under the criteria j\n                        \n                           i\u202f\u2212\u202f1 in the upper level\n\nUser i\n                     \n\nRelative weight of design alternative q\n                     \n\nRelative weight of the criteria J in level I\n                     \n\nRelative weight of design alternative q", "title": "Sensitivity analysis method to address user disparities in the analytic hierarchy process"}, "S0957417418304214": {"highlights": ["Investigation into the development of a multi-disciplinary diagnosis framework for Tuberculosis.", "Tuberculosis-specific antibody detection in real time using mobile phone.", "Exploration of image processing technique to analyse contents of plasmonic ELISA without experts.", "Enhancement of detection accuracy using mobile enabled expert system up to 98.4%."], "abstract": "This paper presents an investigation into the development of an intelligent mobile-enabled expert system to perform an automatic detection of tuberculosis (TB) disease in real-time. One third of the global population are infected with the TB bacterium, and the prevailing diagnosis methods are either resource-intensive or time consuming. Thus, a reliable and easy\u2013to-use diagnosis system has become essential to make the world TB free by 2030, as envisioned by the World Health Organisation. In this work, the challenges in implementing an efficient image processing platform is presented to extract the images from plasmonic ELISAs for TB antigen-specific antibodies and analyse their features. The supervised machine learning techniques are utilised to attain binary classification from eighteen lower-order colour moments. The proposed system is trained off-line, followed by testing and validation using a separate set of images in real-time. Using an ensemble classifier, Random Forest, we demonstrated 98.4% accuracy in TB antigen-specific antibody detection on the mobile platform. Unlike the existing systems, the proposed intelligent system with real time processing capabilities and data portability can provide the prediction without any opto-mechanical attachment, which will undergo a clinical test in the next phase.", "title": "An intelligent mobile-enabled expert system for tuberculosis disease diagnosis in real time"}, "S0888613X13002107": {"highlights": ["We propose a method for learning mixtures of polynomials from data.", "We estimate one-dimensional and multidimensional probability densities.", "We build non-parametric Bayesian classifiers, yielding competitive accuracies.", "We implement the methods in an R package."], "abstract": "Non-parametric density estimation is an important technique in probabilistic modeling and reasoning with uncertainty. We present a method for learning mixtures of polynomials (MoPs) approximations of one-dimensional and multidimensional probability densities from data. The method is based on basis spline interpolation, where a density is approximated as a linear combination of basis splines. We compute maximum likelihood estimators of the mixing coefficients of the linear combination. The Bayesian information criterion is used as the score function to select the order of the polynomials and the number of pieces of the MoP. The method is evaluated in two ways. First, we test the approximation fitting. We sample artificial datasets from known one-dimensional and multidimensional densities and learn MoP approximations from the datasets. The quality of the approximations is analyzed according to different criteria, and the new proposal is compared with MoPs learned with Lagrange interpolation and mixtures of truncated basis functions. Second, the proposed method is used as a non-parametric density estimation technique in Bayesian classifiers. Two of the most widely studied Bayesian classifiers, i.e., the naive Bayes and tree-augmented naive Bayes classifiers, are implemented and compared. Results on real datasets show that the non-parametric Bayesian classifiers using MoPs are comparable to the kernel density-based Bayesian classifiers. We provide a free R package implementing the proposed methods.", "title": "Learning mixtures of polynomials of multidimensional probability densities from data using B-spline interpolation"}, "S0888613X14001728": {"highlights": ["One system of expressing uncertainty in natural languages involves approximators.", "Approximators are linguistic hedges such as \u201cabout\u201d or \u201cmore than\u201d, with a number.", "We used Amazon Mechanical Turk to decode quantitative meanings of approximators.", "Human interpretations vary widely, but there may be as few as three kinds of hedges.", "Hedge word choice interacts with the magnitude and roundness of the nominal quantity."], "abstract": "An important part of processing elicited numerical inputs is an ability to quantitatively decode natural-language words that are commonly used to express or modify numerical values. These include \u2018about\u2019, \u2018around\u2019, \u2018almost\u2019, \u2018exactly\u2019, \u2018nearly\u2019, \u2018below\u2019, \u2018at least\u2019, \u2018order of\u2019, etc., which are collectively known as approximators or numerical hedges. Figuring out the quantitative implications of these expressions for the uncertainty of numerical quantities is important for being able to understand, for example, what is actually being reported by a patient who says a headache has lasted for \u201cabout 7 days\u201d, and how we should translate the patient's report into uncertainty about the duration. We used Amazon Mechanical Turk to empirically identify the implications of various approximators common in English. To evaluate the numerical range implied by each approximator, we analyzed paired statements differing only in the approximator used in numerical expressions. Despite often considerable diversity, there were several statistically significant findings, but far less quantitative variation implied by the approximators than might have been expected. The numerical implication of different approximators interacts with the magnitude and roundness of the nominal quantity. This investigation strategy generalizes easily to languages other than English.", "title": "Natural language of uncertainty: numeric hedge words"}, "S0921889018302227": {"highlights": ["BCI-controlled autonomous robotic service assistant.", "First online brain\u2013computer-interface using deep learning.", "Menu-driven language generation based on referring expressions.", "Modular ROS-based mobile robot interaction.", "Experimental evaluation with a real robot."], "abstract": "As autonomous service robots become more affordable and thus available for the general public, there is a growing need for user-friendly interfaces to control these systems. Control interfaces typically get more complicated with increasing complexity of robotic tasks and environments. Traditional control modalities such as touch, speech or gesture are not necessarily suited for all users. While some users can make the effort to familiarize themselves with a robotic system, users with motor disabilities may not be capable of controlling such systems even though they need robotic assistance most. In this paper, we present a novel framework that allows these users to interact with a robotic service assistant in a closed-loop fashion, using only thoughts. The system is composed of several interacting components: a brain\u2013computer interface (BCI) that uses non-invasive neuronal signal recording and co-adaptive deep learning, high-level task planning based on referring expressions, navigation and manipulation planning as well as environmental perception. We extensively evaluate the BCI in various tasks, determine the performance of the goal formulation user interface and investigate its intuitiveness in a user study. Furthermore, we demonstrate the applicability and robustness of the system in real-world scenarios, considering fetch-and-carry tasks, close human\u2013robot interactions and in presence of unexpected changes. As our results show, the system is capable of adapting to frequent changes in the environment and reliably accomplishes given tasks within a reasonable amount of time. Combined with high-level task planning based on referring expressions and an autonomous robotic system, interesting new perspectives open up for non-invasive BCI-based human\u2013robot interactions.", "title": "A service assistant combining autonomous robotics, flexible goal formulation, and deep-learning-based brain\u2013computer interfacing"}, "S0921889014000396": {"highlights": ["Novel computational framework for sensory-motor integration learning.", "Cross-modal memory retrieval utilizing a deep autoencoder.", "Noise-robust behavior recognition utilizing acquired multimodal features.", "Multimodal causality acquisition and sensory-motor prediction."], "abstract": "For humans to accurately understand the world around them, multimodal integration is essential because it enhances perceptual precision and reduces ambiguity. Computational models replicating such human ability may contribute to the practical use of robots in daily human living environments; however, primarily because of scalability problems that conventional machine learning algorithms suffer from, sensory-motor information processing in robotic applications has typically been achieved via modal-dependent processes. In this paper, we propose a novel computational framework enabling the integration of sensory-motor time-series data and the self-organization of multimodal fused representations based on a deep learning approach. To evaluate our proposed model, we conducted two behavior-learning experiments utilizing a humanoid robot; the experiments consisted of object manipulation and bell-ringing tasks. From our experimental results, we show that large amounts of sensory-motor information, including raw RGB images, sound spectrums, and joint angles, are directly fused to generate higher-level multimodal representations. Further, we demonstrated that our proposed framework realizes the following three functions: (1) cross-modal memory retrieval utilizing the information complementation capability of the deep autoencoder; (2) noise-robust behavior recognition utilizing the generalization capability of multimodal features; and (3) multimodal causality acquisition and sensory-motor prediction based on the acquired causality.", "title": "Multimodal integration learning of robot behavior using deep neural networks"}, "S0736584515301447": {"highlights": ["A safe trajectory generation in dynamic environments.", "The evaluation of human motion.", "A strategy adapted for industrial robot already installed in the production line.", "The system is based on neural network in order to create the waypoints required for dynamic obstacles avoidance.", "Finally, a quintic polynomial function is used in order to smooth motion and least-square is computed for an optimal trajectory."], "abstract": "Interactive robot doing collaborative work in hybrid work cell need adaptive trajectory planning strategy. Indeed, systems must be able to generate their own trajectories without colliding with dynamic obstacles like humans and assembly components moving inside the robot workspace. The aim of this paper is to improve collision-free motion planning in dynamic environment in order to insure human safety during collaborative tasks such as sharing production activities between human and robot. Our system proposes a trajectory generating method for an industrial manipulator in a shared workspace. A neural network using a supervised learning is applied to create the waypoints required for dynamic obstacles avoidance. These points are linked with a quintic polynomial function for smooth motion which is optimized using least-square to compute an optimal trajectory. Moreover, the evaluation of human motion forms has been taken into consideration in the proposed strategy. According to the results, the proposed approach is an effective solution for trajectories generation in a dynamic environment like a hybrid workspace.", "title": "Human-robot collaboration while sharing production activities in dynamic environment: SPADER system"}, "S1474034614000184": {"highlights": ["Holistic data analytics approach for analyzing shape data for engineering design.", "Surface meshes are introduced as unified shape representation.", "Modeling shape variations and the interrelation to changes in design quality.", "Study techniques for sensitivity analysis, concept retrieval, interaction analysis.", "Application and investigation of passenger car design data."], "abstract": "Although the integration of engineering data within the framework of product data management systems has been successful in the recent years, the holistic analysis (from a systems engineering perspective) of multi-disciplinary data or data based on different representations and tools is still not realized in practice. At the same time, the application of advanced data mining techniques to complete designs is very promising and bears a high potential for synergy between different teams in the development process. In this paper, we propose shape mining as a framework to combine and analyze data from engineering design across different tools and disciplines. In the first part of the paper, we introduce unstructured surface meshes as meta-design representations that enable us to apply sensitivity analysis, design concept retrieval and learning as well as methods for interaction analysis to heterogeneous engineering design data. We propose a new measure of relevance to evaluate the utility of a design concept. In the second part of the paper, we apply the formal methods to passenger car design. We combine data from different representations, design tools and methods for a holistic analysis of the resulting shapes. We visualize sensitivities and sensitive cluster centers (after feature reduction) on the car shape. Furthermore, we are able to identify conceptual design rules using tree induction and to create interaction graphs that illustrate the interrelation between spatially decoupled surface areas. Shape data mining in this paper is studied for a multi-criteria aerodynamic problem, i.e. drag force and rear lift, however, the extension to quality criteria from different disciplines is straightforward as long as the meta-design representation is still applicable.", "title": "Shape mining: A holistic data mining approach for engineering design"}, "S0957417416305929": {"highlights": ["A divide-and-conquer method classifying sentence types before sentiment analysis.", "Classifying sentence types by the number of opinion targets a sentence contain.", "A data-driven approach automatically extract features from input sentences."], "abstract": "Different types of sentences express sentiment in very different ways. Traditional sentence-level sentiment classification research focuses on one-technique-fits-all solution or only centers on one special type of sentences. In this paper, we propose a divide-and-conquer approach which first classifies sentences into different types, then performs sentiment analysis separately on sentences from each type. Specifically, we find that sentences tend to be more complex if they contain more sentiment targets. Thus, we propose to first apply a neural network based sequence model to classify opinionated sentences into three types according to the number of targets appeared in a sentence. Each group of sentences is then fed into a one-dimensional convolutional neural network separately for sentiment classification. Our approach has been evaluated on four sentiment classification datasets and compared with a wide range of baselines. Experimental results show that: (1) sentence type classification can improve the performance of sentence-level sentiment analysis; (2) the proposed approach achieves state-of-the-art results on several benchmarking datasets.", "title": "Improving sentiment analysis via sentence type classification using BiLSTM-CRF and CNN"}, "S0921889016306790": {"highlights": ["Scan registration method that employs additional channels of information like color, intensity.", "Integrates new channels into point covariance weights used in registration optimization.", "Improves registration in regions with limited geometric features, without computation penalty.", "Demonstrated on Ford, Freiburg, and Waterloo hallway datasets."], "abstract": "Current state of the art scan registration algorithms which use only position information often fall victim to correspondence ambiguity and degeneracy in the optimization solutions. Other methods which use additional channels, such as color or intensity, often use only a small fraction of the available information and ignore the underlying structural information of the added channels. The proposed method incorporates the additional channels directly into the scan registration formulation to provide information within the plane of the surface. This is achieved by calculating the uncertainty both along and perpendicular to the local surface at each point and calculating nearest neighbor correspondences in the higher dimensional space. The proposed method reduces instances of degenerate transformation estimates and improves both registration accuracy and convergence rate. The method is tested on the Ford Vision and Lidar dataset using both color and intensity channels, as well as with Microsoft Kinect data from the Freiburg RGBD Office dataset and data obtained from the University of Waterloo campus.", "title": "Multi-Channel Generalized-ICP: A robust framework for multi-channel scan registration"}, "S0893608018303319": {"highlights": ["Developing a stochastic gradient-free neural network based on ensemble randomized maximum likelihood.", "Utilizing covariance matrices for optimization instead of gradients in the training process.", "Able to simultaneously provide estimations and perform uncertainty quantification.", "Robust to small data size and suitable for real-world engineering applications."], "abstract": "In this study, an efficient stochastic gradient-free method, the ensemble neural networks (ENN), is developed. In the ENN, the optimization process relies on covariance matrices rather than derivatives. The covariance matrices are calculated by the ensemble randomized maximum likelihood algorithm (EnRML), which is an inverse modeling method. The ENN is able to simultaneously provide estimations and perform uncertainty quantification since it is built under the Bayesian framework. The ENN is also robust to small training data size because the ensemble of stochastic realizations essentially enlarges the training dataset. This constitutes a desirable characteristic, especially for real-world engineering applications. In addition, the ENN does not require the calculation of gradients, which enables the use of complicated neuron models and loss functions in neural networks. We experimentally demonstrate benefits of the proposed model, in particular showing that the ENN performs much better than the traditional Bayesian neural networks (BNN). The EnRML in ENN is a substitution of gradient-based optimization algorithms, which means that it can be directly combined with the feed-forward process in other existing (deep) neural networks, such as convolutional neural networks (CNN) and recurrent neural networks (RNN), broadening future applications of the ENN.", "title": "Ensemble Neural Networks (ENN): A gradient-free stochastic method"}, "S0957417418302161": {"highlights": ["We propose a framework of classifying people in history into rivalry power groups (parties).", "The proposed method employs graph-based semi-supervised learning.", "To create a network from genealogy, we propose a method for converting the tree structure to a network.", "We devise a labeling method using historical records on political decisions.", "The paper is a pioneering work of machine learning applied to history, which can help people infer the unrevealed facts in history."], "abstract": "In the past, most historical research has been manually carried out by exploring historical facts reading between the lines of documents. Nowadays, historical big data has become electronically available and advances in machine learning techniques allow us to analyze the vast amount of historical data. From a historical perspective, making inferences about political stances of historical figures is important for grasping historical rivalries and power structures of an era. Thus, in this paper, we propose an approach to the systematic inference of power mechanisms based on a human network constructed from historical data. In this network, humans are linked according to the degree of kinship using genealogy records, and identified by political stances on agendas recorded in the annals of a dynasty as a political force. And then, a machine learning algorithm, semi-supervised learning, classifies humans who cannot identify political stances as political forces that reflect the links of the networks. The data consist of the genealogy of the Andong Gwon clan, a record of family relations of 10,243 people from the 10th to 15th century Korea, and the Annals of the Joseon Dynasty, a historical volume that describes historical facts of the Joseon Dynasty for 472 years and is composed of 1894 fascicles and 888 books. From the data, we construct a human network based on a historically meaningful period (1443\u20131488), and classify people into two political forces using the proposed method. We suggest that this machine learning approach to historical study could be utilized as a potent reference tool devoid of the subjectivism of human experts in the field of history.", "title": "Historical inference based on semi-supervised learning"}, "S1071581918303756": {"highlights": ["The main contributions of this paper are:", "We developed a new serious game for teaching the principles and skills of sustainable fishery stock management in Aquaculture.", "We compared two methods of using the game: student-led, exploration-based learning versus passive viewing of an expert demonstration.", "We used a mixed-methods (qualitative-quantitative) triangulation approach for robust data gathering.", "Students enjoyed the experience of using the game and said it was beneficial for learning.", "Expert demonstration was more effective for learning effectiveness than student-led exploration."], "abstract": "There is increasing interest in the use of serious games in STEM education. Interactive simulations and serious games can be used by students to explore systems where it would be impractical or unethical to perform real world studies or experiments. Simulations also have the capacity to reveal the internal workings of systems where these details are hidden in the real world. However, there is still much to be investigated about the best methods for using these games in the classroom so as to derive the maximum educational benefit. We report on an experiment to compare two different methods of using a serious game for teaching a complex concept in marine ecology, in a university setting: expert demonstration versus exploration-based learning. We created an online game based upon a mathematical simulation of fishery management, modelling how fish populations grow and shrink in the presence of stock removal through fishing. The player takes on the role of a fishery manager, who must set annual catch quotas, making these as high as possible to maximise profit, without exceeding sustainable limits and causing the stock to collapse. There are two versions of the game. The \u201cwhite-box\u201d or \u201cteaching\u201d game gives the player full information about all model parameters and actual levels of stock in the ocean, something which is impossible to measure in reality. The \u201cblack-box\u201d or \u201ctesting\u201d game displays only the limited information that is available to fishery managers in the real world, and is used to test the player's understanding of how to use that information to solve the problem of estimating the optimal catch quota.\n                  Our study addresses the question of whether students are likely to learn better by freely exploring the teaching game themselves, or by viewing a demonstration of the game being played expertly by the lecturer. We conducted an experiment with two groups of students, one using free, self-directed exploration and the other viewing an expert demonstration. Both groups were then assessed using the black box testing game, and completed a questionnaire. Our results show a statistically significant benefit for expert demonstration over free exploration. Qualitative analysis of the responses to the questionnaire demonstrates that students saw benefits to both teaching approaches, and many would have preferred a combination of expert demonstration with exploration of the game. The research was carried out among a mix of undergraduate and taught postgraduate science students. Future research challenges include extending the current study to larger cohorts and exploring the potential effectiveness of serious games and interactive simulation-based teaching methods in a range of STEM subjects in both university and school settings.", "title": "A comparison of two methods of using a serious game for teaching marine ecology in a university setting"}, "S0957417414007659": {"highlights": ["Modelling temporal and measurement uncertainty aspects of machine tool calibration.", "Development of a multi-objective domain-independent error mapping model.", "Experimental analysis containing twelve different calibration instances.", "Results identify the feasibility of multi-objective optimisation results.", "Further optimisation is achieved through the use of High Performance Computing."], "abstract": "Error mapping of machine tools is a multi-measurement task that is planned based on expert knowledge. There are no intelligent tools aiding the production of optimal measurement plans. In previous work, a method of intelligently constructing measurement plans demonstrated that it is feasible to optimise the plans either to reduce machine tool downtime or the estimated uncertainty of measurement due to the plan schedule. However, production scheduling and a continuously changing environment can impose conflicting constraints on downtime and the uncertainty of measurement. In this paper, the use of the produced measurement model to minimise machine tool downtime, the uncertainty of measurement and the arithmetic mean of both is investigated and discussed through the use of twelve different error mapping instances. The multi-objective search plans on average have a 3% reduction in the time metric when compared to the downtime of the uncertainty optimised plan and a 23% improvement in estimated uncertainty of measurement metric when compared to the uncertainty of the temporally optimised plan. Further experiments on a High Performance Computing (HPC) architecture demonstrated that there is on average a 3% improvement in optimality when compared with the experiments performed on the PC architecture. This demonstrates that even though a 4% improvement is beneficial, in most applications a standard PC architecture will result in valid error mapping plan.", "title": "Multi-objective optimisation of machine tool error mapping using automated planning"}, "S1319157818311649": {"highlights": ["Sindhi is one of the oldest languages of the world having proper and complex grammar, morphological structure and big number of alphabet.", "This research study analyzes the sentiment based text corpus of Sindhi language.", "The purpose of this research study is to develop the Sindhi text corpus for analysis of feature distribution, language variation and sentiment analysis.", "This research study is derived from my research study on \u201csentiment analysis for Sindhi text\u201d which is submitted at SZABIST Karachi Sindh Pakistan.", "This research study opens doors for research on word2vec, feature analysis and aspect based sentiment analysis."], "abstract": "Sindhi language is a rich language with plenty of literary and general texts. There are number of books, newspapers, magazines and internet material available to develop Sindhi text corpus but yet proper and useful text corpus could not be developed and presented online for research, language features analysis, linguistics analysis and information retrieval systems. The lack of resources for research on computational linguistics and NLP applications for Sindhi language are challenging tasks at this stage. However, we have developed Sindhi text corpora in order to provide text resources to computational linguists, Natural Languages process (NLP) experts and researchers. Online books, newspapers, magazines, blogs and social websites are utilized to build Sindhi text corpus. Sindhi sentiment based text corpus is developed and analyzed with Document Term Matrix and TF-IDF models using 2-gram technique of n-gram model. The corpus may be useful for research on language variation analysis, sentiment analysis, aspect based sentiment analysis, semantic analysis, machine translation, information retrieval, Word2Vec, topic modeling and cluster analysis.", "title": "Development of Sindhi text corpus"}, "S0925231219307611": {"highlights": ["A new prototype selection for multi-output regression data sets is presented.", "A multi-objective evolutionary algorithm is used for prototype selection.", "Multiple Pareto fronts are also used to prevent overfitting.", "The new method improved the predictive capabilities and also greatly reduced data set size."], "abstract": "A novel approach to prototype selection for multi-output regression data sets is presented. A multi-objective evolutionary algorithm is used to evaluate the selections using two criteria: training data set compression and prediction quality expressed in terms of root mean squared error. A multi-target regressor based on k-NN was used for that purpose during the training to evaluate the error, while the tests were performed using four different multi-target predictive models. The distance matrices used by the multi-target regressor were cached to accelerate operational performance. Multiple Pareto fronts were also used to prevent overfitting and to obtain a broader range of solutions, by using different probabilities in the initialization of populations and different evolutionary parameters in each one. The results obtained with the benchmark data sets showed that the proposed method greatly reduced data set size and, at the same time, improved the predictive capabilities of the multi-output regressors trained on the reduced data set.", "title": "Evolutionary prototype selection for multi-output regression"}, "S0957417418303361": {"highlights": ["Reviewing state-of-the-art studies relevant to mining user feedbacks.", "Identification of review mining techniques reported in the literature.", "Identification of software tools to support user feedback mining.", "Identification of mobile app development topics discussed in reviews.", "Discussing challenges and open problems in the area."], "abstract": "Mobile application (app) websites such as Google Play and AppStore allow users to review their downloaded apps. Such reviews can be useful for app users, as they may help users make an informed decision; such reviews can also be potentially useful for app developers, if they contain valuable information concerning user needs and requirements. However, in order to unleash the value of app reviews for mobile app development, intelligent mining tools that can help discern relevant reviews from irrelevant ones must be provided. This paper surveys the state of the art in the development of such tools and techniques behind them. To gain insight into the maturity of the current support mining tools, the paper will also find out what app development information these tools have discovered and what challenges they are facing. The results of this survey can inform the development of more effective and intelligent app review mining techniques and tools.", "title": "Extracting useful software development information from mobile application reviews: A survey of intelligent mining techniques and tools"}, "S0933365718302598": {"highlights": ["Autism spectrum disorder (ASD) affects 750,000 American Children under the age of 10.", "Emotion classifiers integrated into mobile solutions can be used for screening and therapy.", "Emotion classifiers do not generalize well to children due to a lack of labeled training data.", "We propose a method of aggregating emotive video through a mobile game.", "We demonstrate that several algorithms can automatically label frames from video derived from the game."], "abstract": "Autism spectrum disorder (ASD) is a neurodevelopmental disorder characterized by repetitive behaviors, narrow interests, and deficits in social interaction and communication ability. An increasing emphasis is being placed on the development of innovative digital and mobile systems for their potential in therapeutic applications outside of clinical environments. Due to recent advances in the field of computer vision, various emotion classifiers have been developed, which have potential to play a significant role in mobile screening and therapy for developmental delays that impair emotion recognition and expression. However, these classifiers are trained on datasets of predominantly neurotypical adults and can sometimes fail to generalize to children with autism. The need to improve existing classifiers and develop new systems that overcome these limitations necessitates novel methods to crowdsource labeled emotion data from children. In this paper, we present a mobile charades-style game, Guess What?, from which we derive egocentric video with a high density of varied emotion from a 90-second game session. We then present a framework for semi-automatic labeled frame extraction from these videos using meta information from the game session coupled with classification confidence scores. Results show that 94%, 81%, 92%, and 56% of frames were automatically labeled correctly for categories disgust, neutral, surprise, and scared respectively, though performance for angry and happy did not improve significantly from the baseline.", "title": "Labeling images with facial emotion and the potential for pediatric healthcare"}, "S0952197619300442": {"highlights": ["ANDES analyze biometric and physiological signals of the crowd.", "ANDES can determine the public space and real estate values (DS).", "A neuro decision matrix was used in the integrated analysis of the crowd and DS.", "ANDES create affective and physiological maps of sites in question.", "Based on such maps, ANDES give tips for stakeholder groups."], "abstract": "Multiple-criteria decision-making (MCDM) typically assumes that crowds make completely rational decisions. In MCDM, a crowd as a whole, or its individual members, generally make decisions free from any influence of valence, arousal, emotional state or environment. In contrast, various theories dealing with crowd psychology (Gustave Le Bon, Freudian, Deindividuation, Convergence, Emergent norm, Social identity) analyze, in one form or another, the emotions of the crowd. According to above theories, crowd is influenced by a range of behavioral factors, such as physical, social, psychological, culture, norms, and emotions. It can be argued that the emotional state, valence and arousal of crowds affect their decision making to a considerable degree and multiple criteria crowd behavior modeling must, therefore, consider this impact as well. In this light, the integration of crowd simulation and biometric methods, behavioral operations research and emotions in decision making has taken a prominent place as it leads to a better understanding of crowd emotions and crowd decision making. In this context, the authors developed the Affective Analytics of Demonstration Sites (ANDES) that added to this body of research in four ways. The crowd analysis and simulations conducted with ANDES used a neuro decision matrix. The matrix contains a detailed description of demonstration sites (public spaces) in question and the emotions, valence, arousal and physiological parameters of people present there. With ANDES\u2019s Remote Sensor Network, emotional (emotions, valence, arousal) and physiological (average crowd facial temperature, crowd composition by gender and age group, etc.) parameters of people present at demonstration sites can be mapped. ANDES can assist experts in more effective implementations of public spaces planning and a participation process by attendees by collecting and examining various layers of data on the emotional and physiological parameters of visitors based on a visitors-centric public spaces planning approach. ANDES can determine the public space and real estate values.", "title": "Affective analytics of demonstration sites"}, "S1071581914001220": {"highlights": ["Five fundamental aspects of PD from classic participatory design literature.", "Five main categories of research contributions.", "We identify how participation is defined.", "We identify how participation is conducted in experimental design cases."], "abstract": "We investigate the diversity of participatory design research practice, based on a review of ten years of participatory design research published as full research papers at the Participatory Design Conferences (PDC) 2002\u20132012, and relate this body of research to five fundamental aspects of PD from classic participatory design literature. We identify five main categories of research contributions: Participatory Design in new domains, Participatory Design methods, Participatory Design and new technology, Theoretical contributions to Participatory Design, and Basic concepts in Participatory Design. Moreover, we identify how participation is defined, and how participation is conducted in experimental design cases, with a particular focus on interpretation, planning, and decision-making in the design process.", "title": "The diversity of participatory design research practice at PDC 2002\u20132012"}, "S0142061519316394": {"highlights": ["A partial discharge (PD) measuring system was investigated and deployed.", "The measuring system can measure PD in a HV cable joint under impulse conditions.", "HFCT sensors were used to localize PD and to separate PD from disturbance.", "Band pass filters enable disturbance suppression and PD detection during impulses."], "abstract": "A partial discharge (PD) measuring system has been deployed in order to identify and measure PD in a high voltage (HV) cable joint under impulse and superimposed voltages under laboratory conditions. The challenge is to enable the detection of PD during the impulse conditions. The method of measurement has been investigated by introducing an artificial defect in the cable joint in a controlled way to create conditions for partial discharges to occur. Next the HV cable system is subjected to AC, impulse and superimposed voltage. Two high frequency current transformers (HFCT) installed at both ends of the cable joint were used to identify PD from the cable joint and to separate PD from disturbance. Transient voltage suppressors and spark gaps are applied to protect the measuring equipment. Band pass filters with selected characteristics are applied to suppress transient disturbances and increase the chance to detect PD during the impulse. PD signals are separated from transient disturbances during data post processing and by means of pulse polarity analysis. The developed system enables the detection of so-called main and reverse discharges respectively occurring during the rise and tail time of the superimposed impulse. The measurement results obtained show the effectiveness of the presented PD measuring system for investigating the effects of voltage transients on a HV cable system in laboratory conditions.", "title": "Measuring method for partial discharges in a high voltage cable system subjected to impulse and superimposed voltage under laboratory conditions"}, "S0888613X15000559": {"highlights": ["A measurement for the degree of responsibility of each formula of a knowledge base for the inconsistency in that base.", "A causality-based explanation of the measurement.", "The logical properties of the measurement.", "The complexity results for the measurement."], "abstract": "It is desirable to identify the degree of responsibility of each part of a knowledge base for the inconsistency of that base to make some necessary trade-off decisions on restoring the consistency of that base. In this paper, we propose a measurement for the degree of responsibility of each formula in a knowledge base for the inconsistency of that base. This measurement is given in terms of minimal inconsistent subsets of a knowledge base. Moreover, it can be well explained in the context of causality and responsibility presented by Chockler and Halpern [1].", "title": "Responsibility for inconsistency"}, "S0950705116302799": {"highlights": ["A descriptor combining LBP, LGBP and LBPV is proposed for feature extraction.", "Moth-firefly optimization is proposed for feature selection.", "It mitigates premature convergence of FA and MFO algorithms.", "Simulated Annealing is also used to further improve the most promising solution.", "It outperforms other optimization and facial expression recognition methods."], "abstract": "In this research, we propose a facial expression recognition system with a variant of evolutionary firefly algorithm for feature optimization. First of all, a modified Local Binary Pattern descriptor is proposed to produce an initial discriminative face representation. A variant of the firefly algorithm is proposed to perform feature optimization. The proposed evolutionary firefly algorithm exploits the spiral search behaviour of moths and attractiveness search actions of fireflies to mitigate premature convergence of the Levy-flight firefly algorithm (LFA) and the moth-flame optimization (MFO) algorithm. Specifically, it employs the logarithmic spiral search capability of the moths to increase local exploitation of the fireflies, whereas in comparison with the flames in MFO, the fireflies not only represent the best solutions identified by the moths but also act as the search agents guided by the attractiveness function to increase global exploration. Simulated Annealing embedded with Levy flights is also used to increase exploitation of the most promising solution. Diverse single and ensemble classifiers are implemented for the recognition of seven expressions. Evaluated with frontal-view images extracted from CK+, JAFFE, and MMI, and 45-degree multi-view and 90-degree side-view images from BU-3DFE and MMI, respectively, our system achieves a superior performance, and outperforms other state-of-the-art feature optimization methods and related facial expression recognition models by a significant margin.", "title": "Intelligent facial emotion recognition using moth-firefly optimization"}, "S0888613X13002922": {"highlights": ["We propose a fuzzy validity\u2013probability decision maker based on extended fuzzy logic (FLe).", "The system is formulated in terms of the proposed possibility\u2013probability\u2013validity distribution (PPVD).", "The approach is applied to a real-world setting of actual judicial cases.", "To examine the proposed approach, we compare the results with the decisions of human judges.", "The approach outperforms those of fuzzy probabilistic, FLe, fuzzy, and neural systems."], "abstract": "Since the Age of Enlightenment, most philosophers have associated reasoning with the rules of probability and logic. This association has been enhanced over the years and now incorporates the theory of fuzzy logic as a complement to the probability theory, leading to the concept of fuzzy probability. Our insight, here, is integrating the concept of validity into the notion of fuzzy probability within an extended fuzzy logic (FLe) framework keeping with the notion of collective intelligence. In this regard, we propose a novel framework of possibility\u2013probability\u2013validity distribution (PPVD). The proposed distribution is applied to a real world setting of actual judicial cases to examine the role of validity measures in automated judicial decision-making within a fuzzy probabilistic framework. We compute valid fuzzy probability of conviction and acquittal based on different factors. This determines a possible overall hypothesis for the decision of a case, which is valid only to a degree. Validity is computed by aggregating validities of all the involved factors that are obtained from a factor vocabulary based on the empirical data. We then map the combined validity based on the Jaccard similarity measure into linguistic forms, so that a human can understand the results. Then PPVDs that are obtained based on the relevant factors in the given case yield the final valid fuzzy probabilities for conviction and acquittal. Finally, the judge has to make a decision; we therefore provide a numerical measure. Our approach supports the proposed hypothesis within the three-dimensional contexts of probability, possibility, and validity to improve the ability to solve problems with incomplete, unreliable, or ambiguous information to deliver a more reliable decision.", "title": "Introducing validity in fuzzy probability for judicial decision-making"}, "S0933365716301749": {"highlights": ["A novel framework enables NN analysis in medical applications involving small datasets.", "An accurate model for trabecular bone strength estimation in severe osteoarthritis is developed.", "Model enables non-invasive patient-specific prediction of hip fracture risk.", "Method of multiple runs mitigates sporadic fluctuations in NN performance due to small data.", "Surrogate data test is used to account for random effects due to small test data."], "abstract": "Motivation\n                  Single-centre studies in medical domain are often characterised by limited samples due to the complexity and high costs of patient data collection. Machine learning methods for regression modelling of small datasets (less than 10 observations per predictor variable) remain scarce. Our work bridges this gap by developing a novel framework for application of artificial neural networks (NNs) for regression tasks involving small medical datasets.\n               \n               \n                  Methods\n                  In order to address the sporadic fluctuations and validation issues that appear in regression NNs trained on small datasets, the method of multiple runs and surrogate data analysis were proposed in this work. The approach was compared to the state-of-the-art ensemble NNs; the effect of dataset size on NN performance was also investigated.\n               \n               \n                  Results\n                  The proposed framework was applied for the prediction of compressive strength (CS) of femoral trabecular bone in patients suffering from severe osteoarthritis. The NN model was able to estimate the CS of osteoarthritic trabecular bone from its structural and biological properties with a standard error of 0.85MPa. When evaluated on independent test samples, the NN achieved accuracy of 98.3%, outperforming an ensemble NN model by 11%. We reproduce this result on CS data of another porous solid (concrete) and demonstrate that the proposed framework allows for an NN modelled with as few as 56 samples to generalise on 300 independent test samples with 86.5% accuracy, which is comparable to the performance of an NN developed with 18 times larger dataset (1030 samples).\n               \n               \n                  Conclusion\n                  The significance of this work is two-fold: the practical application allows for non-destructive prediction of bone fracture risk, while the novel methodology extends beyond the task considered in this study and provides a general framework for application of regression NNs to medical problems characterised by limited dataset sizes.", "title": "Handling limited datasets with neural networks in medical applications: A small-data approach"}, "S0888613X13001618": {"highlights": ["We study the consequences of the distinction between ontic and epistemic sets in statistical reasoning.", "We discuss the differences between three view of random sets.", "we lay bare examples where the different views matter: conditioning, variance and independence", "We show that interval regression may refer to distinct problems.", "We extend the discussion to fuzzy sets and random fuzzy sets."], "abstract": "In information processing tasks, sets may have a conjunctive or a disjunctive reading. In the conjunctive reading, a set represents an object of interest and its elements are subparts of the object, forming a composite description. In the disjunctive reading, a set contains mutually exclusive elements and refers to the representation of incomplete knowledge. It does not model an actual object or quantity, but partial information about an underlying object or a precise quantity. This distinction between what we call ontic vs. epistemic sets remains valid for fuzzy sets, whose membership functions, in the disjunctive reading are possibility distributions, over deterministic or random values. This paper examines the impact of this distinction in statistics. We show its importance because there is a risk of misusing basic notions and tools, such as conditioning, distance between sets, variance, regression, etc. when data are set-valued. We discuss several examples where the ontic and epistemic points of view yield different approaches to these concepts.", "title": "Statistical reasoning with set-valued information: Ontic vs. epistemic views"}, "S0921889015000901": {"highlights": ["A mobile application is developed for classification of braking states.", "The Sparse and Collaborative Representation based Classifications are used.", "The developed signal filtering and classification modules is accurate and robust.", "The application can be used to classify different dynamical maneuvers of mobility devices."], "abstract": "Personal Mobility Robots, such as the Seqway may be the remedy for the transportation related problems in the congested environment, especially for the last and first mile problems of the elderly people. However, the vehicle segmentation issues for the mobility robots, impede the use of these devices on the shared paths. The mobility reports can only be used in the designated areas and private facilities. The traffic regulatory institutions lack robot\u2013society interaction database. In this study, we proposed methods and algorithms which can be employed on a widespread computing device, such as an Android tablet, to gather travel information and rider behavior making use of the motion and position sensors of the tablet PC. The methods we developed, first filter the noisy sensor readings using a complementary filter, then align the body coordinate system of the device to the Segway\u2019s motion coordinate. A couple of state of the art classification methods are integrated to classify the braking states of the Segway. The classification algorithms are not limited to classification of the braking states, but they can be used for other motion related maneuvers on the road surfaces. The detected braking states and the other classified features related to the motion are reflected to the screen of the Android tablet to inform the rider about the riding and motion conditions. The developed Android application also gathers these travel information to build a National database for further statistical analysis of the robot\u2013society interaction.", "title": "A signal pattern recognition approach for mobile devices and its application to braking state classification on robotic mobility devices"}, "S0142061517324523": {"highlights": ["Real-time resiliency framework is used for analysis and sizing of energy storage.", "Flow battery hardware-characterized dynamic data used for real-time simulations.", "Reconfiguration algorithms as advanced operation functionality in grids with DERs."], "abstract": "This paper presents a real-time simulation and hardware-based approach for systematic integration of Distributed Energy Resources (DERs) in advanced distribution grids with a special focus on resilience. Advanced distribution grids are considered to be functionally more sophisticated than traditional ones. The desirable advanced functionalities include \u2013 reconfiguration, real-time sensing, DERs, self-healing, etc. Some of these functionalities are currently being realized by microgrids as well. However, it is not feasible to convert each section of a distribution grid into a microgrid, but can be instituted with functionalities by design and controls at relatively lower costs. Interconnection of DERs, including energy storage to improve reliability and resilience is presented in details. Resilience of distribution grids is gaining greater importance and research towards enhancing it utilizing DERs is a key area. A real-time resilience framework with Analytical Hierarchical Processes (AHP) is developed that adapts to changing configurations, DERs, switching operations, grid conditions, etc. to provide an accurate and adoptable composite resilience metric. This framework and the composite resilience metric can play a unique role in operational and design decisions for operating future distribution grids. Advanced functionalities such as scenario-based reconfiguration in distribution grids are considered, with resilience metrics as performance criteria for choosing a preferred combination. Simulations are performed using Digital Real-Time Simulator (DRTS) and characterized response of flow battery validated against actual flow battery hardware is imposed to provide realistic results. Reconfiguration program is interfaced with DRTS for bi-directional real-time communication. Key contributions include enhancement of resilience of distribution grids using energy storage system under dynamic operating conditions.", "title": "Integration of flow battery for resilience enhancement of advanced distribution grids"}, "S1875952116300635": {"highlights": ["We propose a spatially divided stroboscope that has feedback from string instruments.", "We realize the flicker-free projection method to maintain a stable projection.", "It can produce morphing and a distortion effect to the string of a string instrument.", "It also can change the shape of strings to arbitrary two-dimensional shapes."], "abstract": "Visual stimuli in the form of special lighting effects are often used to provide additional entertainment when musicians perform. Many technologies have been developed to synchronize visual and audio effects; for example, a CMOS camera can be used to capture the motions of the strings of string instruments as a visual medium. However, because a CMOS sensor scans video line-by-line in sequence, fast moving objects are distorted during the scanning sequence. This morphing and distortion are known as the rolling-shutter effect, which is considered an artistic photographic technique such as strip photography and slit-scan photography. This effect can only be seen in a camera viewfinder or on a PC screen and is usually not perceived by the naked eye. We aimed to overcome this problem by developing a system to allow the rolling-shutter effect to be observed in real time using spatially divided stroboscopic projection. The system produces a wobbly slow-motion effect by animating the sweep lines. Our system also alters the color and texture of strings using a projection of the color and texture sweep lines. Furthermore, it can also change the shape of strings to arbitrary two-dimensional shapes such as geometric patterns or patterns consisting of characters.", "title": "Wobble Strings: Spatially divided stroboscopic effect for augmenting wobbly motion of string instruments"}, "S1071581916000045": {"highlights": ["Tailored text messaging applied to a connection-making framework.", "\u2018Irrelevant\u2019 text messages appeared to be positively perceived by participants.", "Suggestions\u2019 phrasing did not influence participants\u2019 responses on the suggestions.", "Unexpectedness involves location, memories, familiarity and non-familiarity.", "We propose a connection-making model and framework for design."], "abstract": "Mobile applications have the ability to present information to users that is influenced by their surroundings, activities and interests. Such applications have the potential to influence the likelihood of individuals experiencing \u2018serendipity\u2019, through a combination of information, context, insight and activity. This study reports the deployment of a system that sends push text suggestions to users throughout the day, where the content of those messages is informed by users\u2019 experience and interests. We investigated the responses to and interactions with messages that varied in format and relevance, and which were received at different times throughout the day. Sixteen participants were asked to use a mobile diary application to record their experiences and thoughts regarding information that was received over a period of five consecutive days. Results suggest that participants\u2019 perception of the received suggestions was influenced by the relevance of the suggestion to their interests, but that there were also positive attitudes towards seemingly irrelevant information. Qualitative data indicates that participants, if in an appropriate time and place, are willing to accept and act upon push suggestions as long as the number of suggestions that they receive is not overwhelming. This study contributes towards an understanding of how mobile users make connections with new information, furthering our understanding of how serendipitous connections and insightful thinking could be accommodated using technology.", "title": "Encouraging serendipity in research: Designing technologies to support connection-making"}, "S1071581914001013": {"highlights": ["Fifteen ontology experts are interviewed about their authoring tasks.", "Different building styles may generate tensions.", "The problems that ontology authors encounter are identified.", "The employed strategies inform design recommendations for tools."], "abstract": "The process of authoring ontologies appears to be fragmented across several tools and workarounds, and there exists no well accepted framework for common authoring tasks such as exploring ontologies, comparing versions, debugging, and testing. This lack of an adequate and seamless tool chain potentially hinders the broad uptake of ontologies, especially OWL, as a knowledge representation formalism. We start to address this situation by presenting insights from an interview-based study with 15 ontology experts. We uncover the tensions that may emerge between ontology authors including antagonistic ontology building styles (definition-driven vs. manually crafted hierarchies). We identify the problems reported by the ontology authors and the strategies they employ to solve them. These data are mapped to a set of key design recommendations, which should inform and guide future efforts for improving ontology authoring tool support, thus opening up ontology authoring to a new generation of users. We discuss future research avenues in light of these results.", "title": "Overcoming the pitfalls of ontology authoring: Strategies and implications for tool design"}, "S0957417417305547": {"highlights": ["A new method for detecting trends in time series is proposed.", "Application of the algorithm to fuel leaks detection problem is presented.", "A step-by-step usage example, as well as time and memory complexity is presented.", "The tests have been performed in accordance to the American certification standard.", "The probability of detection equals 93.11% with 0.73% probability of false alarm."], "abstract": "Leaks and spills of hazardous fluids like petroleum endanger the environment, while remediation costs and penalties imposed when petroleum contaminates the ecosystem affect economics heavily. Therefore, it is crucial to detect any possible symptoms of a leak as soon as possible. Most of existing leak detection techniques require specialized equipment to be used, while purely software-based methods rely solely on data analysis and are very desirable since they can be deployed on petrol stations without any changes to the existing infrastructure. Moreover, such techniques can be considered as complementary to the hardware leak detection systems, as they provide additional security level. In this paper we present the TUBE algorithm, which detects fuel leaks from underground storage tanks, using only standard measurements that are normally registered on petrol stations, i.e. the amount of stored, sold, and delivered fuel. The TUBE algorithm is an autonomous solution capable of making decisions independently as well as supporting human-made decisions and thus can be considered as an expert leak detection system. The TUBE algorithm introduces a new data mining technique for trend detection and cleaning data over time series, which can be easily adapted to any other problem domain. A trend detection technique, called tubes, created for the TUBE algorithm is a novel data analysis method that allows to envelop uncertainties and oscillations in data and produce stable trends. Trend interpretation technique described in this paper has been designed especially for fuel leak detection purposes using our industrial experience. This paper includes a step-by-step usage example of the TUBE algorithm and its evaluation according to the United States Environmental Protection Agency requirements for leakage detection systems (the EPA SIR standard). Such an evaluation involves calculating the probability of detection and the probability of false alarm. The TUBE algorithm has obtained 98.84% probability of detection and 0.07% probability of false alarm while rejecting 42.22% of analyzed datasets due to their uncertainty. Rejecting datasets from analysis is compliant with the EPA SIR standard; however, rejection rate higher than 20% is not acceptable. Therefore we have evaluated the two-phase filtering stage of the algorithm in order to find the best combination of filters as means of data cleaning. Moreover, we have discussed the results pointing at the overall data quality problem, since it is the main cause of rejecting some datasets from the analysis. Finally, the TUBE algorithm has obtained 93.11% probability of detection and 0.73% probability of false alarm for the best combination of all parameters with 15.56% rejection rate, which is acceptable by the EPA SIR standard. The value of probability of detection is not fully compliant with the EPA SIR standard where 95% probability of detection with probability of false alarm lower than 5% is required. We have found that the requirements for the aforementioned probabilities have been completely fulfilled for datasets representing manifolded tank systems but not for single tank datasets. Such a situation was unexpected since manifolded tank systems are generally claimed to be more complex for analysis as they are in fact systems of multiple single tanks directly connected. In this paper we have also measured the time and memory complexity of the TUBE algorithm as well as discussed the issues connected to the TUBE algorithm deployment on petrol stations using our industrial experience in the topic.", "title": "The TUBE algorithm: Discovering trends in time series for the early detection of fuel leaks from underground storage tanks"}, "S0921889016304742": {"highlights": ["A highly detailed survey of sound source localization (SSL) used over robotic platforms.", "Classification of SSL techniques and description of the SSL problem.", "Description of the diverse facets of the SSL problem.", "Survey of the evaluation methodologies used to measure SSL performance in robotics.", "Discussion of current SSL challenges and research questions."], "abstract": "Sound source localization (SSL) in a robotic platform has been essential in the overall scheme of robot audition. It allows a robot to locate a sound source by sound alone. It has an important impact on other robot audition modules, such as source separation, and it enriches human\u2013robot interaction by complementing the robot\u2019s perceptual capabilities. The main objective of this review is to thoroughly map the current state of the SSL field for the reader and provide a starting point to SSL in robotics. To this effect, we present: the evolution and historical context of SSL in robotics; an extensive review and classification of SSL techniques and popular tracking methodologies; different facets of SSL as well as its state-of-the-art; evaluation methodologies used for SSL; and a set of challenges and research motivations.", "title": "Localization of sound sources in robotics: A review"}, "S1319157819304641": {"highlights": ["A Hadoop based distributed detection framework called E-Had to detect DDoS attacks is proposed.", "E-Had distribute computational and memory overheads to multiple mappers and reducers.", "E-Had is robust as it can continue to work in case some of the mappers do not respond in time.", "E-Had is implemented using HA-DDoS testbed consisting of 30 real systems.", "E-Had has been validated using different attack scenarios of CAIDA and DDoSTB datasets."], "abstract": "During the past few years, the traffic volume of legitimate traffic and attack traffic has increased manifolds up to Terabytes per second (Tbps). Because of the processing of such a huge traffic volume, it has become implausible to detect high rate attacks in time using conventional DDoS defense architectures. At present, the majority of the DDoS defense systems are deployed predominantly at the victim-end domain But these victim-end defense systems themselves are vulnerable to HR-DDoS attacks as the mammoth volume of attack traffic is generated by such type of attacks. The insufficient computational resources further make the problem more crucial at the victim-end. This paper proposed a distributed and collaborative architecture called E-Had that is capable of efficiently processing a large amount of data by distributing it among a number of mappers and reducers in a Hadoop based cluster. The proposed E-Had system has been comprehensively validated using various publicly available benchmarked datasets and real datasets generated in HA-DDoS testbed in terms of various detection system evaluation metrics. The experimental results clearly show that the proposed detection system is capable of early detection of different scenarios of DDoS attacks along with differentiating them from flash crowds.", "title": "E-Had: A distributed and collaborative detection framework for early detection of DDoS attacks"}, "S0142061519321866": {"highlights": ["PD signals can be detected by pick-up coils installed in the GIS compartments.", "Magnetic detection of PD signals can achieve high sensitivity.", "Calibration to pC is feasible in GIS although strongly dependent on the signal amplitude."], "abstract": "This paper presents a magnetic loop antenna for partial discharge (PD) measurements on gas insulated systems (GIS). The antenna is based on a single shielded loop inserted in the dielectric window of a GIS that measures the PD currents propagating in TEM mode. The paper describes the relevant parameters of the antenna and the antenna performance in combination with a transimpedance amplifier. A calibration method for charge estimation is presented along with laboratory experiments with free moving particle, surface and corona discharges in SF6 test cells. The results show the suitability of the magnetic antenna for PD detection and the charge evaluation performance. Under laboratory conditions, the antenna sensitivity is in the order of 1 pC at a few meters from the PD source.", "title": "A magnetic loop antenna for partial discharge measurements on GIS"}, "S095741741830441X": {"highlights": ["Recommender system resistant to the cold-start problem is proposed.", "System builds a model of preferences from transactions performed by a population.", "Evaluated on transactional dataset from a real world dietary intake recall system.", "Applications to recommender and ranking tasks are demonstrated."], "abstract": "Recommender systems based on methods such as collaborative and content-based filtering rely on extensive user profiles and item descriptors as well as on an extensive history of user preferences. Such methods face a number of challenges; including the cold-start problem in systems characterized by irregular usage, privacy concerns, and contexts where the range of indicators representing user interests is limited. We describe a recommender algorithm that builds a model of collective preferences independently of personal user interests and does not require a complex system of ratings. The performance of the algorithm is analyzed on a large transactional data set generated by a real-world dietary intake recall system.", "title": "Recommender system based on pairwise association rules"}, "S0921889016304985": {"highlights": ["This paper proposes an extension of stochastic model connecting motions and sentences to objects to be manipulated.", "The model generates words from categories of motions and objects.", "These words are arranged in order based on transition probabilities extracted from sentence datasets."], "abstract": "This paper presents a novel approach to learning of relations among motions, objects, and language, and to generating sentences that describe human actions. Our approach categorizes human motions and the objects acted on those motions, and subsequently integrates the motion categories and object categories with their descriptive sentences. The integration consists of two steps. The first step stochastically learns the relations among the motions, objects, and words in the sentences. The second step stochastically learns the order of words in the sentences as the sentence structures. The model derived in the first step is referred to as \u201caction language\u201d model and that derived in the second step as \u201cnatural language\u201d model. This framework for integrating an action language model with a natural language model can be applied to generating descriptive sentences from human actions, where each action is recognized as a pair containing a motion category and an object category, the words relevant to the action are generated via the contained motion and object categories, and the words to be arranged result in a descriptive sentence. More theoretically, our approach searches for multiple words likely to be generated from the motion and object categories by using the action language model; and subsequently searches for a sequence of these words that is likely to be generated from the obtained words, using the natural language model. We tested our proposed approach for sentence generation by applying it to human action data captured by an RGB-D sensor, and demonstrated its validity.", "title": "Generation of action description from classification of motion and object"}, "S1875952117301350": {"highlights": ["A social network analysis of a 3.5 million player network from Destiny.", "The first large-scale study of social networks in hybrid online games/shooters.", "Players with stronger social relationships have a higher in-game performance and tend to play longer and more often.", "Players being member of a clan have also a higher in-game performance."], "abstract": "Destiny is a hybrid online shooter sharing features with Massively Multi-Player Online Games and first-person shooters and is the to date the most expensive digital game produced. It has attracted millions of players to compete or collaborate within a persistent online environment. In multiplayer online games, the interaction between the players and the social community that forms in persistent games forms a crucial element in retaining and entertaining players. Social networks in games have thus been a focus of research, but the relationships between player behavior, performance, engagement and the networks forming as a result of interactions, are not well understood. In this paper, a large-scale study of social networks in hybrid online games/shooters is presented. In a network of over 3 million players, the connections formed via direct competitive play are explored and analyzed to answer five main research question focusing on the patterns of players who play with the same people and those who play with random groups, and how differences in this behavior influence performance and engagement metrics. Results show that players with stronger social relationships have a higher performance based on win/loss ratio and kill/death ratio, as well as a tendency to play more and longer.", "title": "Analyzing player networks in Destiny"}, "S0888613X15001620": {"highlights": ["Reproduction selects elite individuals and realizes information transmission.", "Chemotaxis and elimination-and-dispersal maintain a balance between exploitation and exploration.", "Four operators serve as candidate directions for each bacterium to select."], "abstract": "Algorithms inspired by swarm intelligence have been used for many optimization problems and their effectiveness has been proven in many fields. We propose a new swarm intelligence algorithm for structural learning of Bayesian networks, BFO-B, based on bacterial foraging optimization. In the BFO-B algorithm, each bacterium corresponds to a candidate solution that represents a Bayesian network structure, and the algorithm operates under three principal mechanisms: chemotaxis, reproduction, and elimination and dispersal. The chemotaxis mechanism uses four operators to randomly and greedily optimize each solution in a bacterial population, then the reproduction mechanism simulates survival of the fittest to exploit superior solutions and speed convergence of the optimization. Finally, an elimination and dispersal mechanism controls the exploration processes and jumps out of a local optima with a certain probability. We tested the individual contributions of four algorithm operators and compared with two state of the art swarm intelligence based algorithms and seven other well-known algorithms on many benchmark networks. The experimental results verify that the proposed BFO-B algorithm is a viable alternative to learn the structures of Bayesian networks, and is also highly competitive compared to state of the art algorithms.", "title": "Structural learning of Bayesian networks by bacterial foraging optimization"}, "S0957417416301786": {"highlights": ["A new methodology for predicting micrometeorological data is proposed.", "Our proposed method involves a novel combination of SVR and ensemble learning.", "Weak learners built from efficient extracted data is aggregated dynamically.", "Large-scale micrometeorological data to compare other methods is used.", "The best prediction performance and the lowest time complexity are achieved."], "abstract": "Sensor network technology is becoming more widespread and sophisticated, and devices with many sensors, such as smartphones and sensor nodes, have been used extensively. Since these devices have more easily accumulated various kinds of micrometeorological data, such as temperature, humidity, and wind speed, an enormous amount of micrometeorological data has been accumulated. In recent years, it has been expected that such an enormous amount of data, called big data, will produce novel knowledge and value. Accordingly, many current applications have used data mining technology or machine learning to exploit big data. However, micrometeorological data has a complicated correlation among different features, and its characteristics change variously with time. Therefore, it is difficult to predict micrometeorological data accurately with low computational complexity even if state-of-the-art machine learning algorithms are used. In this paper, we propose a new methodology for predicting micrometeorological data, sliding window-based support vector regression (SW-SVR) that involves a novel combination of support vector regression (SVR) and ensemble learning. To represent complicated micrometeorological data easily, SW-SVR builds several SVRs specialized for each representative data group in various natural environments, such as different seasons and climates, and changes weights to aggregate the SVRs dynamically depending on the characteristics of test data. In our experiment, we predicted the temperature after 1h and 6 h by using large-scale micrometeorological data in Tokyo. As a result, regardless of testing periods, training periods, and prediction horizons, the prediction performance of SW-SVR was always greater than or equal to other general methods such as SVR, random forest, and gradient boosting. At the same time, SW-SVR reduced the building time remarkably compared with those of complicated models that have high prediction performance.", "title": "Sliding window-based support vector regression for predicting micrometeorological data"}, "S2589721719300194": {"highlights": ["Developed a tomato defect detector model based on LAB color space", "Extracted color, texture, and shape features as the image feature variables.", "Develop different classifiers to grade tomatoes into different grading categories", "The RBF-SVM outperformed all the explored models in tomato grading categories"], "abstract": "With large-scale production and the need for high-quality tomatoes to meet consumer and market standards criteria, have led to the need for an inline, accurate, reliable grading system during the post-harvest process. This study introduced a tomato grading machine vision system based on RGB images. The proposed system performed calyx and stalk scar detection at an average accuracy of 0.9515 for both defected and healthy tomatoes by histogram thresholding based on the mean g-r value of these regions of interest. Defected regions were detected by an RBF-SVM classifier using the LAB color-space pixel values. The model achieved an overall accuracy of 0.989 upon validation. Four grading categories recognition models were developed based on color and texture features. The RBF-SVM outperformed all the explored models with the highest accuracy of 0.9709 for healthy and defected category. However, the grading accuracy decreased as the number of grading categories increased. A combination of color and texture features achieved the highest accuracy in all the grading categories in image features evaluation. This proposed system can be used as an inline tomato sorting tool to ensure that quality standards are adhered to and maintained.", "title": "A computer vision system for defect discrimination and grading in tomatoes using machine learning and image processing"}, "S0957417416302561": {"highlights": ["Multiple dynamic factors can significantly degrade the accuracy of EMG pattern recognition.", "The impact of many of these factors has been studied in isolation.", "We investigated the combined effect of forearm orientation and muscle contraction levels.", "Twelve intact-limbed and one bilateral trans-radial amputee participated in the experiment.", "Features that quantify the angular similarity can mitigate the problem."], "abstract": "The performance of intelligent electromyogram (EMG)-driven prostheses, functioning as artificial alternatives to missing limbs, is influenced by several dynamic factors including: electrode position shift, varying muscle contraction level, forearm orientation, and limb position. The impact of these factors on EMG pattern recognition has been previously studied in isolation, with the combined effect of these factors being understudied. However, it is likely that a combination of these factors influences the accuracy. We investigated the combined effect of two dynamic factors, namely, forearm orientation and muscle contraction levels, on the generalizability of the EMG pattern recognition. A number of recent time- and frequency-domain EMG features were utilized to study the EMG classification accuracy. Twelve intact-limbed and one bilateral transradial (below-elbow) amputee subject were recruited. They performed six classes of wrist and hand movements at three muscular contraction levels with three forearm orientations (nine conditions). Results indicate that a classifier trained by features that quantify the angle, rather than amplitude, of the muscle activation patterns perform better than other feature sets across different contraction levels and forearm orientations. In addition, a classifier trained with the EMG signals collected at multiple forearm orientations with medium muscular contractions can generalize well and achieve classification accuracies of up to 91%. Furthermore, inclusion of an accelerometer to monitor wrist movement further improved the EMG classification accuracy. The results indicate that the proposed methodology has the potential to improve robustness of myoelectric pattern recognition.", "title": "Combined influence of forearm orientation and muscular contraction on EMG pattern recognition"}, "S1071581916301033": {"highlights": ["Visual feedback leads to more efficient and economical interactions.", "Visual feedback has a negative effect on accuracy.", "All-female pairs compensate for the lack of visual cues through rich verbal means.", "No actual performance difference, but lower perceived performance among females.", "Females use conservative strategies, while males engage in explorative behaviour."], "abstract": "The effects of gender in human communication and human-computer interaction are well-known, yet little is understood about how it influences performance in the complex, collaborative tasks in computer-mediated settings \u2013 referred to as Computer-Supported Collaborative Work (CSCW) \u2013 that are increasingly fundamental to the way in which people work. In such tasks, visual feedback about objects and events is particularly valuable because it facilitates joint reference and attention, and enables the monitoring of people's actions and task progress. As such, software to support CSCW frequently provides shared visual workspace. While numerous studies describe and explain the impact of visual feedback in CSCW, research has not considered whether there are differences in how females and males use it, are aided by it, or are affected by its absence. To address these knowledge gaps, this study explores the effect of gender \u2013 and its interactions within pairs \u2013 in CSCW, with and without visual feedback. An experimental study is reported in which mixed-gender and same-gender pairs communicate to complete a collaborative navigation task, with one of the participants being under the impression that s/he is interacting with a robot (to avoid gender-related social preconceptions). The study analyses performance, perceptions and communication strategies. As predicted, there was a significant benefit associated with visual feedback in terms of language economy and efficiency. However, it was also found that visual feedback may be disruptive to task performance, because it relaxes the users\u2019 precision criteria and inflates their assumptions of shared perspective. While no actual performance difference was found between males and females in the navigation task, females rated their own performance less positively than did males. In terms of communication strategies, males had a strong tendency to introduce novel vocabulary when communication problems occurred, while females exhibited more conservative behaviour. When visual feedback was removed, females adapted their strategies drastically and effectively, increasing the quality and specificity of the verbal interaction, repeating and re-using vocabulary, while the behaviour of males remained consistent. These results are used to produce design recommendations for CSCW systems that will suit users of both genders and enable effective collaboration.", "title": "The influence of visual feedback and gender dynamics on performance, perception and communication strategies in CSCW"}, "S0957417413009901": {"highlights": ["High-speed imaging analysis with image processing algorithms.", "Intelligent system replaces aerodynamic expert in identifying shock waves.", "Decision-making algorithm automatically identifies flow patterns.", "Vibrations, poor illumination and optical set-up corrected by fuzzy logic.", "Low quality aerodynamic visualisations transformed into a precise data."], "abstract": "A digital image processing algorithm was developed to identify flow patterns in high speed imaging. This numerical tool allows to quantify the fluid dynamic features in compressible flows of relevance in aerospace and space related applications. This technique was demonstrated in a harsh environment with poor image quality and illumination fluctuations. This original pattern recognition tool is based on image binarization and object identification. The geometrical properties of the detected elements are obtained by measuring the characteristics of each object in the binary image. In case of multiple shock waves or shock bifurcations, a \u201cdecision-making\u201d algorithm chooses the best shock-wave path, based on the original image intensity and local pattern orientation. The algorithm was successfully used for validation on numerical Schlieren images, where the shock-wave fluctuation was triggered by vortex shedding. The applicability of the algorithm was finally evaluated in two Schlieren imaging studies: at the trailing edge of supersonic airfoils and for hypersonic research. The program correctly identified the fuzzy flow features present in all applications.", "title": "A decision-making algorithm for automatic flow pattern identification in high-speed imaging"}, "S0933365716000051": {"highlights": ["Eight automatic text summarisation methods are described and tested.", "Word space models of distributional semantics are used in five of the presented methods.", "A composition based summarisation method outperforms the other considered methods.", "The utilised automatic evaluation approach is shown to correlate with manual evaluation."], "abstract": "Objective\n                  A major source of information available in electronic health record (EHR) systems are the clinical free text notes documenting patient care. Managing this information is time-consuming for clinicians. Automatic text summarisation could assist clinicians in obtaining an overview of the free text information in ongoing care episodes, as well as in writing final discharge summaries. We present a study of automated text summarisation of clinical notes. It looks to identify which methods are best suited for this task and whether it is possible to automatically evaluate the quality differences of summaries produced by different methods in an efficient and reliable way.\n               \n               \n                  Methods and materials\n                  The study is based on material consisting of 66,884 care episodes from EHRs of heart patients admitted to a university hospital in Finland between 2005 and 2009. We present novel extractive text summarisation methods for summarising the free text content of care episodes. Most of these methods rely on word space models constructed using distributional semantic modelling. The summarisation effectiveness is evaluated using an experimental automatic evaluation approach incorporating well-known ROUGE measures. We also developed a manual evaluation scheme to perform a meta-evaluation on the ROUGE measures to see if they reflect the opinions of health care professionals.\n               \n               \n                  Results\n                  The agreement between the human evaluators is good (ICC=0.74, p\n                     <0.001), demonstrating the stability of the proposed manual evaluation method. Furthermore, the correlation between the manual and automated evaluations are high (> 0.90 Spearman's rho). Three of the presented summarisation methods (\u2018Composite\u2019, \u2018Case-Based\u2019 and \u2018Translate\u2019) significantly outperform the other methods for all ROUGE measures (p\n                     <0.05, Wilcoxon signed-rank test and Bonferroni correction).\n               \n               \n                  Conclusion\n                  The results indicate the feasibility of the automated summarisation of care episodes. Moreover, the high correlation between manual and automated evaluations suggests that the less labour-intensive automated evaluations can be used as a proxy for human evaluations when developing summarisation methods. This is of significant practical value for summarisation method development, because manual evaluation cannot be afforded for every variation of the summarisation methods. Instead, one can resort to automatic evaluation during the method development process.", "title": "Comparison of automatic summarisation methods for clinical free text notes"}, "S0957417419301800": {"highlights": ["A one-step procedure of pruning and decision tree selection is provided.", "We define a new way to represent the tree structure by a dendrogram-like output.", "Our approach can be used to build up both classification and regression trees.", "We show the performance of the proposed approach using real world data sets."], "abstract": "The aim of this study is to provide visual pruning and decision tree selection for classification and regression trees. Specifically, we introduce an unedited tree graph to be made informative for recursive tree data partitioning. A decision tree is visually selected through a dendrogram-like procedure or through automatic tree-size selection. Our proposal is a one-step procedure whereby the most predictive paths are visualized. This method appears to be useful in all real world cases where tree-path interpretation is crucial. Experimental evaluations using real world data sets are presented. The performance was very similar to Classification and Regression Trees (CART) benchmarking methodology, showing that our method is a valid alternative to the well-known method of cost-complexity pruning.", "title": "Informative trees by visual pruning"}, "S0957417417304165": {"highlights": ["We calculate the means of different pixel classes from slope difference distribution.", "The image is segmented by clustering the pixels to its nearest mean.", "The segmentation is further refined by minimizing the energy of its Gibbs distribution.", "The boundary of the refined segmentation is deformed to the nearest detected canny edges."], "abstract": "Image segmentation plays a fundamental role in many computer vision applications. It is challenging because of the vast variety of images involved and the diverse segmentation requirements in different applications. As a result, it remains an open problem after so many years of study by researchers all over the world. In this paper, we propose to segment the image by combing its global and local properties. The global properties of the image are characterized by the mean values of different pixel classes and the continuous boundary of the object or region. The local properties are characterized by the interactions of neighboring pixels and the image edge. The proposed approach consists of four basic parts corresponding to the global or local property of the image respectively: (1) The slope difference distribution that is used to compute the global mean values of different pixel classes; (2) Energy minimization to remove inhomogeneity based on Gibbs distribution that complies with local interactions of neighboring pixels; (3) The Canny operator that is used to detect the local edge of the object or the region; (4) The polynomial spline that is used to smooth the boundary of the object or the region. These four basic parts are applied one by one and each of them is indispensable for the achieved high accuracy. A large variety of images are used to validate the proposed approach and the results are favorable.", "title": "Image segmentation by combining the global and local properties"}, "S0921889017307492": {"highlights": ["We provide a haptic zero shot learning algorithm for object recognition.", "It enables object recognition of objects experienced/touched for the first time.", "We develop and test our algorithm on an open source haptic database.", "We implement it for haptic recognition of daily-life objects by our robot hand.", "Our algorithm enabled our robot to recognize eight out of ten novel objects."], "abstract": "Object recognition is essential to enable robots to interact with their environment. Robots should be capable, on one hand of recognizing previously experienced objects, and on the other, of using the experienced objects for learning novel objects, i.e. objects for which training data are not available. Recognition of such novel objects can be achieved with Zero-Shot Learning (ZSL). In this work, we show the potential of ZSL for haptic recognition. First, we design a zero-shot haptic recognition algorithm and, using the extensive PHAC-2 database (Chu et\u00a0al., 2015) as well as our own, we adapt, analyze and optimize the ZSL for the challenges and constraints characteristic of haptic recognition. Finally, we apply the optimized algorithm for haptic recognition of daily-life objects using an anthropomorphic robot hand. Our algorithm enables the robot to recognize eight of the ten novel objects handed to it.", "title": "Haptic Zero-Shot Learning: Recognition of objects never touched before"}, "S0888613X14000243": {"highlights": ["We introduce a new neuro-fuzzy inference engine for modeling MIMO systems.", "The method integrates TSK fuzzy rule-based system, ANFIS and APCA.", "The performance are better than a conventional application of the ANFIS algorithm."], "abstract": "This paper introduces a novel neuro-fuzzy approach for learning and modeling so-called Multi-Input Multi-Output Coupling (MIMO) systems, i.e., systems where the output variables may depend upon all system's input variables. This strong coupling makes the MIMO systems behavior highly oscillatory in time and, as a consequence, it makes these systems not particularly suitable to be learned and represented by using conventional approaches. In order to address this issue, our proposal presents an adaptive supervised learning algorithm capable of forming a suitable collection of Timed Automata based Fuzzy Systems that model the dynamic behavior of a given MIMO system. The adaptive learning is accomplished by taking advantage of the theories coming from the area of times series analysis (such as the Adaptive Piecewise Constant Approximation method) with a well-known neuro-fuzzy framework of the Adaptive Neuro Fuzzy Inference System (ANFIS). In experiments, where our proposal has been tested on the Fuzz-IEEE 2011 Fuzzy Competition dataset, the proposed supervised learning algorithm significantly reduces the output error measure and achieves better performance than the one provided by a conventional application of the ANFIS algorithm.", "title": "Efficient modeling of MIMO systems through Timed Automata based Neuro-Fuzzy Inference Engine"}, "S0888613X16302092": {"highlights": ["Novel algorithmic and hardware techniques for fast SSM inference are proposed.", "New algorithm extends applicability of particle MCMC to multi-modal posteriors.", "FPGA architectures exploit particle and chain parallelism to accelerate sampling.", "42x speedup vs. state-of-the-art CPU/GPU samplers is achieved for large problems."], "abstract": "Particle Markov Chain Monte Carlo (pMCMC) is a stochastic algorithm designed to generate samples from a probability distribution, when the density of the distribution does not admit a closed form expression. pMCMC is most commonly used to sample from the Bayesian posterior distribution in State-Space Models (SSMs), a class of probabilistic models used in numerous scientific applications. Nevertheless, this task is prohibitive when dealing with complex SSMs with massive data, due to the high computational cost of pMCMC and its poor performance when the posterior exhibits multi-modality. This paper aims to address both issues by: 1) Proposing a novel pMCMC algorithm (denoted ppMCMC), which uses multiple Markov chains (instead of the one used by pMCMC) to improve sampling efficiency for multi-modal posteriors, 2) Introducing custom, parallel hardware architectures, which are tailored for pMCMC and ppMCMC. The architectures are implemented on Field Programmable Gate Arrays (FPGAs), a type of hardware accelerator with massive parallelization capabilities. The new algorithm and the two FPGA architectures are evaluated using a large-scale case study from genetics. Results indicate that ppMCMC achieves 1.96x higher sampling efficiency than pMCMC when using sequential CPU implementations. The FPGA architecture of pMCMC is 12.1x and 10.1x faster than state-of-the-art, parallel CPU and GPU implementations of pMCMC and up to 53x more energy efficient; the FPGA architecture of ppMCMC increases these speedups to 34.9x and 41.8x respectively and is 173x more power efficient, bringing previously intractable SSM-based data analyses within reach.", "title": "Particle MCMC algorithms and architectures for accelerating inference in state-space models"}, "S0921889014001821": {"highlights": ["A flexible and stretchable durable fabric-based tactile sensor capable of capturing typical human interaction forces was developed.", "We present elaborate measurement results of the sensor.", "A process of creating multiple sensor areas in a single fabric patch was developed.", "The measures against performance degradation due to moisture are presented.", "Using the developed technology, a tactile dataglove with 54 pressure sensitive regions was built."], "abstract": "We introduce a novel, fabric-based, flexible, and stretchable tactile sensor, which is capable of seamlessly covering natural shapes. As humans and robots have curved body parts that move with respect to each other, the practical usage of traditional rigid tactile sensor arrays is limited. Rather, a flexible tactile skin is required. Our design allows for several tactile cells to be embedded in a single sensor patch. It can have an arbitrary perimeter and can cover free-form surfaces. In this article we discuss the construction of the sensor and evaluate its performance. Our flexible tactile sensor remains operational on top of soft padding such as a gel cushion, enabling the construction of a human-like soft tactile skin. The sensor allows pressure measurements to be read from a subtle less than 1\u00a0kPa up to high pressures of more than 500\u00a0kPa, which easily covers the common range for everyday human manual interactions. Due to a layered construction, the sensor is very robust and can withstand normal forces multiple magnitudes higher than what could be achieved by a human without sustaining damage.\n                  As an exciting application for the sensor, we describe the construction of a wearable tactile dataglove with 54 tactile cells and embedded data acquisition electronics. We also discuss the necessary implementation details to maintain long term sensor performance in the presence of moisture.", "title": "Flexible and stretchable fabric-based tactile sensor"}}