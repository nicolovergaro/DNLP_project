{"S0921889015003000": {"highlights": ["An autonomous system should act ethically, but what if it has no all-ethical choice?", "We model how to rank states violating multiple instances of ethical principles.", "We enable an autonomous system to use this ethic rank to rank its available plans.", "We guarantee that when a plan is chosen, it is the most ethical plan available."], "abstract": "Autonomous systems such as unmanned vehicles are beginning to operate within society. All participants in society are required to follow specific regulations and laws. An autonomous system cannot be an exception. Inevitably an autonomous system will find itself in a situation in which it needs to not only choose to obey a rule or not, but also make a complex ethical decision. However, there exists no obvious way to implement the human understanding of ethical behaviour in computers. Even if we enable autonomous systems to distinguish between more and less ethical alternatives, how can we be sure that they would choose right? We consider autonomous systems with a hybrid architecture in which the highest level of reasoning is executed by a rational (BDI) agent. For such a system, formal verification has been used successfully to prove that specific rules of behaviour are observed when making decisions. We propose a theoretical framework for ethical plan selection that can be formally verified. We implement a rational agent that incorporates a given ethical policy in its plan selection and show that we can formally verify that the agent chooses to execute, to the best of its beliefs, the most ethical available plan.", "title": "Formal verification of ethical choices in autonomous systems"}, "S0952197619301253": {"highlights": ["A bilevel model for simultaneously determining TODs and traffic signal optimization.", "Memetic algorithms based on PSO, SA, GA and Nelder Mead are proposed for bilevel model.", "A set of computational tests on synthetic and real data sets.", "A novel oriented-problem approach to determine optimal number of TODs."], "abstract": "Graphical abstract", "title": "A bilevel approach to enhance prefixed traffic signal optimization"}, "S0925231219301961": {"highlights": ["Different types of uncertainties for deep-learning based medical image segmentation were analysed.", "We propose a general aleatoric uncertainty estimation method based on test-time augmentation.", "A theoretical formulation of test-time augmentation was proposed.", "The proposed method was validated with 2D fetal brain segmentation and 3D brain tumor segmentation tasks."], "abstract": "Despite the state-of-the-art performance for medical image segmentation, deep convolutional neural networks (CNNs) have rarely provided uncertainty estimations regarding their segmentation outputs, e.g., model (epistemic) and image-based (aleatoric) uncertainties. In this work, we analyze these different types of uncertainties for CNN-based 2D and 3D medical image segmentation tasks at both pixel level and structure level. We additionally propose a test-time augmentation-based aleatoric uncertainty to analyze the effect of different transformations of the input image on the segmentation output. Test-time augmentation has been previously used to improve segmentation accuracy, yet not been formulated in a consistent mathematical framework. Hence, we also propose a theoretical formulation of test-time augmentation, where a distribution of the prediction is estimated by Monte Carlo simulation with prior distributions of parameters in an image acquisition model that involves image transformations and noise. We compare and combine our proposed aleatoric uncertainty with model uncertainty. Experiments with segmentation of fetal brains and brain tumors from 2D and 3D Magnetic Resonance Images (MRI) showed that 1) the test-time augmentation-based aleatoric uncertainty provides a better uncertainty estimation than calculating the test-time dropout-based model uncertainty alone and helps to reduce overconfident incorrect predictions, and 2) our test-time augmentation outperforms a single-prediction baseline and dropout-based multiple predictions.", "title": "Aleatoric uncertainty estimation with test-time augmentation for medical image segmentation with convolutional neural networks"}, "S0957417414006472": {"highlights": ["A modified WordNet based similarity measure for word sense disambiguation.", "Lexical chains as text representation for ideally cover the theme of texts.", "Extracted core semantics are sufficient to reduce dimensionality of feature set.", "The proposed scheme is able to correctly estimate the true number of clusters.", "The topic labels have good indicator of recognizing and understanding the clusters."], "abstract": "Traditional clustering algorithms do not consider the semantic relationships among words so that cannot accurately represent the meaning of documents. To overcome this problem, introducing semantic information from ontology such as WordNet has been widely used to improve the quality of text clustering. However, there still exist several challenges, such as synonym and polysemy, high dimensionality, extracting core semantics from texts, and assigning appropriate description for the generated clusters. In this paper, we report our attempt towards integrating WordNet with lexical chains to alleviate these problems. The proposed approach exploits ontology hierarchical structure and relations to provide a more accurate assessment of the similarity between terms for word sense disambiguation. Furthermore, we introduce lexical chains to extract a set of semantically related words from texts, which can represent the semantic content of the texts. Although lexical chains have been extensively used in text summarization, their potential impact on text clustering problem has not been fully investigated. Our integrated way can identify the theme of documents based on the disambiguated core features extracted, and in parallel downsize the dimensions of feature space. The experimental results using the proposed framework on reuters-21578 show that clustering performance improves significantly compared to several classical methods.", "title": "A semantic approach for text clustering using WordNet and lexical chains"}, "S0306437915000459": {"highlights": ["Framework of ten compliance monitoring functionalities (CMF) in business processes is defined.", "Related techniques and enabling technologies are discussed.", "Systematic literature review and presentation of real-world business constraints for compliance are extracted from five case studies.", "Systematic comparison with compliance patterns and classification of existing approaches using the framework is presented.", "CMF framework based on two realistic data sets using three different compliance monitoring tools is applied."], "abstract": "In recent years, monitoring the compliance of business processes with relevant regulations, constraints, and rules during runtime has evolved as major concern in literature and practice. Monitoring not only refers to continuously observing possible compliance violations, but also includes the ability to provide fine-grained feedback and to predict possible compliance violations in the future. The body of literature on business process compliance is large and approaches specifically addressing process monitoring are hard to identify. Moreover, proper means for the systematic comparison of these approaches are missing. Hence, it is unclear which approaches are suitable for particular scenarios. The goal of this paper is to define a framework for Compliance Monitoring Functionalities (CMF) that enables the systematic comparison of existing and new approaches for monitoring compliance rules over business processes during runtime. To define the scope of the framework, at first, related areas are identified and discussed. The CMFs are harvested based on a systematic literature review and five selected case studies. The appropriateness of the selection of CMFs is demonstrated in two ways: (a) a systematic comparison with pattern-based compliance approaches and (b) a classification of existing compliance monitoring approaches using the CMFs. Moreover, the application of the CMFs is showcased using three existing tools that are applied to two realistic data sets. Overall, the CMF framework provides powerful means to position existing and future compliance monitoring approaches.", "title": "Compliance monitoring in business processes: Functionalities, application, and tool-support"}, "S1071581916300453": {"highlights": ["We study the learnability of educational authoring tools for preventing teachers' rejection or abandonment.", "We evaluate two interaction paradigms of authoring educational tools: menu-based versus direct-manipulation.", "The interaction paradigm of the authoring tool has an important impact on the tool's learning curve's entry point.", "A consistent interaction metaphor allows teachers creating educational activities smooth and fast."], "abstract": "Few teachers include information and communication technology in the classroom, despite their potential for increasing attention and motivation for students. Educational authoring tools are intended to turn teachers into designers and deliverers of technology-enhanced educational content, and increasing the adoption of these tools is a key element for speeding up this transformation. This paper emphasizes the importance of learnability for preventing rejection or abandonment by of such an authoring tool, and how acceptance is deeply affected by the interaction paradigm and the creation metaphor used in the tool. We present an analysis comparing two design paradigms: the widespread menu-based and choice-guided interaction paradigm versus a consistent metaphor with direct manipulation. The latter was implemented in DEDOS-Editor, a novel authoring tool that allows the creation of diverse educational activities that can be performed on different devices, such as PCs, digital blackboards, tablets, and multitouch surfaces. An experimental study shows the tremendous impact that interface choices have on the tool's learning curve. The results provide the first mapping of the choice of a direct-manipulation interface and its effect on the learning curve's entry point, as well as a consistent interaction metaphor with smoother and fast-growing learning curves. This allows users to complete more tasks and gain more knowledge through experience, in contrast to menu-based interfaces. The initial use of the tool is thus made easier for users with no experience or information about the tool, and the advantages of experience and expertize in facing new challenges are facilitating. This work also highlights the appropriateness of learning curves as a tool for measuring learnability.", "title": "Mind the gap: Impact on learnability of user interface design of authoring tools for teachers"}, "S0957417415003590": {"highlights": ["A Knowledge Acquisition learning algorithm is proposed for troubleshooting in LTE.", "A sensitivity analysis is performed on the proposed algorithm.", "The algorithm is tested with a live network scenario.", "The performance has been compared with a Bayesian Network based algorithm."], "abstract": "The recent developments in cellular networks, along with the increase in services, users and the demand of high quality have raised the Operational Expenditure (OPEX). Self-Organizing Networks (SON) are the solution to reduce these costs. Within SON, self-healing is the functionality that aims to automatically solve problems in the radio access network, at the same time reducing the downtime and the impact on the user experience. Self-healing comprises four main functions: fault detection, root cause analysis, fault compensation and recovery. To perform the root cause analysis (also known as diagnosis), Knowledge-Based Systems (KBS) are commonly used, such as fuzzy logic. In this paper, a novel method for extracting the Knowledge Base for a KBS from solved troubleshooting cases is proposed. This method is based on data mining techniques as opposed to the manual techniques currently used. The data mining problem of extracting knowledge out of LTE troubleshooting information can be considered a Big Data problem. Therefore, the proposed method has been designed so it can be easily scaled up to process a large volume of data with relatively low resources, as opposed to other existing algorithms. Tests show the feasibility and good results obtained by the diagnosis system created by the proposed methodology in LTE networks.", "title": "Data mining for fuzzy diagnosis systems in LTE networks"}, "S0888613X13002867": {"highlights": ["The multi-section inconsistency measure (MSIM) for stratified knowledge bases.", "Two kinds of stances for the multi-section inconsistency measure.", "The preference-based inconsistency measure for stratified knowledge bases.", "The complexity results for these measures."], "abstract": "A number of proposals have been proposed for measuring inconsistency for knowledge bases. However, it is rarely investigated how to incorporate preference information into inconsistency measures. This paper presents two approaches to measuring inconsistency for stratified knowledge bases. The first approach, termed the multi-section inconsistency measure (MSIM for short), provides a framework for characterizing the inconsistency at each stratum of a stratified knowledge base. Two instances of MSIM are defined: the naive MSIM and the stratum-centric MSIM. The second approach, termed the preference-based approach, aims to articulate the inconsistency in a stratified knowledge base from a global perspective. This approach allows us to define measures by taking into account the number of formulas involved in inconsistencies as well as the preference levels of these formulas. A set of desirable properties are introduced for inconsistency measures of stratified knowledge bases and studied with respect to the inconsistency measures introduced in the paper. Computational complexity results for these measures are presented. In addition, a simple but explanatory example is given to illustrate the application of the proposed approaches to requirements engineering.", "title": "Approaches to measuring inconsistency for stratified knowledge bases"}, "S0921889015000834": {"highlights": ["Proposes a layout for a walking free-leg hexapod machine tool.", "Optimisation approach for tripod gait based on selected system parameters.", "Proposes an algorithm for independent walking motion based on stability."], "abstract": "The scope of this paper is to present a novel gait methodology in order to obtain an efficient walking capability for an original walking free-leg hexapod structure (WalkingHex) of tri-radial symmetry. Torque in the upper (actuated) spherical joints and stability margin analyses are obtained based on a constraint-driven gait generator. Therefore, the kinematic information of foot pose and angular orientation of the platform are considered as important variables along with the effect that they can produce in different gait cycles. The torque analysis is studied to determine the motor torque requirements for each step of the gait so that the robotic structure yields a stable and achievable pose. In this way, the analysis of torque permits the selection of an optimal gait based on stability margin criteria. Consequently, a gait generating algorithm is proposed for different types of terrain such as flat, ramp or stepped surfaces.\n               \n            \n\nAngle of slope of terrain\u00a0(rad)\n\nFoot spacing angle\u00a0(rad)\n\nFoot spacing radius\u00a0(m)\n\nFoot \n                           i\n                        \n                     \n\nGravitational Coefficient\u00a09.81\u00a0(ms\u22122)\n\nHexapod rotation\u00a0(rad)\n\nOptimal hexapod rotation\u00a0(rad)\n\nMagnitude of stability margin \n                           i\n                         \u00a0(m)\n\nMaximum torque in system\u00a0(N\u00a0m)\n\nOptimal translation\u00a0(m)\n\nOverall system stability margin\u00a0(m)\n\nPlatform pitch\u00a0(rad)\n\nPlatform translation\u00a0(m)\n\nPrismatic joint \n                           i\n                        \n                     \n\nSet of integers\n\nTorque in upper spherical joint \n                           i\n                         \u00a0(N\u00a0m)\n\nUpper spherical joint \n                           i", "title": "Pre-gait analysis using optimal parameters for a walking machine tool based on a free-leg hexapod structure"}, "S2590188519300162": {"highlights": ["Firefly algorithm with an evolutionary framework for OSELM is the proposed model.", "Stock market data are input to ELM, OSELM and RBPNN prediction models.", "Comparison has made on outcome of statistical and optimized feature reduction method.", "The model is validated over four stock market datasets such as BSE, NSE, S&P and FTSE.", "The model performance is compared with PCA, FA, GA and firefly based prediction model."], "abstract": "Forecasting future trends of the stock market using the historical data is the exigent demand in the field of academia as well as business. This work has explored the feature optimization capacity of firefly with an evolutionary framework considering the biochemical and social aspects of Firefly algorithm, along with the selection procedure of objective value in evolutionary notion. The performance of the proposed model is evaluated using four different stock market datasets, such as BSE Sensex, NSE Sensex, S&P 500 index and FTSE index. The datasets are regenerated using the proper mathematical formulation of the fundamental part belonging to technical analysis, such as technical indicators and statistical measures. The feature reduction through transformation is carried out on the enhanced dataset before employing the experimented dataset to the prediction models such as Extreme Learning Machine (ELM), Online Sequential Extreme Learning Machine (OSELM) and Recurrent Back Propagation Neural Network (RBPNN). For feature reduction, both statistical and optimized based feature reduction strategies are considered, where Principal Component Analysis (PCA) and Factor Analysis (FA) are examined for statistical based feature reduction and Firefly Optimization (FO), Genetic Algorithm (GA) and Firefly algorithm with evolutionary framework are well thought out for optimized feature reduction techniques. An empirical comparison is established among the experimented prediction models considering all the feature reduction techniques for the time horizon of 1 day, 3 days, 5 days, 7 days, 5 days and 30 days in advance, applying on all the datasets used in this study. From the simulation result, it can be clearly figured out that firefly with evolutionary framework optimized feature reduction applying to OSELM prediction model outperformed over the rest experimented models.", "title": "Stock market prediction using Firefly algorithm with evolutionary framework optimized feature reduction for OSELM method"}, "S0888613X1300234X": {"highlights": ["Introduced are concepts of linguistic scales and their quantitative semantic scales.", "Properties of context-dependent semantics are studied.", "4-tuple linguistic representation and 4-tuple semantic linguistic scales are examined.", "A methodology to construct a sound 4-tuple semantic linguistic scale is proposed."], "abstract": "Data semantics plays a fundamental role in computer science, in general, and in computing with words, in particular. The semantics of words arises as a sophisticated problem, since words being actually vague linguistic terms are pieces of information characterized by impreciseness, incompleteness, uncertainty and/or vagueness. The qualitative semantics and the quantitative semantics are two aspects of vague linguistic information, which are closely related. However, the qualitative semantics of linguistic terms, and even the qualitative semantics of the symbolic approaches, seem to be not elaborated on directly in the literature. In this study, we propose an interpretation of the inherent order-based semantics of terms through their qualitative semantics modeled by hedge algebra structures. The quantitative semantics of terms are developed based on the quantification of hedge algebras. With this explicit approach, we propose two concepts of assessment scales to address decision problems: linguistic scales used for representing expert linguistic assessments and semantic linguistic scales based on 4-tuple linguistic representation model, which forms a formalized structure useful for computing with words. An example of a simple multi-criteria decision problem is examined by running a comparative study. We also analyze the main advantages of the proposed approach.", "title": "A construction of sound semantic linguistic scales using 4-tuple representation of term semantics"}, "S0888613X13002910": {"highlights": ["CP decomposition of CPTs of noisy threshold and exactly l-out-of-k functions.", "Symmetric rank of these tensors in the real and complex domains.", "Experiments on subnetworks of the QMR-DT generalized by using noisy-thresholds.", "Superiority of the CP decomposition to the parent divorcing method."], "abstract": "The specification of conditional probability tables (CPTs) is a difficult task in the construction of probabilistic graphical models. Several types of canonical models have been proposed to ease that difficulty. Noisy-threshold models generalize the two most popular canonical models: the noisy-or and the noisy-and. When using the standard inference techniques the inference complexity is exponential with respect to the number of parents of a variable. More efficient inference techniques can be employed for CPTs that take a special form. CPTs can be viewed as tensors. Tensors can be decomposed into linear combinations of rank-one tensors, where a rank-one tensor is an outer product of vectors. Such decomposition is referred to as Canonical Polyadic (CP) or CANDECOMP-PARAFAC (CP) decomposition. The tensor decomposition offers a compact representation of CPTs which can be efficiently utilized in probabilistic inference. In this paper we propose a CP decomposition of tensors corresponding to CPTs of threshold functions, exactly \u2113-out-of-k functions, and their noisy counterparts. We prove results about the symmetric rank of these tensors in the real and complex domains. The proofs are constructive and provide methods for CP decomposition of these tensors. An analytical and experimental comparison with the parent-divorcing method (which also has a polynomial complexity) shows superiority of the CP decomposition-based method. The experiments were performed on subnetworks of the well-known QMRT-DT network generalized by replacing noisy-or by noisy-threshold models.", "title": "Probabilistic inference with noisy-threshold models based on a CP tensor decomposition"}, "S0963868717301798": {"highlights": ["Social media for organizational socialization creates inclusiveness and divisiveness.", "Technology affordances actualized by users have consequences for non-users.", "Five generative mechanisms link social media affordances and socialization."], "abstract": "In response to the challenge of socializing new IT employees, some IT departments are exploring the incorporation of enterprise social media (hereinafter ESM) as an informal organizational socialization tool. Because this is a relatively new phenomenon, little is known about how ESM facilitate employee socialization. In order to contribute to our understanding of how ESM affects employee socialization, this paper invokes a case study to explore how one organization\u2019s implementation of an ESM for its IT new hire program influenced the socialization process and outcomes. To delve deeply into how the ESM influences socialization, we draw upon technology affordance theory to uncover the various first and second-order affordances actualized by different actor groups and the various outcomes resulting from the affordances. We then identify five generative mechanisms \u2013 bureaucracy circumvention, executive perspective, personal development, name recognition, and morale booster \u2013 that explain how the actualization of different strands of affordances by various groups of users produces eight different outcomes. Our results provide insights into the different affordances made possible by ESM in the context of a new hire socialization program and how these affordances have repercussions beyond those experienced by the individuals using the ESM. The results have important implications for new hire socialization and technology affordance research.", "title": "An affordance perspective of enterprise social media and organizational socialization"}, "S2590188519300083": {"highlights": ["We present a new idea for family and non-family photo classification.", "The proposed method explores the strengths of facial and the texture features.", "The texture feature are extracted by a new Fractional entropy based features.", "The proposed method combines geometric and entropy features in a new way.", "The CNN has been explored for final classification."], "abstract": "Due to the power and impact of social media, unsolved practical issues such as human trafficking, kinship recognition, and clustering family photos from large collections have recently received special attention from researchers. In this paper, we present a new idea for family and non-family photo classification. Unlike existing methods that explore face recognition and biometric features, the proposed method explores the strengths of facial geometric features and texture given by a new fractional-entropy approach for classification. The geometric features include spatial and angle information of facial key points, which give spatial and directional coherence. The texture features extract regular patterns in images. The proposed method then combines the above properties in a new way for classifying family and non-family photos with the help of Convolutional Neural Networks (CNNs). Experimental results on our own as well as benchmark datasets show that the proposed approach outperforms the state-of-the-art methods in terms of classification rate.", "title": "A geometric and fractional entropy-based method for family photo classification"}, "S1071581918303471": {"highlights": ["We developed a machine learning classifier that determines ideal interruption points for computer-based tasks.", ">The classifier uses a user model in its\u2019 reasoning computations. This is a novel contribution.", ">The classifier's performance is quite promising at 96% accuracy in several models created.", "The classifier is implemented with an Adaptive Neural-Fuzzy Inference System\u2014a novel contribution.", "This research shed light on reasoning about ideal interruption points for free-form tasks."], "abstract": "Current trends in society and technology make the concept of interruption a central human computer interaction problem. In this work, a novel soft computing implementation for an Interruption Classifier was designed, developed and evaluated that draws from a user model and real-time observations of the user's actions as s/he works on computer-based tasks to determine ideal times to interact with the user. This research is timely as the number of interruptions people experience daily has grown considerably over the last decade. Thus, systems are needed to manage interruptions by reasoning about ideal timings of interactions.\n                  This research shows: (1) the classifier incorporates a user model in its\u2019 reasoning process. Most of the research in this area has focused on task-based contextual information when designing systems that reason about interruptions; (2) the classifier performed at 96% accuracy in experimental test scenarios and significantly outperformed other comparable systems; (3) the classifier is implemented using an advanced machine learning technology\u2014an Adaptive Neural-Fuzzy Inference System\u2014this is unique since all other systems use Bayesian Networks or other machine learning tools; (4) the classifier does not require any direct user involvement\u2014in other systems, users must provide interruption annotations while reviewing video sessions so the system can learn; and (5) a promising direction for reasoning about interruptions for free-form tasks\u2013this is largely an unsolved problem.", "title": "Reasoning about ideal interruptible moments: A soft computing implementation of an interruption classifier in free-form task environments"}, "S1875952116300040": {"highlights": ["We developed a highly engaging interactive game designed for the cinema theatre.", "The game runs with a very low footprint \u2013 a simple browser running on the movie-goer\u2019s smartphone.", "The game offers a socially engaging experience that is scalable\u2013from 2 to 100 movie-goers.", "This research shed lights on designing and developing multiplayer real-time cinema games."], "abstract": "The pre-show experience is a significant part of the movie industry. Moviegoers, on average arrive 24min before when the previews start. Previews have been a part of the movie experience for more than a hundred years and are a culturally significant aspect of the whole experience. Over the last decade, the pre-movie in-theatre experience has grown to a $600 million industry. This growth continues to accelerate. Since 2012, this industry has increased by 150%. Consequently, there is an industry-wide demand for innovation in the pre-movie area. In this paper, we describe Paths, an innovative multiplayer real-time socially engaging game that we designed, developed and evaluated. An iterative refinement application development methodology was used to create the game. The game may be played on any smartphone and group interactions are viewed on the large theatre screen. This paper also reports on the quasi-experimental mixed method study with repeated measures that was conducted to ascertain the effectiveness of this new game. The results show that Paths is very engaging with elements of suspense, pleasant unpredictability and effective team building and crowd-pleasing characteristics.", "title": "Mobile devices at the cinema theatre"}, "S0020025519304864": {"highlights": ["A novel intuitionistic hesitant fuzzy sets based image enhancement scheme is presented for low illuminated dronogram where the hesitant score is used as a new way to measure image uncertainty.", "The proposed method initially separates a dronogram into the foreground/background areas based on a global threshold, and determine the membership functions by intuitionistic hesitant fuzzification approach via hyperbolic operations in membership modification.", "Finally, a highly informative and improved dronogram is obtained by defuzzification.", "Results of application on a drone database indicate the efficacy of the proposed method."], "abstract": "In this paper, we address the hesitant information in enhancement task often caused by differences in image contrast. Enhancement approaches generally use certain filters which generate artifacts or are unable to recover all the objects details in images. Typically, the contrast of an image quantifies a unique ratio between the amounts of black and white through a single pixel. However, contrast is better represented by a group of pixels. We have proposed a novel image enhancement scheme based on intuitionistic hesitant fuzzy sets (IHFSs) for drone images (dronogram) to facilitate better interpretations of target objects. First, a given dronogram is divided into foreground and background areas based on an estimated threshold from which the proposed model measures the amount of black/white intensity levels. Next, we fuzzify both of them and determine the hesitant score indicated by the distance between the two areas for each point in the fuzzy plane. Finally, a hyperbolic operator is adopted for each membership grade to improve the photographic quality leading to enhanced results via defuzzification. The proposed method is tested on a large drone image database. Results demonstrate better contrast enhancement, improved visual quality, and better recognition compared to the state-of-the-art methods.", "title": "Enhancement of dronogram aid to visual interpretation of target objects via intuitionistic fuzzy hesitant sets"}, "S107158191630074X": {"highlights": ["We present a system for reproducible research in sonification for process monitoring.", "We developed an experiment design to analyze effectiveness in monitoring as secondary task.", "We compared continuous sonification to visual-only and auditory alerts.", "Continuous sonification significantly enhances the adequacy of interactions.", "Participants find continuous sonification significantly more helpful and reassuring."], "abstract": "As many users who are charged with process monitoring need to focus mainly on other work while performing monitoring as a secondary task, monitoring systems that purely rely on visual means are often not well suited for this purpose. Sonification, the presentation of data as (non-speech) sound, has proven in several studies that it can help in guiding the user's attention, especially in scenarios where process monitoring is performed in parallel with a different, main task. However, there are several aspects that have not been investigated in this area so far, for example if a continuous soundscape can guide the user's attention better than one that is based on auditory cues. We have developed a system that allows reproducible research to answer such questions. In this system, the participants\u2019 performance both for the main task (simulated by simple arithmetic problems) and for the secondary task (a simulation of a production process) can be measured in a more fine-grained manner than has been the case for existing research in this field. In a within-subject study (n=18), we compared three monitoring conditions \u2013 visual only, visual + auditory alerts and a condition combining the visual mode with continuous sonification of process events based on a forest soundscape. Participants showed significantly higher process monitoring performances in the continuous sonification condition, compared to the other two modes. The performance in the main task was at the same time not significantly affected by the continuous sonification.", "title": "Continuous sonification enhances adequacy of interactions in peripheral process monitoring"}, "S0888613X13002880": {"highlights": ["Definition and properties of qualitative chain graphs (QCGs).", "Key differences with qualitative probabilistic networks (QPNs).", "Modelling and reasoning of qualitative representations of feedback systems.", "Approximate reasoning of qualitative information with 2nd order distributions.", "Application to common diseases of real patient data in general practice."], "abstract": "For many problem domains, such as medicine, chain graphs are more attractive than Bayesian networks as they support representing interactions between variables that have no natural direction. In particular, interactions between variables that result from certain feedback mechanisms can be represented by chain graphs. Using qualitative abstractions of probabilistic interactions is also of interest, as these allow focusing on patterns in the interactions rather than on the numerical detail. Such patterns are often known by experts and sufficient for making decisions. So far, qualitative abstractions of probabilistic interactions have only been developed for Bayesian networks in the form of qualitative probabilistic networks. In this paper, such qualitative abstractions are developed for chain graphs with the practical aim of using qualitative knowledge as constraints on the hyperspace of probability distributions. The usefulness of qualitative chain graphs is explored for modelling and reasoning about the interactions between diseases.", "title": "Qualitative chain graphs and their application"}, "S1071581918300971": {"highlights": ["A semantic speech editing system was evaluated in professional radio production.", "Participants were able to use the system to produce real programmes for broadcast.", "The interface was missing functionality for annotation and collaboration.", "A portable interface would allow users to work where they are most productive.", "Efficient playback is important in maintaining high sound quality."], "abstract": "Radio production involves editing speech-based audio using tools that represent sound using simple waveforms. Semantic speech editing systems allow users to edit audio using an automatically generated transcript, which has the potential to improve the production workflow. To investigate this, we developed a semantic audio editor based on a pilot study. Through a contextual qualitative study of five professional radio producers at the BBC, we examined the existing radio production process and evaluated our semantic editor by using it to create programmes that were later broadcast.\n                  We observed that the participants in our study wrote detailed notes about their recordings and used annotation to mark which parts they wanted to use. They collaborated closely with the presenter of their programme to structure the contents and write narrative elements. Participants reported that they often work away from the office to avoid distractions, and print transcripts so they can work away from screens. They also emphasised that listening is an important part of production, to ensure high sound quality. We found that semantic speech editing with automated speech recognition can be used to improve the radio production workflow, but that annotation, collaboration, portability and listening were not well supported by current semantic speech editing systems. In this paper, we make recommendations on how future semantic speech editing systems can better support the requirements of radio production.", "title": "A Contextual Study of Semantic Speech Editing in Radio Production"}, "S0888613X14001212": {"highlights": ["Two credal classifiers for multivariate time series based on imprecise HMMs.", "Classification is achieved by extending the k-NN approach to interval data.", "Other credal approaches outperformed, compete also with dynamic time warping."], "abstract": "A novel technique to classify time series with imprecise hidden Markov models is presented. The learning of these models is achieved by coupling the EM algorithm with the imprecise Dirichlet model. In the stationarity limit, each model corresponds to an imprecise mixture of Gaussian densities, this reducing the problem to the classification of static, imprecise-probabilistic, information. Two classifiers, one based on the expected value of the mixture, the other on the Bhattacharyya distance between pairs of mixtures, are developed. The computation of the bounds of these descriptors with respect to the imprecise quantification of the parameters is reduced to, respectively, linear and quadratic optimization tasks, and hence efficiently solved. Classification is performed by extending the k-nearest neighbors approach to interval-valued data. The classifiers are credal, meaning that multiple class labels can be returned in the output. Experiments on benchmark datasets for computer vision show that these methods achieve the required robustness whilst outperforming other precise and imprecise methods.", "title": "Robust classification of multivariate time series by imprecise hidden Markov models"}, "S0925231217309864": {"highlights": ["Real-world streaming analytics calls for novel algorithms that run online, and corresponding tools for evaluation.", "Anomaly detection with Hierarchical Temporal Memory (HTM) is a state-of-the-art, online, unsupervised method.", "The Numenta Anomaly Benchmark (NAB) is an open-source environment specifically designed to evaluate anomaly detection algorithms for real-world use."], "abstract": "We are seeing an enormous increase in the availability of streaming, time-series data. Largely driven by the rise of connected real-time data sources, this data presents technical challenges and opportunities. One fundamental capability for streaming analytics is to model each stream in an unsupervised fashion and detect unusual, anomalous behaviors in real-time. Early anomaly detection is valuable, yet it can be difficult to execute reliably in practice. Application constraints require systems to process data in real-time, not batches. Streaming data inherently exhibits concept drift, favoring algorithms that learn continuously. Furthermore, the massive number of independent streams in practice requires that anomaly detectors be fully automated. In this paper we propose a novel anomaly detection algorithm that meets these constraints. The technique is based on an online sequence memory algorithm called Hierarchical Temporal Memory (HTM). We also present results using the Numenta Anomaly Benchmark (NAB), a benchmark containing real-world data streams with labeled anomalies. The benchmark, the first of its kind, provides a controlled open-source environment for testing anomaly detection algorithms on streaming data. We present results and analysis for a wide range of algorithms on this benchmark, and discuss future challenges for the emerging field of streaming analytics.", "title": "Unsupervised real-time anomaly detection for streaming data"}, "S095741741830215X": {"highlights": ["The study describes the essential phases of text classification.", "The overview explains the concepts related to text classification.", "The quantitative analysis outlines different aspects of text classification.", "The quantitative analysis uncovers the research trends in text classification."], "abstract": "The aim of this study is to provide an overview the state-of-the-art elements of text classification. For this purpose, we first select and investigate the primary and recent studies and objectives in this field. Next, we examine the state-of-the-art elements of text classification. In the following steps, we qualitatively and quantitatively analyse the related works. Herein, we describe six baseline elements of text classification including data collection, data analysis for labelling, feature construction and weighing, feature selection and projection, training of a classification model, and solution evaluation. This study will help readers acquire the necessary information about these elements and their associated techniques. Thus, we believe that this study will assist other researchers and professionals to propose new studies in the field of text classification.", "title": "A recent overview of the state-of-the-art elements of text classification"}, "S0957417413009615": {"highlights": ["The study improves expression recognition rate and execution time.", "Average recognition rates in JAFFE and Yale databases are 96.83% and 92.22%, respectively.", "The execution time for processing 100\u00d7100 pixel size is 14.5ms.", "Best recognitions are happy, surprise, and disgust and the poorest is neutral.", "The general results are very encouraging when compared with others."], "abstract": "This study improves the recognition accuracy and execution time of facial expression recognition system. Various techniques were utilized to achieve this. The face detection component is implemented by the adoption of Viola\u2013Jones descriptor. The detected face is down-sampled by Bessel transform to reduce the feature extraction space to improve processing time then. Gabor feature extraction techniques were employed to extract thousands of facial features which represent various facial deformation patterns. An AdaBoost-based hypothesis is formulated to select a few hundreds of the numerous extracted features to speed up classification. The selected features were fed into a well designed 3-layer neural network classifier that is trained by a back-propagation algorithm. The system is trained and tested with datasets from JAFFE and Yale facial expression databases. An average recognition rate of 96.83% and 92.22% are registered in JAFFE and Yale databases, respectively. The execution time for a 100\u00d7100 pixel size is 14.5ms. The general results of the proposed techniques are very encouraging when compared with others.", "title": "A neural-AdaBoost based facial expression recognition system"}, "S0957417417300751": {"highlights": ["A taxonomy that classifies ensemble models in the literature is presented.", "Surface and deep features integration is explored to improve classification.", "Several ensembles of classifiers and features are proposed and evaluated.", "Performance of the proposed models is evaluated on several sentiment datasets."], "abstract": "Deep learning techniques for Sentiment Analysis have become very popular. They provide automatic feature extraction and both richer representation capabilities and better performance than traditional feature based techniques (i.e., surface methods). Traditional surface approaches are based on complex manually extracted features, and this extraction process is a fundamental question in feature driven methods. These long-established approaches can yield strong baselines, and their predictive capabilities can be used in conjunction with the arising deep learning methods. In this paper we seek to improve the performance of deep learning techniques integrating them with traditional surface approaches based on manually extracted features. The contributions of this paper are sixfold. First, we develop a deep learning based sentiment classifier using a word embeddings model and a linear machine learning algorithm. This classifier serves as a baseline to compare to subsequent results. Second, we propose two ensemble techniques which aggregate our baseline classifier with other surface classifiers widely used in Sentiment Analysis. Third, we also propose two models for combining both surface and deep features to merge information from several sources. Fourth, we introduce a taxonomy for classifying the different models found in the literature, as well as the ones we propose. Fifth, we conduct several experiments to compare the performance of these models with the deep learning baseline. For this, we use seven public datasets that were extracted from the microblogging and movie reviews domain. Finally, as a result, a statistical study confirms that the performance of these proposed models surpasses that of our original baseline on F1-Score.", "title": "Enhancing deep learning sentiment analysis with ensemble techniques in social applications"}, "S0736584518303831": {"highlights": ["Introduces a Modular Path Planning solution for Wire + Arc Additive Manufacturing.", "Incorporates feature-based design modularity into traditional layer-by-layer strategy.", "Presents a path planning design process for a wide variety of complex geometries.", "Streamlines software workflow reducing user\u2019s work to simple CAD operations."], "abstract": "Wire + Arc Additive Manufacturing (WAAM) has proven its capability to build medium to large metallic parts thanks to its high-rate deposition and its potentially unlimited build volume. Moreover, the low-cost equipment and the ability to deposit various metals make WAAM a strong candidate to become a standard industrial process. However, like all Additive Manufacturing (AM) technologies, the key to manufacturing suitable parts lies in the generation of an optimised path that guarantees a uniform defect-free deposition. Most AM technologies have been able to use traditional path strategies derived from CNC machining, but the specificities inherent to the arc deposition make the use of those solutions unreliable across a variety of topologies. Nevertheless, studies have shown that superior results can be achieved by using a feature-based design approach, but developing a path strategy for each new geometry would be a very time-consuming task. Therefore, this paper introduces the Modular Path Planning (MPP) solution that aims to incorporate the modularity of feature-based design into the traditional layer-by-layer strategy. By dividing each layer into individual deposition sections, this method allows users to adapt the path planning to the targeted geometry allowing the construction of a wide variety of complex geometries. This paper also proposes a software implementation that limits user interventions and reduces user inputs to basic CAD modelling operations. Moreover, the MPP has been compared to a traditional path planning solution and used to build a complex part for industry.", "title": "A modular path planning solution for Wire + Arc Additive Manufacturing"}, "S0950705118301394": {"highlights": ["Semantic networks could be used to quantify convergence and divergence in design thinking.", "Successful ideas exhibit divergence of semantic similarity and increased information content in time.", "Client feedback enhances information content and divergence of successful ideas.", "Information content and semantic similarity could be monitored for enhancement of user creativity."], "abstract": "Human creativity generates novel ideas to solve real-world problems. This thereby grants us the power to transform the surrounding world and extend our human attributes beyond what is currently possible. Creative ideas are not just new and unexpected, but are also successful in providing solutions that are useful, efficient and valuable. Thus, creativity optimizes the use of available resources and increases wealth. The origin of human creativity, however, is poorly understood, and semantic measures that could predict the success of generated ideas are currently unknown. Here, we analyze a dataset of design problem-solving conversations in real-world settings by using 49 semantic measures based on WordNet 3.1 and demonstrate that a divergence of semantic similarity, an increased information content, and a decreased polysemy predict the success of generated ideas. The first feedback from clients also enhances information content and leads to a divergence of successful ideas in creative problem solving. These results advance cognitive science by identifying real-world processes in human problem solving that are relevant to the success of produced solutions and provide tools for real-time monitoring of problem solving, student training and skill acquisition. A selected subset of information content (IC S\u00e1nchez\u2013Batet) and semantic similarity (Lin/S\u00e1nchez\u2013Batet) measures, which are both statistically powerful and computationally fast, could support the development of technologies for computer-assisted enhancements of human creativity or for the implementation of creativity in machines endowed with general artificial intelligence.", "title": "Enhancing user creativity: Semantic measures for idea generation"}, "S0888613X15000857": {"highlights": ["The non-deterministic procedure is goal-oriented, sound, and complete and terminates.", "The deterministic procedure is more efficient than the non-deterministic one.", "The number and size of trees created by the deterministic procedure are less.", "The deterministic procedure gives all and only the most general answers to a query.", "The deterministic procedure enables threshold computation and top-k retrieval."], "abstract": "Fuzzy linguistic logic programming is a logical system for representing and reasoning with linguistically-expressed human knowledge. In fuzzy linguistic logic programming, up until now, there have been only two methods to compute answers to a query w.r.t. a logic program: (i) by bottom-up iterating the immediate consequence operator \n                        \n                           \n                              T\n                           \n                           \n                              P\n                           \n                        \n                     ; or (ii) by using the procedural semantics. Nevertheless, the former is exhaustive and not goal-oriented. Indeed, it requires computation of the whole least Herbrand model despite the fact that not all the results are required to determine the answer of the query. On the other hand, although the latter is goal-oriented, it may lead to an infinite loop and may recompute atoms in rule bodies. Furthermore, it may not, in general, give a most general answer to a query. In this paper, we develop two query answering procedures which can overcome these problems for fuzzy linguistic logic programming. More precisely, the non-deterministic tabulation procedure is close to the procedural semantics and gives all answers to a query. The deterministic tabulation procedure is more efficient than the non-deterministic one and gives all and only the most general answers to a query. The deterministic procedure also enables threshold computation and top-k retrieval.", "title": "Tabulation proof procedures for fuzzy linguistic logic programming"}, "S0957417415000238": {"highlights": ["Visual ontology design is affected by cognitive peculiarities of expert or analyst.", "Field-independence, reflection and category width are main cognitive style features.", "Ontology assessment is feasible via cognitive ergonomic metrics.", "Collaborative ontology design may have several different scenarios."], "abstract": "The paper presents the main results of the KOMET (Knowledge and cOntent structuring via METhods of collaborative ontology design) project, which aims to develop a novel paradigm for knowledge structuring based on the interplay between cognitive psychology and ontology engineering. By the knowledge structure (a conceptual model) we define the main domain concepts and relations between them in the form of a graph, map or diagram. This approach considers individual cognitive styles and uses recent advances in knowledge engineering and conceptual structuring; it aims to create new, consistent and structurally holistic knowledge bases for various areas of science and technology. Two stages of research have been completed: research into correlations between the expert\u2019s individual cognitive style and the peculiarities of the expert\u2019s subject domain ontology development; and research into correlations between the expert\u2019s individual cognitive style and the group ontology design (including design accomplished by groups of experts with either similar or different cognitive styles). The results of these research stages can be applied to organizing collaborative ontology design (especially for research and learning purposes), data structuring and other group analytical work. Implications for practice are briefly delineated.", "title": "Ontology design and individual cognitive peculiarities: A pilot study"}, "S1071581918304312": {"highlights": ["An experiential goal encourged creative engagement in some aspects.", "A utilitarian goal has the potential to support a sustained creative engagement.", "Allow to replay musical ideas increased some aspects of creative engagement, when being able to edit creations the increase is more pronounced.", "A model of non-musician\u2019s creative engagement with musical interfaces is described.", "Design implications are proposed."], "abstract": "Creative engagement with novel musical interfaces can be rewarding for non-musicians. However, designing novel musical interfaces for non-musicians can be challenging because they lack conceptual and technical musical skills. In this paper we explore the effects of task motivation (experiential goal vs utilitarian goal) and user interface mode (whether the content is editable, and whether content can be replayed), on non-musicians\u2019 creative engagement with novel musical interfaces. We show through an empirical study of twenty-four participants that an experiential exploratory goal encourages users\u2019 creative engagement compared to a utilitarian creative goal. We found that being able to replay records is less important when participants have an experiential exploratory goal than when they have a utilitarian creative goal. Results also indicate that allowing people to replay their musical ideas increased some aspects of their creative engagement which was further increased when they were able to edit their creations. We also found that creative engagement increased when the interface supported users in planning ahead. A descriptive model of non-musician\u2019s creative engagement with musical interfaces is proposed including three modes of musicking. An optimal trajectory of creative engagement through these modes is suggested and a description of inferred motivations, output, status and activities during creative processes is discussed. Design implications are proposed for supporting novices\u2019 creative engagement taking into consideration their motivation and skills, and supporting insight and real-time activity.", "title": "Musicking with an interactive musical system: The effects of task motivation and user interface mode on non-musicians\u2019 creative engagement"}, "S0888613X14000607": {"highlights": ["Some extension principle-based models are also connected to robust statistics.", "Fuzzy-valued loss functions may be preferred to scalar losses.", "Disambiguation and imputation are close concepts."], "abstract": "The paper by Eyke H\u00fcllermeier introduces a new set of techniques for learning models from imprecise data. The removal of the uncertainty in the training instances through the input\u2013output relationship described by the model is also considered. This discussion addresses three points of the paper: extension principle-based models, precedence operators between fuzzy losses and possible connections between data disambiguation and data imputation.", "title": "Comments on \u201cLearning from imprecise and fuzzy observations: Data disambiguation through generalized loss minimization\u201d by Eyke H\u00fcllermeier"}, "S1071581917300988": {"highlights": ["Multisensory experience design in the museum context, integrating sound and mid-air haptic.", "Description of the design and implementation of the multisensory stimuli for visual art (painting).", "Study of the multisensory experience in an art gallery through questionnaires (2500) and interviews (50).", "Summary of lessons and implications for future multisensory design and research within HCI."], "abstract": "The use of the senses of vision and audition as interactive means has dominated the field of Human-Computer Interaction (HCI) for decades, even though nature has provided us with many more senses for perceiving and interacting with the world around us. That said, it has become attractive for HCI researchers and designers to harness touch, taste, and smell in interactive tasks and experience design. In this paper, we present research and design insights gained throughout an interdisciplinary collaboration on a six-week multisensory display \u2013 Tate Sensorium \u2013 exhibited at the Tate Britain art gallery in London, UK. This is a unique and first time case study on how to design art experiences whilst considering all the senses (i.e., vision, sound, touch, smell, and taste), in particular touch, which we exploited by capitalizing on a novel haptic technology, namely, mid-air haptics. We first describe the overall set up of Tate Sensorium and then move on to describing in detail the design process of the mid-air haptic feedback and its integration with sound for the Full Stop painting by John Latham (1961). This was the first time that mid-air haptic technology was used in a museum context over a prolonged period of time and integrated with sound to enhance the experience of visual art. As part of an interdisciplinary team of curators, sensory designers, sound artists, we selected a total of three variations of the mid-air haptic experience (i.e., haptic patterns), which were alternated at dedicated times throughout the six-week exhibition. We collected questionnaire-based feedback from 2500 visitors and conducted 50 interviews to gain quantitative and qualitative insights on visitors\u2019 experiences and emotional reactions. Whilst the questionnaire results are generally very positive with only a small variation of the visitors\u2019 arousal ratings across the three tactile experiences designed for the Full Stop painting, the interview data shed light on the differences in the visitors\u2019 subjective experiences. Our findings suggest multisensory designers and art curators can ensure a balance between surprising experiences versus the possibility of free exploration for visitors. In addition, participants expressed that experiencing art with the combination of mid-air haptic and sound was immersive and provided an up-lifting experience of touching without touch. We are convinced that the insights gained from this large-scale and real-world field exploration of multisensory experience design exploiting a new and emerging technology provide a solid starting point for the HCI community, creative industries, and art curators to think beyond conventional art experiences. Specifically, our work demonstrates how novel mid-air technology can make art more emotionally engaging and stimulating, especially abstract art that is often open to interpretation.", "title": "Not just seeing, but also feeling art: Mid-air haptic experiences integrated in a multisensory art exhibition"}, "S0740818818301828": {"highlights": ["Key library business processes offer a framework for identifying knowledge, tasks and resources.", "The redundancy of knowledge, tasks and resources determines the level of specialization.", "Congruence measures the matching of, and the compatibility of, the library's social and technical systems."], "abstract": "A library is a particular kind of organization. It plays a valuable role and is dedicated mainly to the development and growth of society. Analyzing a library from the perspective of a network of relations and ties, which exist between social and technical network nodes, contributes to a more nuanced assessment of effectiveness. Building on social network analysis and going beyond human relations in a library, this study examines perceptions related to knowledge and skills, resources, and tasks, identified through a survey conducted at the university library in Warsaw. Overall, the analyzed library is characterized by redundancy and congruence of knowledge, resources, and tasks required at the library (organizational) level and at the particular node (employee) level. Analyzing the network efficiency of a library is a new and valuable research design which uses a unique network measurement that should attract more interest in the future. This form of analysis gives managers the tools to dynamize relations and understand the flow, use, and sharing of resources or knowledge within a library context. However, more studies in the public sector would be invaluable in order to formulate new theories or conclusions.", "title": "Organizational network analysis: A study of a university library from a network efficiency perspective"}, "S1071581919300552": {"highlights": ["We review the history of human-automation interaction research in IJHCS.", "Automated systems are used by non-professional users, in more dynamic contexts.", "Given the expansion of the field, there is a continued need for HCI contributions.", "We discuss important future areas for human-automation interaction research."], "abstract": "We review the history of human-automation interaction research, assess its current status and identify future directions. We start by reviewing articles that were published on this topic in the International Journal of Human-Computer Studies during the last 50 years. We find that over the years, automated systems have been used more frequently (1) in time-sensitive or safety-critical settings, (2) in embodied and situated systems, and (3) by non-professional users. Looking to the future, there is a need for human-automation interaction research to focus on (1) issues of function and task allocation between humans and machines, (2) issues of trust, incorrect use, and confusion, (3) the balance between focus, divided attention and attention management, (4) the need for interdisciplinary approaches to cover breadth and depth, (5) regulation and explainability, (6) ethical and social dilemmas, (7) allowing a human and humane experience, and (8) radically different human-automation interaction.", "title": "History and future of human-automation interaction"}, "S0888613X14001133": {"highlights": ["We study credal networks under epistemic irrelevance for sets of desirable gambles.", "We characterise the so-called irrelevant natural extension of these networks.", "We obtain marginalisation properties for this irrelevant natural extension.", "We introduce an asymmetrical separation criterion, called AD-separation.", "We show that AD-separation implies epistemic irrelevance in the irr. nat. ext."], "abstract": "We present a new approach to credal networks, which are graphical models that generalise Bayesian networks to deal with imprecise probabilities. Instead of applying the commonly used notion of strong independence, we replace it by the weaker, asymmetrical notion of epistemic irrelevance. We show how assessments of epistemic irrelevance allow us to construct a global model out of given local uncertainty models, leading to an intuitive expression for the so-called irrelevant natural extension of a credal network. In contrast with Cozman [4], who introduced this notion in terms of credal sets, our main results are presented using the language of sets of desirable gambles. This has allowed us to derive some remarkable properties of the irrelevant natural extension, including marginalisation properties and a tight connection with the notion of independent natural extension. Our perhaps most important result is that the irrelevant natural extension satisfies a collection of epistemic irrelevancies that is induced by AD-separation, an asymmetrical adaptation of d-separation. Both AD-separation and the induced collection of irrelevancies are shown to satisfy all graphoid properties except symmetry.", "title": "Credal networks under epistemic irrelevance: The sets of desirable gambles approach"}, "S0888613X17302335": {"highlights": ["Information theoretic testing, estimation and ranking in under-reported scenarios.", "Valid tests with known power by incorporating prior knowledge.", "Corrections for point/interval estimates of the mutual information.", "Estimates that capture both relevance and redundancy.", "Different ways for ranking under-reported."], "abstract": "Under-reporting occurs in survey data when there is a reason for participants to give a false negative response to a question, e.g. maternal smoking in epidemiological studies. Failing to correct this misreporting introduces biases and it may lead to misinformed decision making. Our work provides methods of correcting for this bias, by reinterpreting it as a missing data problem, and particularly learning from positive and unlabelled data. Focusing on information theoretic approaches we have three key contributions: (1) we provide a method to perform valid independence tests with known power by incorporating prior knowledge over misreporting; (2) we derive corrections for point/interval estimates of the mutual information that capture both relevance and redundancy; and finally, (3) we derive different ways for ranking under-reported risk factors. Furthermore, we show how to use our results in real-world problems and machine learning tasks.", "title": "Dealing with under-reported variables: An information theoretic solution"}, "S0957417417307698": {"highlights": ["This work combines geo-clustering and content aggregation to detect unexpected behavior in a city.", "Content analysis provide explanatory information to anomalous clusters.", "Results show that the complementarity of content and geo-location is beneficial.", "Feasibility to be deployed in real scenarios."], "abstract": "Citizens are actively interacting with their surroundings, especially through social media. Not only do shared posts give important information about what is happening (from the users\u2019 perspective), but also the metadata linked to these posts offer relevant data, such as the GPS-location in Location-based Social Networks (LBSNs). In this paper we introduce a global analysis of the geo-tagged posts in social media which supports (i) the detection of unexpected behavior in the city and (ii) the analysis of the posts to infer what is happening. The former is obtained by applying density-based clustering techniques, whereas the latter is consequence of applying content aggregation techniques. We have applied our methodology to a dataset obtained from Instagram activity in New York City for seven months obtaining promising results. The developed algorithms require very low resources, being able to analyze millions of data-points in commodity hardware in less than one hour without applying complex parallelization techniques. Furthermore, the solution can be easily adapted to other geo-tagged data sources without extra effort.", "title": "Discovering geo-dependent stories by combining density-based clustering and thread-based aggregation techniques"}, "S0933365716302950": {"highlights": ["Data-driven Bayesian networks based analysis has been performed on health care data.", "Summarized, healthcare provider level data was used for this analysis.", "Novel hypothesis linking diagnosis codes was proposed based on findings from Bayesian networks approach.", "Potential mechanisms were explored to explain novel hypothesis.", "This paper demonstrates the ability of artificial intelligence methods to advance medical research."], "abstract": "Objective\n                  Given the availability of extensive digitized healthcare data from medical records, claims and prescription information, it is now possible to use hypothesis-free, data-driven approaches to mine medical databases for novel insight. The goal of this analysis was to demonstrate the use of artificial intelligence based methods such as Bayesian networks to open up opportunities for creation of new knowledge in management of chronic conditions.\n               \n               \n                  Materials and methods\n                  Hospital level Medicare claims data containing discharge numbers for most common diagnoses were analyzed in a hypothesis-free manner using Bayesian networks learning methodology.\n               \n               \n                  Results\n                  While many interactions identified between discharge rates of diagnoses using this data set are supported by current medical knowledge, a novel interaction linking asthma and renal failure was discovered. This interaction is non-obvious and had not been looked at by the research and clinical communities in epidemiological or clinical data. A plausible pharmacological explanation of this link is proposed together with a verification of the risk significance by conventional statistical analysis.\n               \n               \n                  Conclusion\n                  Potential clinical and molecular pathways defining the relationship between commonly used asthma medications and renal disease are discussed. The study underscores the need for further epidemiological research to validate this novel hypothesis. Validation will lead to advancement in clinical treatment of asthma & bronchitis, thereby, improving patient outcomes and leading to long term cost savings. In summary, this study demonstrates that application of advanced artificial intelligence methods in healthcare has the potential to enhance the quality of care by discovering non-obvious, clinically relevant relationships and enabling timely care intervention.", "title": "Non-obvious correlations to disease management unraveled by Bayesian artificial intelligence analyses of CMS data"}, "S1071581916301380": {"highlights": ["The study examined how the Facebook News Feed algorithm constrains interaction.", "Facebook users were prompted to notice posts from Friends that they had missed.", "Relationship closeness did not affect the likelihood of noticing missed posts.", "Missed posts from close Friends were more surprising, indicating unmet expectations.", "Believing the algorithm caused missed posts was related to greater surprise."], "abstract": "The Facebook News Feed prioritizes posts for display by ranking them more prominently in the News Feed, based on users\u2019 past interactions with the system. This study investigated constraints imposed on social interactions by the algorithm, by triggering participants\u2019 awareness of \u201cmissed posts\u201d in their Friends\u2019 Timelines that they did not remember seeing before. If the algorithm prioritizes posts from people that users feel closer to and want to stay in touch with, participants should be less likely to report missed posts from close Friends. However, the results showed that relationship closeness had no effect on the likelihood of noticing a missed post, after controlling for how many Facebook Friends participants had and the accuracy of participants\u2019 memories for their Friends\u2019 Facebook activity. Also, missed posts from close Friends were more surprising, even when participants believed that the actions of the system caused the missed posts, indicating that these instances represent participants\u2019 unmet expectations for the behavior of their News Feeds. Because Facebook posts present opportunities for feedback important for social support and maintaining social ties, this could indicate bias in the way the algorithm promotes content that could affect users\u2019 ability to maintain relationships on Facebook. These findings have implications for approaches to improve user control and increase transparency in systems that use algorithmic filtering.", "title": "Examining user surprise as a symptom of algorithmic filtering"}, "S259018851930006X": {"highlights": ["Based on fuzzy trend forecasting, automatic clustering and PSO techniques.", "IRI is regarded as fuzzy time series, which are divided into different granular spaces.", "IRI prediction in this research can utilize multiple factors.", "PSO technique is employed incorporating with multi-granularity analysis."], "abstract": "The effective prediction of pavement performance trends can help in achieving the cost-effective management of pavements over their service life. The international roughness index (IRI) is a widely used pavement performance index, which can be considered as a time-dependent variable in terms of scientific modeling. This research aims to develop an innovative IRI prediction model based on fuzzy-trend time-series forecasting and particle swarm optimization (PSO) techniques. Raw datasets extracted from the Long-Term Pavement Performance database are used for model training, testing, and performance assessment. First, IRI values are divided into different granular spaces, which are considered as the principal factor and subfactors. In addition, the multifactor interval division method is proposed according to the principle of the automatic clustering technique. Next, a second-order fuzzy-trend model and fuzzy-trend relationship classification method are proposed to predict the fuzzy-trend of each factor. Then, the fuzzy-trend states for multiple granular spaces are generated while giving full consideration to various uncertainties. Finally, the PSO technique is used to optimize the performance model while carrying out future IRI forecasting. Comparative experiments are performed using more than 20,000 data items from different regions to verify the effectiveness of the proposed method. The experimental results indicate that the proposed method outperforms other approaches including the polynomial fitting, autoregressive integrated moving average, and backpropagation neural network methods in terms of the root mean squared error (0.191) and relative error (6.37%).", "title": "International roughness index prediction based on multigranularity fuzzy time series and particle swarm optimization"}, "S1071581917301404": {"highlights": ["We explored the transformation of social media content into three radically different formats; a book, a triptych of photographs and film.", "Using interviews, we investigated users' responses to their remediated data.", "Our findings were used to develop a digital curation process to assist the development of different tools for social media analysis and display.", "Our paper establishes design implications to aid reflection on social media use through remediation."], "abstract": "Increasingly our digital traces are providing new opportunities for self-reflection. In particular, social media (SM) data can be used to support self-reflection, but to what extent is this affected by the form in which SM data is presented? Here, we present three studies where we work with individuals to transform or remediate their SM data into a physical book, a photographic triptych and a film. We describe the editorial decisions that take place as part of the remediation process and show how the transformations allow users to reflect on their digital identity in new ways. We discuss our findings in terms of the application of Goffman's (1959) self-presentation theories to the SM context, showing that a fluid rather than bounded interpretation of our social media spaces may be appropriate. We argue that remediation can contribute to the understanding of digital self and consider the design implications for new SM systems designed to support self-reflection.", "title": "Exploring digital remediation in support of personal reflection"}, "S1071581916000021": {"highlights": ["We examine if the length of a person\u05f3s thumb can be revealed from how they interact with a smartphone.", "From thumb length, we can infer other physical characteristics such as likely standing height.", "We examined 19,000 swipe gestures captured from 178 volunteers.", "People with longer thumbs complete swipe gestures faster than those with shorter thumbs.", "Males and females differ in the amount of pressure applied to the screen."], "abstract": "Anthropometrics show that the lengths of many human body segments follow a common proportional relationship. To know the length of one body segment \u2013 such as a thumb \u2013 potentially provides a predictive route to other physical characteristics, such as overall standing height. In this study, we examined whether it is feasible that the length of a person\u05f3s thumb could be revealed from the way in which they complete swipe gestures on a touchscreen-based smartphone.\n                  From a corpus of approx. 19,000 swipe gestures captured from 178 volunteers, we found that people with longer thumbs complete swipe gestures with shorter completion times, higher speeds and with higher accelerations than people with shorter thumbs. These differences were also observed to exist between our male and female volunteers, along with additional differences in the amount of touch pressure applied to the screen.\n                  Results are discussed in terms of linking behavioural and physical biometrics.", "title": "Different strokes for different folks? Revealing the physical characteristics of smartphone users from their swipe gestures"}, "S0957417419301903": {"highlights": ["We freshly use a sample of personal loans, provided by one of the largest Indian banks.", "We uniquely use actual misclassification costs to evaluate our models.", "Our scoring models can significantly reduce the default rate by 14.24%.", "Redundancy and branch-closure policies could thus ultimately have been avoided."], "abstract": "The main aim of this paper is to investigate how far applying suitably conceived and designed credit scoring models can properly account for the incidence of default and help improve the decision-making process. Four statistical modelling techniques, namely, discriminant analysis, logistic regression, multi-layer feed-forward neural network and probabilistic neural network are used in building credit scoring models for the Indian banking sector. Notably actual misclassification costs are analysed in preference to estimated misclassification costs. Our first-stage scoring models show that sophisticated credit scoring models, in particular probabilistic neural networks, can help to strengthen the decision-making processes by reducing default rates by over 14%. The second-stage of our analysis focuses upon the default cases and substantiates the significance of the timing of default. Moreover, our results reveal that State of residence, equated monthly instalment, net annual income, marital status and loan amount, are the most important predictive variables. The practical implications of this study are that our scoring models could help banks avoid high default rates, rising bad debts, shrinking cash flows and punitive cost-cutting measures.", "title": "Would two-stage scoring models alleviate bank exposure to bad debt?"}, "S1071581917300320": {"highlights": ["Interactive newsprint can be authored to include audio information and voting.", "Interactive paper can be designed and experienced at four different levels.", "Audio can add personality and authenticity to printed news.", "Printed and online news might be combined in new ways through interactive newsprint."], "abstract": "The possibility of linking paper to digital information is enhanced by recent developments in printed electronics. In this article we report the design and evaluation of a local newspaper augmented with capacitive touch regions and an embedded Bluetooth chip working with an adjunct device. These allowed the interactive playback of associated audio and the registration of manual voting actions on the web. Design conventions inherited from paper and the web were explored by showing four different versions of an interactive newspaper to 16 community residents. The diverse responses of residents are described, outlining the potential of the approach for local journalism and recommendations for the design of interactive newsprint.", "title": "Designing interactive newsprint"}, "S0957417419301812": {"highlights": ["Machine learning classifiers can be used to resolve cashtag collisions on Twitter.", "Classifiers benefit from custom company corpora created through data fusion.", "Support Vector Machines outperform other classifiers in this regard."], "abstract": "Investors utilise social media such as Twitter as a means of sharing news surrounding financials stocks listed on international stock exchanges. Company ticker symbols are used to uniquely identify companies listed on stock exchanges and can be embedded within tweets to create clickable hyperlinks referred to as cashtags, allowing investors to associate their tweets with specific companies. The main limitation is that identical ticker symbols are present on exchanges all over the world, and when searching for such cashtags on Twitter, a stream of tweets is returned which match any company in which the cashtag refers to - we refer to this as a cashtag collision. The presence of colliding cashtags could sow confusion for investors seeking news regarding a specific company. A resolution to this issue would benefit investors who rely on the speediness of tweets for financial information, saving them precious time. We propose a methodology to resolve this problem which combines Natural Language Processing and Data Fusion to construct company-specific corpora to aid in the detection and resolution of colliding cashtags, so that tweets can be classified as being related to a specific stock exchange or not. Supervised machine learning classifiers are trained twice on each tweet \u2013 once on a count vectorisation of the tweet text, and again with the assistance of features contained in the company-specific corpora. We validate the cashtag collision methodology by carrying out an experiment involving companies listed on the London Stock Exchange. Results show that several machine learning classifiers benefit from the use of the custom corpora, yielding higher classification accuracy in the prediction and resolution of colliding cashtags.", "title": "A methodology for the resolution of cashtag collisions on Twitter \u2013 A natural language processing & data fusion approach"}, "S0921889018307474": {"highlights": ["Automatic controller generation based on sensor variables\u2019 dependency detection.", "Multi-modal sensor relations found automatically using mutual information.", "Applicable to soft-actuator robot system with unknown physical properties.", "Analyzable partial relations identified in the controller generator.", "Robust and quick adaptation of controller to partial change of the robot system."], "abstract": "Autonomous robots that work in the same environment as humans are preferred to ensure mechanical safety with respect to soft contact with their surroundings and adaptivity to handle various tools and to manage partial malfunctions. To ensure that these requirements for robots are satisfied, this study proposes an approach for obtaining a robot structure and its application to building controller for dynamic motion of a robot. It is assumed that the physical relations between the sensor variables are unknown. On the basis of dependency network construction using mutual information, controllers are generated and tested by finding appropriate causal chains of the sensor variables. The proposed controller generation methods were tested using the control tasks of a musculoskeletal robotic arm. Thus, the proposed controller generation algorithm finds appropriate controllers, and the framework of this generation is robust to the changes in the body of the body.", "title": "Automatic controller generation based on dependency network of multi-modal sensor variables for musculoskeletal robotic arm"}, "S0306437919304909": {"highlights": ["Visualization concepts for rule violations, anomalies, and root causes are presented.", "A comparison with five alternative anomaly detection approaches is given.", "Related design requirements are discussed based on systematic literature reviews.", "A user study on process anomaly root cause visualization techniques is performed.", "Related challenges and limitations are discussed."], "abstract": "Detecting anomalies in process runtime behavior is crucial: they might reflect, on the one side, security breaches and fraudulent behavior and on the other side desired deviations due to, for example, exceptional conditions. Both scenarios yield valuable insights for process analysts and owners, but happen due to different reasons and require a different treatment. Hence a distinction into malign and benign anomalies is required. Existing anomaly detection approaches typically fall short in supporting experts when in need to take this decision. An additional problem are false positives which could result in selecting incorrect countermeasures. This paper proposes a novel anomaly detection approach based on association rule mining. It fosters the explanation of anomalies and the estimation of their severity. In addition, the approach is able to deal with process change and flexible executions which potentially lead to false positives. This facilitates to take the appropriate countermeasure for a malign anomaly and to avoid the possible termination of benign process executions. The feasibility and result quality of the approach are shown by a prototypical implementation and by analyzing real life logs with injected artificial anomalies. The explanatory power of the presented approach is evaluated through a controlled experiment with users.", "title": "Mining association rules for anomaly detection in dynamic process runtime behavior and explaining the root cause to users"}, "S1071581918300016": {"highlights": ["This paper original contribution is a multilayer framework for personalisation in the context of tangible and embodied interaction for cultural heritage.", "It originates from a methodological approach that involves cultural heritage professionals in shaping personalisation that is meaningful to them and effective with visitors.", "To better explain the framework, we bring together in an organic and reflexive way several studies and prototypes based on the proposed approach."], "abstract": "Shaping personalisation in a scenario of tangible, embedded and embodied interaction for cultural heritage involves challenges that go well beyond the requirements of implementing content personalisation for portable mobile guides. Content is coupled with the physical experience of the objects, the space, and the facets of the context\u2014being those personal or social\u2014acquire a more prominent role. This paper presents a personalisation framework to support complex scenarios that combine the physical, the digital, and the social dimensions of a visit. It is based on our experience of collaborating with curators and museum experts to understand and shape personalisation in a way that is meaningful to them and to visitors alike, that is sustainable to implement, and effective in managing the complexity of context-awareness. The proposed approach features a decomposition of personalisation into multiple layers of complexity that involve a blend of customisation on the visitor's initiative or according to the visitor's profile, system context-awareness, and automatic adaptivity computed by the system based on the visitor's behaviour model. We use a number of case studies of implemented exhibitions where this approach was used to illustrate its many facets and how adaptive techniques can be effectively complemented with interaction design, rich narratives and visitors\u2019 choice to create deeply personal experiences. Overarching reflections spanning case studies and prototypes provide evidence of the viability of the proposed framework, and illustrate the final effect of the user experience.", "title": "Blending customisation, context-awareness and adaptivity for personalised tangible interaction in cultural heritage"}, "S0736584515000666": {"highlights": ["A part of the work undertaken for the development of a KUKA robot manipulator based automated NDT system is presented.", "A MATLAB based software solution enables flexible trajectory planning to be accomplished for the inspection of complex curved surfaces, often encountered in engineering production.", "The novelty of the approach lies in the linking of feedback and control of industrial 6 axis manipulators through an external PC, running the developed software, to generate NDT tool-paths.", "The paper provides experimental validation of path trajectory generation and NDT data acquisition on two large, curved surfaces of a composite aerofoil component."], "abstract": "The requirement to increase inspection speeds for non-destructive testing (NDT) of composite aerospace parts is common to many manufacturers. The prevalence of complex curved surfaces in the industry provides motivation for the use of 6 axis robots in these inspections. The purpose of this paper is to present work undertaken for the development of a KUKA robot manipulator based automated NDT system. A new software solution is presented that enables flexible trajectory planning to be accomplished for the inspection of complex curved surfaces often encountered in engineering production. The techniques and issues associated with conventional manual inspection techniques and automated systems for the inspection of large complex surfaces were reviewed. This approach has directly influenced the development of a MATLAB toolbox targeted to NDT automation, capable of complex path planning, obstacle avoidance, and external synchronization between robots and associated external NDT systems. This paper highlights the advantages of this software over conventional off-line-programming approaches when applied to NDT measurements. An experimental validation of path trajectory generation, on a large and curved composite aerofoil component, is presented. Comparative metrology experiments were undertaken to evaluate the real path accuracy of the toolbox when inspecting a curved 0.5m2 and a 1.6m2 surface using a KUKA KR16 L6-2 robot. The results have shown that the deviation of the distance between the commanded TCPs and the feedback positions were within 2.7mm. The variance of the standoff between the probe and the scanned surfaces was smaller than the variance obtainable via commercial path-planning software. Tool paths were generated directly on the triangular mesh imported from the CAD models of the inspected components without need for an approximating analytical surface. By implementing full external control of the robotic hardware, it has been possible to synchronise the NDT data collection with positions at all points along the path, and our approach allows for the future development of additional functionality that is specific to NDT inspection problems. For the current NDT application, the deviations from CAD design and the requirements for both coarse and fine inspections, dependent on measured NDT data, demand flexibility in path planning beyond what is currently available from existing off-line robot programming software.", "title": "Robotic path planning for non-destructive testing \u2013 A custom MATLAB toolbox approach"}, "S0888613X13002041": {"highlights": ["We proposed a model based on Type-2 fuzzy time series and particle swarm optimization.", "The model deals with M-factors time series data set.", "The model is tested and validated with SBI and Google stock index data sets.", "Various comparison studies with different models exhibit superiority of our model."], "abstract": "In real time, one observation always relies on several observations. To improve the forecasting accuracy, all these observations can be incorporated in forecasting models. Therefore, in this study, we have intended to introduce a new Type-2 fuzzy time series model that can utilize more observations in forecasting. Later, this Type-2 model is enhanced by employing particle swarm optimization (PSO) technique. The main motive behind the utilization of the PSO with the Type-2 model is to adjust the lengths of intervals in the universe of discourse that are employed in forecasting, without increasing the number of intervals. The daily stock index price data set of SBI (State Bank of India) is used to evaluate the performance of the proposed model. The proposed model is also validated by forecasting the daily stock index price of Google. Our experimental results demonstrate the effectiveness and robustness of the proposed model in comparison with existing fuzzy time series models and conventional time series models.", "title": "Forecasting stock index price based on M-factors fuzzy time series and particle swarm optimization"}, "S0888613X1400067X": {"highlights": ["It uses multi-tier structure to interpret association rules in terms of granules.", "It proposes association mappings for the construction of multi-tier structure.", "It presents a method to interpret granules in terms of patterns.", "It indicates that small closed patterns can be interpreted as small granules.", "It proves that decision rules and max closed patterns are mutually corresponding."], "abstract": "Dealing with the large amount of data resulting from association rule mining is a big challenge. The essential issue is how to provide efficient methods for summarizing and representing meaningful discovered knowledge from databases. This paper presents a new approach called multi-tier granule mining to improve the performance of association rule mining. Rather than using patterns, it uses granules to represent knowledge that is implicitly contained in relational databases. This approach also uses multi-tier structures and association mappings to interpret association rules in terms of granules. Consequently, association rules can be quickly assessed and meaningless association rules can be justified according to these association mappings. The experimental results indicate that the proposed approach is promising.", "title": "Interpretation of association rules in multi-tier structures"}, "S1875952117300952": {"highlights": ["The applicable agreement between the devices was measured using a two-way ANOVA.", "3D visualisation and real-time mirrored effects have helped a player\u2019s to correct themselves and improved the ROM.", "A comparable inter-session reliability (acceptable to good)", "ICC", "2", ",", "1", "\u2a7e", "0.79", "over two repeated sessions was achieved.", "The Pearson correlation between two devices was high (", "r", "\u2a7e", "0.84", ")."], "abstract": "A cost-effective, easily-accessible neuro-motor rehabilitation solution is proposed that can determine the range of motion and the kinematic ability of participants. A serious game comprising four-scenarios are developed in which the players control an avatar that mirrors the rotations of the upper-limb joints through multi-channel-input devices (Kinect, Myo, FootPedal). Administered functional reach tests (FRT) challenge the player to interact with a 3D-environment while standing or sitting and using the FootPedal which simulates the action of walking whilst body movement is measured concurrently. The FRT\u2019s complexity level is adapted using a Monte Carlo Tree Search algorithm which determines a virtual object\u2019s position based on the proved ability of the user. Twenty-three volunteers were recruited to play the game in 45-min sessions. The data show that the system has a more positive impact on players performance and is more motivating than formal therapy. The visual representation of the trajectory of the objects is shown to increase the perception of the participants voluntary/involuntary upper extremity movement, and the results show a comparable inter-session reliability (acceptable-good) over two repeated sessions. A high Pearson correlation demonstrates the validity of using Kinect and Myo devices in assessing upper-limb rehabilitation, and the timing and the clinically relevant movement data have a higher accuracy when the devices are paired.", "title": "Validity of the Kinect and Myo armband in a serious game for assessing upper limb movement"}, "S0142061518304319": {"highlights": ["PD measuring circuit affects PD features and in turn effectiveness of clustering techniques.", "Density Peak Clustering method may fail with data sets having large variation of density and scatter.", "Density Peak Clustering method and smoothed density methods are combined to better separate clusters.", "The proposed methodology splits data sets in subsets improving computational performance."], "abstract": "The recognition of partial discharge (PD) sources is an important task of the monitoring and diagnostics of high-voltage components. Nowadays, digital PD measuring systems have the capability of extracting features and form scatter plots with such data sets. Part of an unsupervised PD analysis system is to discover clusters within the data sets and link them to particular PD sources. Due to the nature of PD data sets, clusters may appear very close to each other or even merged hindering the separation of sources. Clustering methods based on spatial density such as the density peak clustering (DPC) method and DBSCAN are suitable approaches to discover clusters within PD data sets. However, their accuracy can be reduced due to the proximity among clusters. In this paper, a new method is presented to improve the accuracy of the DPC method. Our method proposes to partition the data set and later pass the resulting subsets to the DPC method. The partitioning is based on the spatial density of data computed by a smoothed density method (SD). SD has the advantage of being fast and not requiring high computational power. As a final step, a routine is applied to group the sub clusters as per the DPC method having a threshold for the data contour distance as a criterion. This method proved higher accuracy to discover clusters in actual PD data sets. However, the threshold for the data contour distance still needs further research.", "title": "Density-based clustering methods for unsupervised separation of partial discharge sources"}, "S0957417416306844": {"highlights": ["We build highly applicable clustering method of non-linear data.", "We use a f-adapted Gaussian distribution.", "We use Cross-Entropy clustering method instead of EM approach.", "Our algorithm gives better results than classical methods."], "abstract": "Gaussian Mixture Models (GMM) have many applications in density estimation and data clustering. However, the models do not adapt well to curved and strongly nonlinear data, since many Gaussian components are typically needed to appropriately fit the data that lie around the nonlinear manifold.\n                  To solve this problem we constructed the Active Function Cross-Entropy Clustering (afCEC) method, which uses Gaussians in curvilinear coordinate systems. The method has a few advantages in relation to GMM: it enables easy adaptation to clustering of complicated data sets along with a predefined family of functions and does not need external methods to determine the number of clusters, as it automatically (on-line) reduces the number of groups.\n                  Experiments on synthetic data, Chinese characters, data from UCI repository and wind turbine monitoring systems show that the proposed nonlinear model typically obtains better results than the classical methods.", "title": "Active function Cross-Entropy Clustering"}, "S0888613X15000912": {"highlights": ["Developed is a concept of incremental models with fuzzy rules.", "Rules capture the structure of error and realize its compensation.", "Fuzzy clustering is used as a generic method to structure errors of the generic model.", "A series of experimental studies is reported demonstrating the performance of the proposed approach."], "abstract": "In the study, we propose a concept of incremental fuzzy models in which fuzzy rules are aimed at compensating discrepancies resulting because of the use of a certain global yet simple model of general nature (such as e.g., a constant or linear regression). The structure of input data and error discovered through fuzzy clustering is captured in the form of a collection of fuzzy clusters, which helps eliminate (compensate) error produced by the global model. We discuss a detailed architecture of the proposed rule-based model and present its design based on an augmented version of Fuzzy C-Means (FCM). An extended suite of experimental studies offering some comparative analysis is covered as well.", "title": "A rule-based development of incremental models"}, "S0888613X14000796": {"highlights": ["We give conditions under which the principle of exclusion/inclusion applies to belief functions.", "We discuss its interest for evaluating uncertainty on Boolean formulas and monotone functions.", "We illustrate the applicability of our results on reliability analysis problems.", "We discuss the connection with other types of independence (strong independence)."], "abstract": "The inclusion\u2013exclusion principle is a well-known property in probability theory, and is instrumental in some computational problems such as the evaluation of system reliability or the calculation of the probability of a Boolean formula in diagnosis. However, in the setting of uncertainty theories more general than probability theory, this principle no longer holds in general. It is therefore useful to know for which families of events it continues to hold. This paper investigates this question in the setting of belief functions. After exhibiting original sufficient and necessary conditions for the principle to hold, we illustrate its use on the uncertainty analysis of Boolean and non-Boolean systems in reliability.", "title": "Inclusion\u2013exclusion principle for belief functions"}, "S1071581916300866": {"highlights": ["A set of scenarios that reliably express situations of a specific stressor.", "A set of emotional support statements reliably categorised into 5 main categories.", "An evaluated algorithm for choosing emotional support statements for a stressor.", "A method for investigating how to provide emotional support."], "abstract": "Although computers could offer emotional support as well as task support when aiding a user for a complex task, there is little current understanding of how they might do this. Moreover existing demonstrations of emotional support, though promising, only cover a small number of types of support and investigate a limited number of algorithms designed by hand. In this paper, we present an empirical investigation that starts from first principles, determining different categories of stressors for which emotional support might be useful, different categories of emotional support utterances and promising algorithms for deciding the content and form of textual emotional support messages according to the stressors present. At each stage, the results are validated through empirical experiments with human participants who, for instance, are required to place statements into categories, evaluate possible support messages in different imagined situations and compose their own emotional support from options offered. This development methodology allows us to avoid potentially challenging ethical issues in presenting people with stressful situations. Although our algorithms are attempting to choose emotional support based on the general, \u201cnaive\u201d competence of human speakers, we use as a running example situations that can arise when attending a medical emergency and awaiting expert help.", "title": "Designing emotional support messages tailored to stressors"}, "S0957417418306535": {"highlights": ["We expose the two sides of the malware arms race: detection and evasion.", "We propose EnTS, a novel and scalable malware detection technique.", "EnTS improves the accuracy of its competitors, being up to 3000 times faster.", "To defeat EnTS, we create EEE, an evasion technique with learning abilities.", "EEE defeats EnTS and SoA detectors, pushing their false negatives up to a 90%."], "abstract": "Malware creators have been getting their way for too long now. String-based similarity measures can leverage ground truth in a scalable way and can operate at a level of abstraction that is difficult to combat from the code level. At the string level, information theory and, specifically, entropy play an important role related to detecting patterns altered by concealment strategies, such as polymorphism or encryption. Controlling the entropy levels in different parts of a disk resident executable allows an analyst to detect malware or a black hat to evade the detection. This paper shows these two perspectives into two scalable entropy-based tools: EnTS and EEE. EnTS, the detection tool, shows the effectiveness of detecting entropy patterns, achieving 100% precision with 82% accuracy. It outperforms VirusTotal for accuracy on combined Kaggle and VirusShare malware. EEE, the evasion tool, shows the effectiveness of entropy as a concealment strategy, attacking binary-based state of the art detectors. It learns their detection patterns in up to 8 generations of its search process, and increments their false negative rate from range 0\u20139%, up to the range 90\u201398.7%.", "title": "The arms race: Adversarial search defeats entropy used to detect malware"}, "S0925231214000265": {"highlights": ["We extend the low-rank matrix completion problem to a low-n-rank tensor completion problem.", "An efficient algorithm based on the multi-linear low-n-rank factorization model is proposed in this paper.", "The nonlinear Gauss\u2013Seidal method that only requires solving a linear least squares problem per iteration is applied to solve this model.", "The proposed algorithm is much less computational cost than the trace norm minimization algorithm especially facing the large data."], "abstract": "The tensor completion problem is to recover a low-n-rank tensor from a subset of its entries. The main solution strategy has been based on the extensions of trace norm for the minimization of tensor rank via convex optimization. This strategy bears the computational cost required by the singular value decomposition (SVD) which becomes increasingly expensive as the size of the underlying tensor increase. In order to reduce the computational cost, we propose a multi-linear low-n-rank factorization model and apply the nonlinear Gauss\u2013Seidal method that only requires solving a linear least squares problem per iteration to solve this model. Numerical results show that the proposed algorithm can reliably solve a wide range of problems at least several times faster than the trace norm minimization algorithm.", "title": "Tensor completion via a multi-linear low-n-rank factorization model"}, "S0888613X14000851": {"highlights": ["This issue contains five position papers, nine discussion papers and five rejoinders.", "Position papers propose different techniques to deal with uncertainty in statistics.", "Each position paper is commented by two or more discussants.", "A rejoinder to the discussions was written for each position paper."], "abstract": "This special issue contains a collection of five position papers, nine discussion papers and five rejoinders. The content of the five position papers is based on the plenary talks presented by the authors at the Workshop on Harnessing the Information contained in Low-Quality Data Sources jointly organized by the University of Oviedo and the Soft Computing Centre, which took place in Mieres (Asturias), May 16\u201317, 2012. During the workshop, the plenary speakers proposed different techniques to deal with some specific problems concerning uncertainty in statistics and encouraged discussion among members from different communities. At the end of the workshop, a round table entitled \u201cUncertainty in Statistics\u201d, chaired by Dr. Dubois, took place. The aim of the round table was to better understand the impact on Statistics and Information Processing of several more or less recent formalisms such as Fuzzy Set Theory (Zadeh [24]), Random sets (Kendall [14], Matheron [16]), Belief functions (Shafer [21], Smets [22]), Possibility theory (Shackle [20], Zadeh [25]), Imprecise probabilities (Dempster [4], Walley [23]), Fuzzy random variables (F\u00e9ron [11]), etc. As a result of this meeting, the present issue includes deep and insightful discussion around those topics.\n\nThe paper entitled \u201cA distance-based statistical analysis of fuzzy number-valued data\u201d, written by the members of the SMIRE Research Group [1] focuses on the ontic view of (fuzzy) random sets. According to this perspective, their (fuzzy) set-valued outcomes are viewed as complex entities belonging to a space of functions, as a counterpart to the epistemic interpretation of the outcomes of random sets and fuzzy random variables, representing imprecise or incomplete perceptions of precise quantities. (See [8,10], where the notions of \u201contic\u201d and \u201cepistemic\u201d fuzzy sets are introduced and discussed). This paper is discussed by S\u00e9bastien Destercke [6] and also by Didier Dubois [9], in the second section of his discussion paper entitled \u201cOn various ways of tackling incomplete information in statistics\u201d.\n\nThe papers written by In\u00e9s Couso and Didier Dubois [2] and by Eyke H\u00fcllermeier [13] demonstrate the importance of distinguishing between the ontic and the epistemic interpretations of (fuzzy) set-valued data, and illustrate this issue in different examples of application. In their paper \u201cStatistical reasoning with set-value information: ontic vs epistemic views\u201d [2], the authors consider several situations where each of both interpretations of fuzzy data appears, and it reviews different extensions that naturally arise in each case for several notions and techniques in (classical) Probability and Statistics, such as the concept of conditional probability and independence, the notion of variance, or different regression techniques under different frameworks. The paper is discussed by Prof. Seraf\u00edn Moral [17] and Prof. Mar\u00eda \u00c1ngeles Gil [12]. Meanwhile, Prof. Eyke H\u00fcllermeier argues that different interpretations of fuzzy sets call from different types of extensions of existing learning algorithms and methods for data analysis. His paper entitled \u201cLearning from imprecise and fuzzy observations: data disambiguation through generalized loss minimization\u201d [13] focuses on the epistemic interpretation of fuzzy sets and proposes a generic approach that allows for generalizing machine learning methods to the case of imprecise data; this approach can be applied to different loss-function-based methods. The idea is illustrated by means of two concrete problems, namely regression and classification. The author introduces the notion of \u201cdata disambiguation\u201d in order to select a most plausible model, based on the information provided by a set of imprecisely specified observations and the underlying statistical model assumptions. Several existing methods, such as robust regression and semi-supervised learning, are recovered as special cases. This special issue also contains three discussions on this paper authored by S\u00e9bastien Destercke [7], Luciano S\u00e1nchez [19] and Didier Dubois [9], that devotes the fourth section of his discussion paper to this one.\n\nAlso within the epistemic view, the paper authored by Thierry Den\u0153ux [5] describes an approach to statistical inference using belief functions. Prior knowledge of the parameter is not required and the relative likelihood of the parameter is identified with a contour function of a consonant belief function. Extensions for partially relevant and uncertain data are also addressed. This paper is discussed by Seraf\u00edn Moral [18] and Didier Dubois [9].\n\nLastly, the paper by Andr\u00e9s Masegosa and Seraf\u00edn Moral [15] examine the use of imprecise models for estimating multinomial probabilities. It is shown that the selection of the equivalent sample size in a Dirichlet model is not simple, and imprecise equivalent sample sizes are considered that are useful to learn credal networks with an also imprecise structure. The discussion about this work comprises three papers. One of them is written by Marco Zaffalon and Giorgio Corani [26], another one is authored by Fabio G. Cozman [3] and a third review is included in Didier Dubois' discussion paper [9].\n\nRejoinders to the discussions comments and suggestions provided by the discussants end this special issue.", "title": "Harnessing the information contained in low-quality data sources"}, "S0921889016306285": {"highlights": ["We discuss how service robots interact with human labor.", "We identify different job segments that might come under pressure.", "We describe how human\u2013machine cooperation should be developed from a work science perspective.", "We define first concluding criteria to assess service robots with respect to human labor."], "abstract": "Since the beginning of robotics, the substitution of human labor has been one of the crucial issues. The focus is on the economic perspective, asking how robotics affects the labor market, and on changes in the work processes of human workers. While there are already some lessons learnt from industrial robotics, the area of service robots has been analyzed to a much lesser extent. First insights into these aspects are of utmost relevance to technology assessment providing policy advice. As conclusions for service robots in general cannot be drawn, we identify criteria for the ex-ante evaluation of service robots in concrete application areas.", "title": "Service Robotics and Human Labor: A first technology assessment of substitution and cooperation"}, "S0888613X14000206": {"highlights": ["We presented two p-adic valued conditional probabilistic logics.", "Formulas are interpreted in Kripke-like models.", "Axiomatic systems are given and proved to be sound and strongly complete.", "The decidability of the satisfiability problem for each logic is proved."], "abstract": "In this paper we present the proof-theoretical approach to p-adic valued conditional probabilistic logics. We introduce two such logics denoted by \n                        \n                           \n                              CPL\n                           \n                           \n                              \n                                 \n                                    Z\n                                 \n                                 \n                                    p\n                                 \n                              \n                           \n                        \n                      and \n                        \n                           \n                              CPL\n                           \n                           \n                              \n                                 \n                                    Q\n                                 \n                                 \n                                    p\n                                 \n                              \n                           \n                           \n                              fin\n                           \n                        \n                     . Each of these logics extends classical propositional logic with a list of binary (conditional probability) operators. Formulas are interpreted in Kripke-like models that are based on p-adic probability spaces. Axiomatic systems with infinitary rules of inference are given and proved to be sound and strongly complete. The decidability of the satisfiability problem for each logic is proved.", "title": "Conditional p-adic probability logic"}, "S0921889014002164": {"highlights": ["An extensive survey of human\u2013robot interactive communication is provided.", "Verbal as well as non-verbal aspects of human\u2013robot interaction are covered.", "The paper starts with a historical introduction.", "Ten special desiderata that human\u2013robot systems should fulfil are proposed.", "The desiderata are examined in detail, culminating to a forward-looking discussion."], "abstract": "In this paper, an overview of human\u2013robot interactive communication is presented, covering verbal as well as non-verbal aspects. Following a historical introduction, and motivation towards fluid human\u2013robot communication, ten desiderata are proposed, which provide an organizational axis both of recent as well as of future research on human\u2013robot communication. Then, the ten desiderata are examined in detail, culminating in a unifying discussion, and a forward-looking conclusion.\n               \n            \n\nWhile the first modern-day industrial robot, Unimate, began work on the General Motors assembly line in 1961, and was conceived in 1954 by George Devol\u00a0 [1,2], the concept of a robot has a very long history, starting in mythology and folklore, and the first mechanical predecessors (automata) having been constructed in Ancient Times. For example, in Greek mythology, the God Hephaestus is reputed to have made mechanical servants from gold ([3] in p. 114, and\u00a0 [4] verse 18.419). Furthermore, a rich tradition of designing and building mechanical, pneumatic or hydraulic automata also exists: from the automata of Ancient Egyptian temples, to the mechanical pigeon of the Pythagorean Archytas of Tarantum circa 400 BC\u00a0 [5], to the accounts of earlier automata found in the Lie Zi text in China in 300 BC\u00a0 [6], to the devices of Heron of Alexandria\u00a0 [7] in the 1st century. The Islamic world also plays an important role in the development of automata; Al-Jazari, an Arab inventor, designed and constructed numerous automatic machines, and is even reputed to have devised the first programmable humanoid robot in 1206 AD\u00a0 [8]. The word \u201crobot\u201d, a Slavic word meaning servitude, was first used in this context by the Czech author Karel Capek in 1921\u00a0 [9].\n\nHowever, regarding robots with natural-language conversational abilities, it was not until the 1990s that the first pioneering systems started to appear. Despite the long history of mythology and automata, and the fact that even the mythological handmaidens of Hephaestus were reputed to have been given a voice\u00a0 [3], and despite the fact that the first general-purpose electronic speech synthesizer was developed by Noriko Omeda in Japan in 1968\u00a0 [10], it was not until the early 1990s that conversational robots such as MAIA\u00a0 [11], RHINO\u00a0 [12], and AESOP\u00a0 [13] appeared. These robots cover a range of intended application domains; for example, MAIA was intended to carry objects and deliver them, while RHINO is a museum guide robot, and AESOP a surgical robot.\n\nIn more detail, the early systems include Polly, a robotic guide that could give tours in offices\u00a0 [14,15]. Polly had very simple interaction capacities; it could perceive human feet waving a \u201ctour wanted\u201d signal, and then it would just use pre-determined phrases during the tour itself. A slightly more advanced system was TJ\u00a0 [16]. TJ could verbally respond to simple commands, such as \u201cgo left\u201d, albeit through a keyboard. RHINO, on the other hand\u00a0 [12], could respond to tour-start commands, but then, again, just offered a pre-programmed tour with fixed programmer-defined verbal descriptions. Regarding mobile assistant robots with conversational capabilities in the 1990s, a classic system is MAIA\u00a0 [11,17], obeying simple commands, and carrying objects around places, as well as the mobile office assistant which could not only deliver parcels but also guide visitors described in\u00a0 [18], and the similar in functionality Japanese-language robot Jijo-2\u00a0 [19\u201321]. Finally, an important book from the period is\u00a0 [22], which is characteristic of the traditional natural-language semantics-inspired theoretical approaches to the problem of human\u2013robot communication, and also of the great gap between the theoretical proposals and the actual implemented systems of this early decade.\n\nWhat is common to all the above early systems is that they share a number of limitations. First, all of them only accept a fixed and small number of simple canned commands, and they respond with a set of canned answers. Second, the only speech acts (in the sense of Searle\u00a0 [23]) that they can handle are requests. Third, the dialogue they support is clearly not flexibly mixed initiative; in most cases it is just human-initiative. Four, they do not really support situated language, i.e.\u00a0language about their physical situations and events that are happening around them; except for a fixed number of canned location names in a few cases. Five, they are not able to handle affective speech; i.e.\u00a0emotion-carrying prosody is neither recognized nor generated. Six, their non-verbal communication \u00a0 [24] capabilities are almost non-existent; for example, gestures, gait, facial expressions, and head nods are neither recognized nor produced. And seventh, their dialogue systems are usually effectively stimulus\u2013response or stimulus-state-response systems; i.e.\u00a0no real speech planning or purposeful dialogue generation is taking place, and certainly not in conjunction with the motor planning subsystems of the robot. Last but quite importantly, no real learning, off-line or on-the-fly is taking place in these systems; verbal behaviours have to be prescribed.\n\nAll of these shortcomings of the early systems of the 1990s, effectively have become desiderata for the next two decades of research: the 2000s and 2010s, which we are in at the moment. Thus, in this paper, we will start by providing a discussion giving motivation to the need for existence of interactive robots with natural human\u2013robot communication capabilities, and then we will enlist a number of desiderata for such systems, which have also effectively become areas of active research in the last decade. Then, we will examine these desiderata one by one, and discuss the research that has taken place towards their fulfilment. Special consideration will be given to the so-called \u201csymbol grounding problem\u201d\u00a0 [25], which is central to most endeavours towards natural language communication with physically embodied agents, such as robots. Finally, after a discussion of the most important open problems for the future, we will provide a concise conclusion.\n\nThere are at least two avenues towards answering this fundamental question, and both will be attempted here. The first avenue will attempt to start from first principles and derive a rationale towards equipping robots with natural language. The second, more traditional and safe avenue, will start from a concrete, yet partially transient, base: application domains existing or potential. In more detail:\n\nTraditionally, there used to be a clear separation between design and deployment phases for robots. Application-specific robots (for example, manufacturing robots, such as\u00a0 [26]) were: (a) designed by expert designers, (b) possibly tailor-programmed and occasionally reprogrammed by specialist engineers at their installation site, and (c) interacted with their environment as well as with specialized operators during actual operation. However, not only the phenomenal simplicity but also the accompanying inflexibility and cost of this traditional setting is often changing nowadays. For example, one might want to have broader-domain and less application-specific robots, necessitating more generic designs, as well as less effort by the programmer-engineers on site, in order to cover the various contexts of operation. Even better, one might want to rely less on specialized operators, and to have robots interact and collaborate with non-expert humans with a little if any prior training. Ideally, even the actual traditional programming and re-programming might also be transferred over to non-expert humans; and instead of programming in a technical language, to be replaced by intuitive tuition by demonstration, imitation and explanation\u00a0 [27\u201329]. Learning by demonstration and imitation for robots already has quite some active research; but most examples only cover motor and aspects of learning, and language and communication is not involved deeply.\n\nAnd this is exactly where natural language and other forms of fluid and natural human\u2013robot communication enter the picture: Unspecialized non-expert humans are used to (and quite good at) teaching and interacting with other humans through a mixture of natural language as well as nonverbal signs. Thus, it makes sense to capitalize on this existing ability of non-expert humans by building robots that do not require humans to adapt to them in a special way, and which can fluidly collaborate with other humans, interacting with them and being taught by them in a natural manner, almost as if they were other humans themselves.\n\nThus, based on the above observations, the following is one classic line of motivation towards justifying efforts for equipping robots with natural language capabilities: why not build robots that can comprehend and generate human-like interactive behaviours, so that they can cooperate with and be taught by non-expert humans, so that they can be applied in a wide range of contexts with ease? And of course, as natural language plays a very important role within these behaviours, why not build robots that can fluidly converse with humans in natural language, also supporting crucial non-verbal communication aspects, in order to maximize communication effectiveness, and enable their quick and effective application?\n\nThus, having presented the classical line of reasoning arriving towards the utility of equipping robots with natural language capabilities, and having discussed a space of possibilities regarding role assignment between human and robot, let us now move to the second, more concrete, albeit less general avenue towards justifying conversational robots: namely, specific applications, existing or potential. Such applications, where natural human\u2013robot interaction capabilities with verbal and non-verbal aspects would be desirable, include: flexible manufacturing robots; lab or household robotic assistants\u00a0 [30\u201333]; assistive robotics and companions for special groups of people\u00a0 [34]; persuasive robotics (for example,\u00a0 [35,36]); robotic receptionists\u00a0 [37], robotic educational assistants, shopping mall robots\u00a0 [38], museum robots\u00a0 [39,40], tour guides\u00a0 [41,42], environmental monitoring robots\u00a0 [43], robotic wheelchairs\u00a0 [44,45], companion robots\u00a0 [46], social drink-serving robots\u00a0 [47], all the way to more exotic domains, such as robotic theatre actors\u00a0 [48,49], musicians\u00a0 [50], and dancers\u00a0 [51].\n\nIn almost all of the above applications, although there is quite some variation regarding requirements, one aspect at least is shared: the desirability of natural fluid interaction with humans supporting natural language and non-verbal communication, possibly augmented with other means. Of course, although this might be desired, it is not always justified as the optimum choice, given techno-economic constraints of every specific application setting. A thorough analysis of such constraints together with a set of guidelines for deciding when natural-language interaction is justified, can be found in\u00a0 [52].\n\nNow, having examined justifications towards the need for natural language and other human-like communication capabilities in robots across two avenues, let us proceed and become more specific: natural language, indeed but what capabilities do we actually need?\n\nAn initial list of desiderata is presented below, which is neither totally exhaustive nor absolutely orthogonal; however, it serves as a good starting point for discussing the state of the art, as well as the potentials of each of the items: \n                        \n                           (D1)\n                           Breaking the \u201csimple commands only\u201d barrier.\n\nMultiple speech acts.\n\nMixed initiative dialogue.\n\nSituated language and the symbol grounding problem.\n\nAffective interaction.\n\nMotor correlates and Non-Verbal Communication.\n\nPurposeful speech and planning.\n\nMulti-level learning.\n\nUtilization of online resources and services.\n\nMiscellaneous abilities.\n\nThe particular order of the sequence of desiderata, was chosen for the purpose of illustration, as it provides partially for a building-up of key points, also allowing for some tangential deviations. Not all desiderata are necessarily of equal difficulty, and arguably D1, D3\u20134, and D7\u20138 have so far proven to be particularly hard. One of the main reasons underlying this situation has to do with the divide between the two worlds that interactive robots usually live in: the symbolic/discrete world of logical representations and language on the one hand, and the continuous and noisy world of sensorymotor data on the other. And it is not only the uncertainty that arises from the unreliability of the sensorymotor end that contributes to the difficulties, but also the fact that sensor data tends to be structured in ways that are not easily alignable to the requirements of symbolic representations, as we shall see. Let us now proceed and examine the desiderata in detail one by one:\n\nThe traditional conception of conversational robots, as well as most early systems, is based on a clear human-master robot-servant role assignment, and restricts the robots conversational competencies to simple \u201cmotor command requests\u201d only in most cases. For example, in systems such as [30,53], a typical dialogue might be: \n                           \n                              H:\n                              \u201cGive me the red one\u201d.\n\n(Picks up the red ball, and gives to human.)\n\n\u201cGive me the green one\u201d.\n\n\u201cDo you mean this one, or that one?\u201d (robot points to two possible candidate objects).\n\n\u201cThe one on the left\u201d.\n\n(Picks up the green ball on the left, and hands over to human.)\n\nWhat are the main points noticed in this example? Well, first of all, (p1) this is primarily a single-initiative dialogue: the human drives the conversation, the robot effectively just produces motor and verbal responses to the human verbal stimulus. Second, (p2) apart from some disambiguating questions accompanied by deixis, there is not much that the robot says the robot primarily responds with motor actions to the human requests, and does not speak. And, (p3) regarding the human statements, we only have one type of speech acts\u00a0 [23]: RequestForMotorAction. Furthermore, (p4) usually such systems are quite inflexible regarding multiple surface realizations of the acceptable commands; i.e.\u00a0the human is allowed to say \u201cGive me the red one\u201d, but if he instead used the elliptical \u201cthe red object, please\u201d he might have been misinterpreted and (p5) in most cases, the mapping of words-to-responses is arbitrarily chosen by the designer; i.e.\u00a0motor verbs translate to what the designer thinks they should mean for the robot (normative meaning), instead of what an empirical investigation would show regarding what other humans would expect they mean (empirical meaning).\n\nHistorically, advanced theorization for such systems exists as early as\u00a0 [22]. Actually, if one extends from physical robots to systems comprising a virtual robot in a virtual world, Winograds SHRDLU program\u00a0 [54,55] from the early seventies could already support multiple speech acts and basic mixed initiative dialogue. There is still quite a stream of active research which, although based on beautiful and systematic formalizations and eloquent grammars, basically produces systems which would still fall within the three points mentioned above. Such an example is\u00a0 [56], in which a mobile robot in a multi-room environment, can handle commands such as: \u201cGo to the breakroom and report the location of the blue box\u201d.\n\nNotice that here we are not claiming that there is no importance in this research that falls within this strand; we are just mentioning that, as we shall see, there are many other aspects of natural language and robots, which are left unaccounted by such systems. Furthermore, it remains to be seen, how many of these aspects can later be effectively integrated with systems belonging to this strand of research.\n\nThe limitations (p1)\u2013(p5) cited above for the classic \u201csimple commands only\u201d systems provide useful departure points for extensions. Speech act theory was introduced by J.L. Austin\u00a0 [57], and a speech act is usually defined as an utterance that has performative function in language and communication. Thus, we are focusing on the function and purpose of the utterance, instead of the content and form. Several taxonomies of utterances can be derived according to such a viewpoint: for example, Searle\u00a0 [58], proposed a classification of illocutionary speech acts into assertives, directives, commisives, expressives, and declarations. Computational models of speech acts have been proposed for use in human\u2013computer interaction\u00a0 [59].\n\nIn the light of speech acts, lets us start by extending upon point (p3) made in the previous section. In the short human\u2013robot dialogue presented in the previous section, the human utterances \u201cGive me the red one\u201d and \u201cGive me the green one\u201d could be classified as Request speech acts, and more specifically requests for motor action (one could also have requests for information, such as \u201cWhat colour is the object?\u201d). But what else might one desire in terms of speech act handling capabilities, apart from RequestForMotorAction (which we shall call SA1, a Directive according to\u00a0 [58])? Some possibilities follow below:\n                           \n                              H:\n                              \u201cHow big is the green one?\u201d (RequestForInformAct, SA2, Directive).\n\n\u201cThere is a red object at the left\u201d (Inform, SA3, Assertive).\n\n\u201cLet us call the small doll Daisy\u201d (Declare, SA4, Declaration).\n\nAnd many more exist. Systems such as\u00a0 [53] are able to handle SA2 and SA3 apart from SA1-type acts; and one should also notice, that there are many classificatory systems for speech acts, across different axes of classification, and with multiple granularities. Also, it is worth starting at this stage to contemplate upon what might it mean to respond appropriately to different kinds of speech acts. For example, an appropriate response to a RequestForMotorAction (a Directive) is the motor action itself, if unambiguous and feasible; however, an appropriate response to an Assertive or a Declarative consists of a change to some form of a \u201cmental model\u201d\u00a0 [60] or \u201csituation model\u201d\u00a0 [61,53] that the robot might be keeping; i.e.\u00a0creating an appropriate mental token for an object in the case of \u201cThere is a red object at the left\u201d, or changing the name label for a mental object token in the case of \u201cLet us call this small doll Daisy\u201d; i.e.\u00a0both statements elicit primarily internal (mental) actions, instead of external (motor or verbal) actions.\n\nAnother relevant aspect of speech act theory is the handling of indirect speech acts. For example, consider the following utterance: \n                           \n                              H:\n                              \u201cAh, it is quite hot in this room\u201d (phenomenally, an Assertive),\n\nwhich might actually be a polite way of saying:\n\n\u201cOpen the window\u201d (essentially, a Directive).\n\nThis substitution of an Assertive for an implied Directive (to be inferred by the listener) is a classic example of an indirect speech act. Usually, the analysis of such acts is based on the Gricean maxims of conversation\u00a0 [62]; and numerous computational implementations for handling such indirect speech acts have been proposed, such as\u00a0 [63].\n\nFinally, yet another problem related to speech acts, is the issue of their classification from the robot, after hearing them. Classic techniques such as those described in\u00a0 [64] rely on linguistic information only; however, paralinguistic information (such as prosodic features) can also prove useful towards speech act classification; the interested reader is referred for example to\u00a0 [65].\n\nNow, starting again from the shortcoming of the traditional \u201csimple commands-only\u201d systems, let us extend across another axis, namely (p1): human-initiative dialogue is not the only option; one could also have robot-initiative, or ideally, full mixed-initiative. Consider FaceBots\u00a0 [66,67], a conversational robot utilizing facebook-derived information. A typical dialogue might include turns such as:\n                           \n                              R:\n                              \u201cHello! Are you Noura Dhaheri?\u201d\n\n\u201cYes\u201d.\n\n\u201cHello Noura! Are you doing well today?\u201d\n\n\u201cPretty well!\u201d\n\n\u201cGreat! Do you know that our friend Wajahat Kazmi has posted a new photo?\u201d\n\n\u201cNo!\u201d\n\n\u201cWell, I am sending you an inbox message for this, check it out!\u201d\n\nThis is a classic example of robot-initiative dialogue, and actually with very simple responses expected from the human mainly Yes or No. On the other hand, consider a dialogue such as (from the robot BIRON at Bielefeld, dialogue in\u00a0 [68]), which is an example of a dialogue with limited mixed initiative:\n                           \n                              R:\n                              \u201cHello Human!\u201d\n\n\u201cHello! Who are you?\u201d\n\n\u201cMy name is BIRON, if you show me something I can remember it\u201d.\n\n\u201cOK, um, look, this is a mug\u201d.\n\n\u201cI beg your pardon?\u201d\n\n\u201cThis is a mug, umm, here\u201d.\n\n\u201cSorry, can you use some other words?\u201d\n\n\u201cThis is a mug!\u201d\n\n\u201cSorry, I cannot find it. Are you pointing to it with your finger?\u201d\n\n\u201cYes!\u201d\n\n\u201cI know it is sometimes difficult with me, but dont feel discouraged!\u201d\n\n(laugh).\n\n\u201cOK, I have found it, it is really nice!\u201d\n\nHere, it is neither the robot nor the human driving the dialogue all of the time; for example, the opening pair, R\u2013H is robot-initiative (R: \u201cHello Human!\u201d H: \u201cHello!\u201d). However, directly afterwards, the second half of H together with R creates a second pair of exchanges, which is human-initiative (H: \u201cWho are you?\u201d, R: \u201cMy names is BIRON\u2026\u201d). And thus the initiative can be reversed in multiple points throughout the dialogue.\n\nFor an investigation of the state of the art towards mixed initiative, the interested reader is referred to examples such as the Karlsruhe Humanoid\u00a0 [69] the Biron and Barthoc systems at Bielefeld\u00a0 [68], and also workshops such as\u00a0 [70].\n\nYet another observation regarding shortcomings of the traditional command-only systems that are worth extending from, was point (p5) that was mentioned above: the meanings of the utterances were normatively decided by the designer, and not based on empirical observations. For example, a designer/coder could normatively pre-define the semantics of the colour descriptor \u201cred\u201d as belonging to the range between two specific given values. Alternatively, one could empirically get a model of the applicability of the descriptor \u201cred\u201d based on actual human usage; by observing the human usage of the word in conjunction with the actual apparent colour wavelength and the context of the situation. Furthermore, the actual vocabularies (red, \u201cpink\u201d, etc.) or the classes of multiple surface realizations (p4) (quasi-synonyms or semantically equivalent parts of utterances, for example: \u201cgive me the red object\u201d, \u201chand me the red ball\u201d), are usually hand-crafted in such systems, and again not based on systematic human observation or experiment.\n\nThere are a number of notable exceptions to this rule, and there is a growing tendency to indeed overcome these two limitations recently. For example, consider\u00a0 [71], during which a wizard-of-oz experiment provided the collection of vocabulary from users desiring to verbally interact with a robotic arm, and examples such as\u00a0 [44], for which the actual context-depending action models corresponding to simple verbal commands like \u201cgo left\u201d or \u201cgo right\u201d (which might have quite different expected actions, depending on the surrounding environment) were learnt empirically through human experiments.\n\nEmbarking upon this avenue of thought, it slowly becomes apparent that the connection between local environment (and more generally, situational context) and procedural semantics of an utterance is quite crucial. Thus, when dealing with robots and language, it is impossible to isolate the linguistic subsystems from perception and action, and just plug-and-play with a simple speech-in speech-out black box chatterbot of some sort (such as the celebrated ELIZA\u00a0 [72] or even the more recent victors of the Loebner Prize\u00a0 [73]). Simply put, in such systems, there is no connection of what is being heard or said to what the robot senses and what the robot does. This is quite a crucial point; there is a fundamental need for closer integration of language with sensing, action, and purpose in conversational robots\u00a0 [30,53], as we shall also see in the next sections.\n\nUpon discussing the connection of language to the physical context, another important concept becomes relevant: situated language, and especially the language that children primarily use during their early years; i.e.\u00a0language that is not abstract or about past or imagined events; but rather concrete, and about the physical here-and-now. But what is the relevance of this observation to conversational robots? One possibility is the following; given that there seems to be a progression of increasing complexity regarding human linguistic development, often in parallel to a progression of cognitive abilities, it seems reasonable to: first partially mimic the human developmental pathway, and thus start by building robots that can handle such situated language, before moving on to a wider spectrum of linguistic abilities. This is for example the approach taken at\u00a0 [53].\n\nChoosing situated language as a starting point also creates a suitable entry point for discussing language grounding in the next section. Now, another question that naturally follows is: could one postulate a number of levels of extensions from language about the concrete here-and-now to wider domains? This is attempted in\u00a0 [53], and the levels of increasing detachment from the \u201chere-and-now\u201d postulated there are:\n\nFirst level: limited only to the \u201chere-and-now, existing concrete things\u201d. Words connect to things directly accessible to the senses at the present moment. If there is a chair behind me, although I might have seen it before, I cannot talk about it\u2014\u201cout of sight\u201d means \u201cnon-existing\u201d in this case. For example, such a robotic system is\u00a0 [74].\n\nSecond level: (\u201cnow, existing concrete things\u201d); we can talk about the \u201cnow\u201d, but we are not necessarily limited to the \u201chere\u201d\u2014where here means currently accessible to the senses. We can talk about things that have come to our senses previously, that we conjecture still exist through some form of psychological \u201cobject permanence\u201d\u00a0 [75]\u2014i.e.,\u00a0we are keeping some primitive \u201cmental map\u201d of the environment. For example, this was the state of the robot Ripley during\u00a0 [76].\n\nThird level: (\u201cpast or present, existing concrete things\u201d), we are also dropping the requirement of the \u201cnow\u201d\u2014in this case, we also possess some form of episodic memory\u00a0 [77] enabling us to talk about past states. An example robot implementation can be found in\u00a0 [78].\n\nFourth level: (\u201cimagined or predicted concrete things\u201d); we are dropping the requirement of actual past or present existence, and we can talk about things with the possibility of actual existence\u2014either predicted (connectible to the present) or imagined\u00a0 [53].\n\nFifth level: (\u201cabstract things\u201d) we are not talking about potentially existing concrete things any more, but about entities that are abstract. But what is the criterion of \u201cconcreteness?\u201d A rough possibility is the following: a concrete thing is a first-order entity (one that is directly connected to the senses); an \u201cabstract\u201d thing is built upon first order entities, and does not connect directly to the senses, as it deals with relationships between them. Take, for example, the concept of the \u201cnumber three\u201d: it can be found in an auditory example (\u201cthreeness\u201d in the sound of three consecutive ticks); it can also be found in a visual example (\u201cthreeness\u201d in the snapshot of three birds sitting on a wire). Thus, threeness seems to be an abstract thing (not directly connected to the senses).\n\nCurrently, there exist robots and methodologies\u00a0 [53] that can create systems handling basic language corresponding to the first four stages of detachment from situatedness; however, the fifth seems to still be out of reach. If what we are aiming towards is a robot with a deeper understanding of the meaning of words referring to abstract concepts, although related work on computational analogy making (such as\u00a0 [79]), could prove to provide some starting points for extensions towards such domains, we are still beyond the current state-of-the-art.\n\nNevertheless, there are two interesting points that have arisen in the previous sections: first, that when discussing natural language and robots, there is a need to connect language not only to sensory data, but also to internalized \u201cmental models\u201d of the world in order for example to deal with detachment from the immediate \u201chere-and-now\u201d. And second, that one needs to consider not only phonological and syntactical levels of language but also questions of semantics and meaning; and pose the question: \u201cwhat does it mean for a robot to understand a word that it hears or utters?\u201d And also, more practically: what are viable computational models of the meaning of words, suitable to embodied conversational robots? We will try to tackle these questions right now, in the next subsection.\n\nOne of the main philosophical problems that arises when trying to create embodied conversational robots is the so-called \u201csymbol grounding problem\u201d\u00a0 [25]. In simple terms, the problem is the following: imagine a robot, having an apple in front of it, and hearing the word \u201capple\u201d a verbal label which is a conventional sign (in semiotic terms\u00a0 [80,81]), and which is represented by a symbol within the robots cognitive system. Now this sign is not irrelevant to the actual physical situation; the human that uttered the word \u201capple\u201d was using it to refer to the physical apple that is in front of the robot. Now the problem that arises is the following: how can we connect the symbol standing for \u201capple\u201d in the robots cognitive system, with the physical apple that it refers to? Or, in other words, how can we ground out the meaning of the symbol to the world? In simple terms, this is an example of the symbol grounding problem. Of course, it extends not only to objects signified by nouns, but to properties, relations, events, etc., and there are many other extensions and variations of it.\n\nSo, what are solutions relevant to the problem? In the case of embodied robots, the connection between the internal cognitive system of the robot (where the sign is) and the external world (where the referent is) is mediated through the sensory system, for this simple case described above. Thus, in order to ground out the meaning, one needs to connect the symbol to the sensory data say, to vision. Which is at least, to find a mechanism through which, achieves the following bidirectional connection: first, when an apple appears in the visual stream, instantiates an apple symbol in the cognitive system (which can later for example trigger the production of the word \u201capple\u201d by the robot), and second, when an apple symbol is instantiated in the cognitive system (for example, because the robot heard that \u201cthere is an apple\u201d), creates an expectation regarding the contents of the sensory stream given that an apple is reported to be present. This bidirectional connection can be succinctly summarized as:\n                              \n                                 \n                                    \n                                       external\u00a0referent\n                                       >\n                                       sensory\u00a0stream\n                                       >\n                                       internal\u00a0symbol\n                                       >\n                                       produced\u00a0utterance\n                                    \n                                 \n                                 \n                                    \n                                       external\u00a0referent\n                                       <\n                                       sensory\u00a0expectation\n                                       <\n                                       internal\u00a0symbol\n                                       <\n                                       heard\u00a0utterance\u00a0.\n                                    \n                                 \n                              \n                           \n                        \n\nThis bidirectional connection we will refer to as \u201cfull grounding\u201d, while its first unidirectional part as \u201chalf grounding\u201d. Some notable papers presenting computational solutions of the symbol grounding problem for the case of robots are: half-grounding of colour and shapes for the Toco robot\u00a0 [74], and full-grounding of multiple properties for the Ripley robot\u00a0 [30]. Highly relevant work includes:\u00a0 [82] and also Steels\u00a0 [83\u201385], and also\u00a0 [86] from a child lexical perspective.\n\nThe case of grounding of spatial relations (such as \u201cto the left of\u201d, and \u201cinside\u201d) reserves special attention, as it is a significant field on its own. A classic paper is\u00a0 [87], presenting an empirical study modelling the effect of central and proximal distance on 2D spatial relations; regarding the generation and interpretation of referring expressions on the basis of landmarks for a simple rectangle world, there is\u00a0 [88], while the book by\u00a0 [89] extends well into illustrating the inadequacy of geometrical models and the need for functional models when grounding terms such as \u201cinside\u201d, and covers a range of relevant interesting subjects. Furthermore, regarding the grounding of attachment and support relations in videos, there is the classic work by\u00a0 [90]. For an overview of recent spatial semantics research, the interested reader is referred to\u00a0 [91], and a sampler of important current work in robotics includes\u00a0 [92\u201394], and the most recent work of Tellex on grounding with probabilistic graphical models\u00a0 [95], and for learning word meanings from unaligned parallel data\u00a0 [96].\n\nFinally, an interesting question arises when trying to ground out personal pronouns, such as \u201cme, my, you, your\u201d. Regarding their use as modifiers of spatial terms (\u201cmy left\u201d), relevant work on a real robot is\u00a0 [76], and regarding more general models of their meaning, the reader is referred to\u00a0 [97], where a system learns the semantics of the pronouns through examples.\n\nA number of papers have recently also appeared claiming to have provided a solution to the \u201csymbol grounding problem\u201d, such as\u00a0 [98]. There is a variety of different opinions regarding what an adequate solution should accomplish, though. A stream of work around an approach dealing with the evolution of language and semiotics, is outlined in\u00a0 [99]. From a more applied and practical point of view though, one would like to be able to have grounded ontologies\u00a0 [100,101] or even robot-useable lexica augmented with computational models providing such grounding: and this is the ultimate goal of the EU projects POETICON\u00a0 [102,103], and the follow-up project POETICON II.\n\nAnother important aspect regarding grounding is the set of qualitatively different possible target meaning spaces for a concept. For example,\u00a0 [53] proposes three different types of meaning spaces: sensory, sensorymotor, and teleological. A number of other proposals exist for meaning spaces in cognitive science, but not directly related to grounding; for example, the geometrical spaces proposal of Gardenfors\u00a0 [104]. Furthermore, any long-ranging agenda towards extending symbol grounding to an ever-increasing range of concepts, needs to address yet another important point: semantic composition, i.e.\u00a0for a very simple example, consider how a robot could combine a model of \u201cred\u201d with a model of \u201cdark\u201d in order to derive a model of \u201cdark red\u201d. Although this is a fundamental issue, as discussed in\u00a0 [53], it has yet to be addressed properly.\n\nLast but not least, regarding the real-world acquisition of large-scale models of grounding in practice, special data-driven models are required, and the quantities of empirical data required would make collection of such data from non-experts (ideally online) highly desirable. Towards that direction, there exists the pioneering work of Gorniak\u00a0 [85] where a specially modified computer game allowed the collection of referential and functional models of meaning of the utterances used by the human players. This was followed up by\u00a0 [105\u2013107], in which specially designed online games allowed the acquisition of scripts for situationally appropriate dialogue production. These experiments can be seen as a special form of crowdsourcing, building upon the ideas started by pioneering systems such as Luis Von Ahns peekaboom game\u00a0 [108], but especially targeting the situated dialogic capabilities of embodied agents. Much more remains to be done in this promising direction in the future.\n\nHaving introduced the concept of non-logic-like grounded models of meaning, another interesting complication arises. Given that different conversational partners might have different models of meaning, say for the lexical semantics of a colour term such as \u201cpink\u201d, how is communication possible? A short, yet minimally informative answer, would be: given enough overlap of the particular models, there should be enough shared meaning for communication. But if one examines a number of typical cases of misalignment across models, he will soon reach to the realization that models of meaning, or even second-level models (beliefs about the models that others hold), are very often being negotiated and adjusted online, during a conversation. For example:\n\n(Turquoise object on robot table, in front of human and robot) \n                              \n                                 H:\n                                 \u201cGive me the blue object!\u201d\n\n\u201cNo such object exists\u201d.\n\n\u201cGive me the blue one!\u201d\n\n\u201cNo such object exists\u201d.\n\nBut why is this surreal human\u2013robot dialogue taking place, and why it would not have taken place for the case of two humans in a similar setting? Let us analyse the situation. The object on the table is turquoise, a colour which some people might classify as \u201cblue\u201d, and others as \u201cgreen\u201d. The robots colour classifier has learnt to treat turquoise as green; the human classifies the object as \u201cblue\u201d. Thus, we have a categorical misalignment error, as defined in\u00a0 [53]. For the case of two humans interacting instead of a human and a robot, given the non-existence of another unique referent satisfying the \u201cblue object\u201d description, the second human would have readily assumed that most probably the first human is classifying turquoise as \u201cblue\u201d; and, thus, he would have temporarily adjusted his model of meaning for \u201cblue\u201d in order to be able to include turquoise as \u201cblue\u201d, and thus to align his communication with his conversational partner. Thus, ideally we would like to have conversational robots that can gracefully recover from such situations, and fluidly negotiate their models of meaning online, in order to be able to account for such situations. Once again, this is a yet unexplored, yet crucial and highly promising avenue for future research.\n\nAn important dimension of cognition is the affective/emotional. In the german psychological tradition of the 18th century, the affective was part of the tripartite classification of mental activities into cognition, affection, and conation; and apart from the widespread use of the term, the influence of the tri-partite division extended well into the 20th century\u00a0 [109].\n\nThe affective dimension is very important in human interaction\u00a0 [110], because it is strongly intertwined with learning\u00a0 [111], persuasion\u00a0 [112], and empathy, among many other functions. Thus, it carries over its high significance for the case of human\u2013robot interaction. For the case of speech, affect is marked both in the semantic/pragmatic content as well as in the prosody of speech: and thus both of these ideally need to be covered for effective human\u2013robot interaction, and also from both the generation as well as recognition perspectives. Furthermore, other affective markers include facial expressions, body posture and gait, as well as markers more directly linked to physiology, such as heart rate, breathing rate, and galvanic skin response.\n\nPioneering work towards affective human\u2013robot interaction includes\u00a0 [113] where, extending upon analogous research from virtual avatars such as Rea\u00a0 [114], Steve\u00a0 [115], and Greta\u00a0 [116], Cynthia Breazeal presents an interactive emotion and drive system for the Kismet robot\u00a0 [117], which is capable of multiple facial expressions. An interesting cross-linguistic emotional speech corpus arising from children\u2019s interactions with the Sony AIBO robot is presented in\u00a0 [118]. Another example of preliminary work based on a Wizard-of-Oz approach, this time regarding children\u2019s interactions with the ATR Robovie robot in Japan, is presented in\u00a0 [119]. In this paper, automatic recognition of embarrassment or pleasure of the children is demonstrated. Regarding interactive affective storytelling with robots with generation and recognition of facial expressions,\u00a0 [120] present a promising starting point. Recognition of human facial expressions is accomplished through SHORE\u00a0 [121], as well as the Seeing Machines product FaceAPI. Other available facial expression recognition systems include\u00a0 [122], which has also been used as an aid for autistic children, as well as\u00a0 [123,124], where the output of the system is at the level of facial action coding (FACS). Regarding generation of facial expressions for robots, some examples of current research include\u00a0 [125\u2013127]. Apart from static poses, the dynamics of facial expressions is also very important towards conveying believability; for empirical research on dynamics see for example\u00a0 [128]. Still, compared to the wealth of available research on the same subject with virtual avatars, there is still a lag both in empirical evaluations of human\u2013robot affective interaction, as well as in importing existing tools from avatar animation towards their use for robots.\n\nRegarding some basic supporting technologies of affect-enabled text-to-speech and speech recognition, the interested reader can refer to the general reviews by Schroeder\u00a0 [129] on TTS, and by Ververidis and Kotropoulos\u00a0 [130] on recognition. A wealth of other papers on the subject exist; with some notable developments for affective speech-enabled real-world robotic systems including\u00a0 [131,132]. Furthermore, if one moves beyond prosodic affect, to semantic content, the wide literature on sentiment analysis and shallow identification of affect applies directly; for example\u00a0 [133\u2013135]. Regarding physiological measurables, products such as Affectivas \n                           Q\n                         sensor\u00a0 [136], or techniques for measuring heart rate, breathing rate, galvanic skin response and more, could well become applicable to the human\u2013robot affective interaction domain, of course under the caveats of\u00a0 [137]. Yet another important question for which still many aspects remain unanswered, is concerned with conveying emotions for the case of robotic embodiments which are not anthropomorphic and do not support speech, an initial investigation of which is presented in\u00a0 [138,139], and an example empirical study for the case of the emotions conveyed by a UAV can be found in\u00a0 [140]. Also, another interesting option is concerned with utilizing non-linguistic utterances (NLU) for conveying emotion, i.e.\u00a0non-verbal sounds, as is done in\u00a0 [141], which are interpreted categorically\u00a0 [142]. Finally, it is worth noting that significant cross-culture variation exists regarding affect; both at the generation, as well as at the understanding and situational appropriateness levels\u00a0 [143]. In general, affective human\u2013robot interaction is a growing field with promising results, which is expected to grow even more in the near future.\n\nVerbal communication in humans does not come isolated from non-verbal signs; in order to achieve even the most basic degree of naturalness, any humanoid robot needs for example at least some lip-movement-like feature to accompany speech production. Apart from lip-syncing, many other human motor actions are intertwined with speech and natural language; for example, head nods, deictic gestures, gaze movements, etc. Also, note that the term correlates is somewhat misleading; for example, the gesture channel can be more accurately described as being a complementary channel rather than a channel correlated with or just accompanying speech\u00a0 [144]. Furthermore, we are not interested only in the generation of such actions; but also on their combination, as well as on dialogic/interactional aspects.\n\nLet us start by examining the generation of lip syncing. The first question that arises is: should lip sync actions be generated from phoneme-level information, or is the speech soundtrack adequate? Simpler techniques, rely on the speech soundtrack only; the simplest solution being to utilize only the loudness of the soundtrack, and map directly from loudness to mouth opening. There are many shortcomings in this approach; for example, a nasal \u201cm\u201d usually has large apparent loudness, although in humans it is being produced with a closed mouth. Generally, the resulting lip movements of this method are perceivable unnatural. As an improvement to the above method, one can try to use spectrum matching of the soundtrack to a set of reference sounds, such as at\u00a0 [145,146], or even better, a linear prediction speech model, such as\u00a0 [147]. Furthermore, apart from the generation of lip movements, their recognition can be quite useful regarding the improvement of speech recognition performance under low signal-to-noise ratio conditions\u00a0 [148]. There is also ample evidence that humans utilize lip information during recognition; a celebrated example is the McGurk effect\u00a0 [149]. The McGurk effect is an instance of so-called multi-sensory perception phenomena\u00a0 [150], which also include other interesting cases such as the rubber hand illusion\u00a0 [151].\n\nYet another important aspect of communication that requires non-verbal elements is backchannel signalling, primarily accomplished through head nods that the listener provides as feedback to the speaker while listening, in order to for example signal acknowledgement of understanding and continued attention, so that the speaker can continue to provide more verbal input to the listener. An example of a study on backchannel head nods for the case of human\u2013robot communication is given in\u00a0 [152].\n\nNow, let us move on to gestures. The simplest form of gestures which are also directly relevant to natural language are deictic gestures, pointing towards an object and usually accompanied with indexicals such as \u201cthis one!\u201d. Such gestures have long been utilized in human\u2013robot interaction; starting from virtual avatar systems such as Kris Thorissons Gandalf\u00a0 [153], and continuing all the way to robots such as ACE (Autonomous City Explorer)\u00a0 [154], a robot that was able to navigate through Munich by asking pedestrians for directions. There exist quite a number of other types of gestures, depending on the taxonomy one adopts; such as iconic gestures, symbolic gestures, etc. Furthermore, gestures are highly important towards teaching and learning in humans\u00a0 [155]. Apart from McNeills seminal psychological work\u00a0 [144], a definitive reference to gestures, communication, and their relation to language, albeit regarding virtual avatar Embodied Conversational Assistants (ECA), can be found in the work of Justine Cassell, including\u00a0 [156,157]. Many open questions exist in this area; for example, regarding the synchronization between speech and the different non-verbal cues\u00a0 [158], and socio-pragmatic influences on the non-verbal repertoire.\n\nAnother important topic for human\u2013robot interaction is eye gaze coordination and shared attention. Eye gaze cues are important for coordinating collaborative tasks\u00a0 [159,160], and also, eye gazes are an important subset of non-verbal communication cues that can increase efficiency and robustness in human\u2013robot teamwork\u00a0 [161]. Furthermore, in the tour guide setting of\u00a0 [42] a robot that engages visitors in mutual gaze is seen as more humanlike, and slight gaze preference biases towards one of the visitors can positively influence attitudes towards the robot. An attention control system for social robots that can adaptively attract and control a target persons attention is described in\u00a0 [162], extending from the work reported in\u00a0 [163]. The design of robot eyes in order to maximize suitability for gaze reading in investigated in\u00a0 [164]. Also, it is worth noting that gaze plays a significant role in tasks such as robot-to-human handovers\u00a0 [165,166].\n\nFurthermore, eye gaze is very important in disambiguating referring expressions, without the need for hand deixis\u00a0 [167,168], and in shaping participant roles in conversation\u00a0 [169]. Shared attention mechanisms develop in humans during infancy\u00a0 [170], and Scasellati authored the pioneering work on shared attention in robots in 1996\u00a0 [171], followed up by\u00a0 [172]. A developmental viewpoint is also taken in\u00a0 [173], as well as in\u00a0 [174]. A well-cited probabilistic model of gaze imitation and shared attention is given in\u00a0 [175], In virtual avatars, considerable work has also taken place; such as\u00a0 [176,177].\n\nEye-gaze observations are also very important towards mind reading and theory of mind\u00a0 [178] for robots; i.e.\u00a0being able to create models of the mental content and mental functions of other agents (human or robots) minds through observation. Children develop a progressively more complicated theory of mind during their childhood\u00a0 [179]. Elemental forms of theory of mind are very important also towards purposeful speech generation; for example, in creating referring expressions, one should ideally take into account the second-order beliefs of his conversational partner-listener; i.e.\u00a0he should use his beliefs regarding what he thinks the other person believes, in order to create a referring expression that can be resolved uniquely by his listener. Furthermore, when a robot is purposefully issuing an inform statement (\u201cthere is a tomato behind you\u201d) it should know that the human does not already know that; i.e.\u00a0again an estimated model of second-order beliefs is required (i.e.\u00a0what the robot believes the human believes). A pioneering work in theory of mind for robots is Scasellatis\u00a0 [180,181]. An early implementation of perspective-shifting synthetic-camera-driven second-order belief estimation for the Ripley robot is given in\u00a0 [53]. Another example of perspective shifting with geometric reasoning for the HRP-2 humanoid is given in\u00a0 [182].\n\nA major technoeconomic obstacle in the past decade regarding the widespread use of systems which can monitor and react to human gaze, and estimate human attention, has been the cost of precise wearable eye-tracking systems, and the need of placing artificial landmarks in the field of view in most of the traditional realizations of such systems. However, with recent developments, including the google glasses, the situation is rapidly changing. An innovative method for the estimation of human fixations in 3D environments that does not require artificial landmarks and enables attention mapping in 3D models with high precision, is presented in\u00a0 [183], which might well be promising to bring forth new opportunities for studies in joint attention as well as applications for human\u2013robot interaction.\n\nFinally, a quick note on a related field, which is recently growing. Children with Autistic Spectrum Disorders (ASD) face special communication challenges. A prominent theory regarding autism is hypothesizing theory-of-mind deficiencies for autistic individuals\u00a0 [184,185]. However, recent research\u00a0 [186\u2013189] has indicated that specially-designed robots that interact with autistic children could potentially help them towards improving their communication skills, and potentially transferring over these skills to communicating not only with robots, but also with other humans.\n\nYet another important observation to be made is concerned with the relation between the human\u2013human and human\u2013robot interactions. Models arising from observing human\u2013human interactions, can later be used as a basis in order to develop and further refine human\u2013robot interaction. An example of a study of human non-verbal behaviours during teaching, which was made with this purpose in mind, is given in\u00a0 [190]. Last but not least, regarding a wider overview of existing work on non-verbal communication between humans, which could readily provide ideas for future human\u2013robot experiments, the interested reader is referred to\u00a0 [24].\n\nTraditionally, simple command-only canned-response conversational robots had dialogue systems that could be construed as stimulus\u2013response tables: a set of verbs or command utterances were the stimuli, the responses being motor actions, with a fixed mapping between stimuli and responses. Even much more advanced systems, that can support situated language, multiple speech acts, and perspective-shifting theory-of-mind, such as Ripley\u00a0 [53], can be construed as effectively being (stimulus, state) to response maps, where the state of the system includes the contents of the situation model of the robots. What is missing in all of these systems is an explicit modelling of purposeful behaviour towards goals.\n\nSince the early days of AI, automated planning algorithms such as the classic STRIPS\u00a0 [191] and purposeful action selection techniques have been a core research topic. In traditional non-embodied dialogue systems practice, approaches such as Belief-Desire-Intention (BDI) have existed for a while\u00a0 [192], and theoretical models for purposeful generation of speech acts\u00a0 [193] and computation models towards speech planning exist since more than two decades. Also, in robotics, specialized modified planning algorithms have mainly been applied towards motor action planning and path planning\u00a0 [191], such as RRT\u00a0 [194] and Fast-Marching Squares\u00a0 [195].\n\nHowever, it is worth mentioning that the traditional approach towards planning and reasoning faces a very important problem when applied in real-world robots: a considerable amount of uncertainty exists, arising from the imperfections of the current state-of-the-art of speech and language processing as applied on robots, as well as from the multiple sources and often considerable variance of robot sensory-motor errors. Thus, special techniques are required, supporting graceful operation under considerable uncertainty: and one of the dominant mathematical approaches towards this problem involves Partially Observable Markov Decision Processes (POMDPs). Kaelbling, Littman, and Cassandra\u00a0 [196] for the case of robot planning, and Young\u00a0 [197] have proposed the usage of such POMPDP models. Also, methods for representation and reasoning with probabilistic knowledge, such as those described in\u00a0 [198], can play an important role towards dealing with uncertainty. Thus, such tools provide interesting avenues for wider application in real-world interactive robots, and show a highly promising direction for bridging the gap between symbolic representations and the noisy sensorymotor data of real-world robots.\n\nHowever, the important point to notice here is that, although considerable research exists for motor planning or dialogue planning alone, there are almost no systems and generic frameworks either for effectively combining the two, or for having mixed speech- and motor-act planning, or even better agent- and object-interaction-directed planners. Notice that motor planning and speech planning cannot be isolated from one another in real-world systems; both types of actions are often interchangeable with one another towards achieving goals, and thus should not be planned by separate subsystems which are independent of one another. For example, if a robot wants to lower its temperature, it could either say: can you kindly open the window? to a human partner (speech action), or could move its body, approach the window, and close it (motor action). An exemption to this research void of mixed speech-motor planning is\u00a0 [199], where a basic purposeful action selection system for question generation or active sensing act generation is described, and implemented on a real conversation robot. However, this is an early and quite task-specific system, and thus much more remains to be done towards real-world general mixed speech act and motor act action selection and planning for robots.\n\nYet another challenge towards fluid verbal and non-verbal human\u2013robot communication is concerned with learning\u00a0 [200]. But when could learning take place, and what could be and should be learnt? Let us start by examining the when. Data-driven learning can happen at various stages of the lifetime of a system: it could either take place (a) initially and offline, at design time; or, it could take place (b) during special learning sessions, where specific aspects and parameters of the system are renewed; or, (c) it could take place during normal operation of the system, in either a human-directed manner, or ideally (d) through robot-initiated active learning during normal operation. Most current systems that exhibit learning, are actually involving offline learning, i.e.\u00a0case (a) from above. No systems in the literature have exhibited non-trivial online, real-world continuous learning of communications abilities.\n\nThe second aspect beyond the when, is the what of learning. What could be ideally, what could be practically, and what should be learnt, instead of pre-coded, when it comes to human\u2013robot communication? For example, when it comes to natural-language communication, multiple layers exist: the phonological, the morphological, the syntactic, the semantic, the pragmatic, the dialogic. And if one adds the complexity of having to address the symbol grounding problem, a robot needs to have models of grounded meaning, too, in a certain target space, for example in a sensorymotor or a teleological target space. This was already discussed in the previous sections of normative vs. empirical meaning and on symbol grounding. Furthermore, such models might need to be adjustable on the fly; as discussed in the section on online negotiation of meaning. Also, many different aspects of non-verbal communication, from facial expressions to gestures to turn-taking, could ideally be learnable in real operation, even more so for the future case of robots needing to adapt to cultural and individual variations in non-verbal communications. Regarding motor aspects of such non-verbal cues, existing methods in imitation and demonstration learning\u00a0 [28] have been and could further be readily adapted; see for example the imitation learning of human facial expressions for the Leonardo robot\u00a0 [201].\n\nFinally, another important caveat needs to be spelt out at this point. Real-world learning and real-world data collection towards communicative behaviour learning for robots, depending on the data set size required, might require many hours of uninterrupted operation daily by numerous robots: a requirement which is quite unrealistic for today\u2019s systems. Therefore, other avenues need to be sought towards acquiring such data sets; and crowdsourcing through specially designed online games offers a realistic potential solution, as mentioned in the previous paragraph on real-world acquisition of large-scale models of grounding. And of course, the learning content of such systems can move beyond grounded meaning models, to a wider range of the what that could be potentially learnable. A relevant example from a non-embodied setting comes from\u00a0 [202], where a chatterbot acquired interaction capabilities through massive observation and interaction with humans in chat rooms. Of course, there do exist inherent limitations in such online systems, even for the case of the robot-tailored online games such as\u00a0 [107]; for example, the non-physicality of the interaction presents specific obstacles and biases. Being able to extend this promising avenue towards wider massive data-driven models, and to demonstrate massive transfer of learning from the online systems to real-world physical robots, is thus an important research avenue for the future.\n\nYet another interesting avenue towards enhanced human\u2013robot communication that has opened up recently is the following: as more and more robots nowadays can be constantly connected to the internet, not all data and programs that the robot uses need to be onboard its hardware. Therefore, a robot could potentially utilize online information as well as online services, in order to enhance its communication abilities. Thus, the intelligence of the robot is partially offloaded to the internet; and potentially, thousands of programs and/or humans could be providing part of its intelligence, even in real-time. For example, going much beyond traditional cloud robotics\u00a0 [203], in the human\u2013robot cloud proposal\u00a0 [204], one could construct on-demand and on-the-fly distributed robots with human and machine sensing, actuation, and processing components.\n\nBeyond these highly promising glimpses of a possible future, there exist a number of implemented systems that utilize information and/or services from the internet. A prime example is Facebots, which are physical robots that utilize and publish information on Facebook towards enhancing long-term human\u2013robot interaction, are described in\u00a0 [66,67]. Facebots are creating shared memories and shared friends with both their physical as well as their online interaction partners, and are utilizing this information towards creating dialogues that enable the creation of a longer-lasting relationship between the robot and its human partners, thus reversing the quick withdrawal of the novelty effects of long-term HRI reported in\u00a0 [205]. Also, as reported in\u00a0 [206], the multilingual conversational robot Ibn Sina\u00a0 [48], has made use of online google translate services, as well as wikipedia information for its dialogues. Furthermore, one could readily utilize online high-quality speech recognition and text-to-speech services for human\u2013robot communication, such as [Sonic Cloud online services], in order not to sacrifice onboard computational resources.\n\nAlso, quite importantly, there exists the European project Roboearth\u00a0 [207], which is described as a World Wide Web for robots: a giant network and database repository where robots can share information and learn from each other about their behaviour and their environment. Bringing a new meaning to the phrase experience is the best teacher, the goal of RoboEarth is to allow robotic systems to benefit from the experience of other robots, paving the way for rapid advances in machine cognition and behaviour, and ultimately, for more subtle and sophisticated human\u2013machine interaction. Rapyuta\u00a0 [208], which is the cloud engine of Roboearth, claims to make immense computational power available to robots connected to it. Of course, beyond what has been utilized so far, there are many other possible sources of information and/or services on the internet to be exploited; and thus much more remains to be done in the near future in this direction.\n\nBeyond the nine desiderata examined so far, there exist a number of other abilities that are required towards fluid and general human\u2013robot communication. These have to do with dealing with multiple conversational partners in a discussion, with support for multilingual capabilities, and with generating and recognizing natural language across multiple modalities: for example not only acoustic, but also in written form. In more detail:\n\nRegarding conversational turn-taking, in the words of Sacks\u00a0 [209], the organization of taking turns to talk is fundamental to conversation, as well as to other speech-exchange systems, and this readily carries over to human\u2013robot conversations, and becomes especially important in the case of dialogues with multiple conversation partners. Recognition of overlapping speech is also quite important towards turn-taking\u00a0 [210]. Regarding turn-taking in robots, a computational strategy for robots participating in group conversation is presented in\u00a0 [211], and the very important role of gaze cues in turn taking and participant role assignment in human\u2013robot conversations is examined in\u00a0 [169]. In\u00a0 [212], an experimental study using the robot Simon is reported, which is aiming towards showing that the implementation of certain turn-taking cues can make interaction with a robot easier and more efficient for humans. Head movements are also very important in turn-taking; the role of which in keeping engagement in an interaction is explored in\u00a0 [213].\n\nYet another requirement for fluid multi-partner conversations is sound-source localization and speaker identification. Sound source localization is usually accomplished using microphone arrays, such as the robotic system in\u00a0 [214]. An approach utilizing scattering theory for sound source localization in robots is described in\u00a0 [215] and approaches using beamforming for multiple moving sources are presented in\u00a0 [216,217]. Finally, HARK, an open-source robot audition system supporting three simultaneous speakers, is presented in\u00a0 [218]. Speaker identification is an old problem; classic approaches utilize Gaussian mixture models, such as\u00a0 [219,220]. Robotic systems able to identify their speakers identity include\u00a0 [221,64], as well as the well-cited\u00a0 [222]. Also, an important idea towards effective signal separation between multiple speaker sources in order to aid in recognition, is to utilize both visual as well as auditory information towards that goal. Classic examples of such approaches include\u00a0 [223], as well as\u00a0 [224].\n\nOf course, special considerations are needed not only in the case of multiple verbal conversational partners, but also multiple interactive communication partners at large, also covering non-verbal components. An example of an assisted care robot serving tea to the elderly which is able to gracefully deal with requests from multiple individuals simultaneously is presented in\u00a0 [47].\n\nYet another desirable ability for human\u2013robot communication is multilinguality. Multilingual robots could not only communicate with a wider range of people, especially in multi-cultural societies and settings such as museums, but could very importantly also act as translators and mediators. Although there has been considerable progress towards non-embodied multilingual dialogue systems\u00a0 [225], and multi-lingual virtual avatars do exist\u00a0 [226,227], the only implemented real-world multilingual physical android robot so far reported in the literature is\u00a0 [206].\n\nFinally, let us move on to examining multiple modalities for the generation and recognition of natural language. Apart from a wealth of existing research on automated production and recognition of sign language for the deaf (ASL)\u00a0 [228\u2013230], systems directly adaptable to robots also exist\u00a0 [231]. One could also investigate the intersection between human writing and robotics. Again, a wealth of approaches exist for the problem of optical character recognition and handwriting recognition\u00a0 [232,233], even for languages such as Arabic\u00a0 [234], the only robotic system that has demonstrated limited OCR capabilities is\u00a0 [206]. Last but not least, another modality available for natural language communication for robots is internet chat. The only reported system so far that could perform dialogues both physically as well as through facebook chat is\u00a0 [66,67].\n\nAs a big part of human knowledge, information, as well as real-world communication is taking place either through writing or through such electronic channels, inevitably more and more systems in the future will have corresponding abilities. Thus, robots will be able to more fluidly integrate within human societies and environments, and ideally will be enabled to utilize the services offered within such networks for humans. Most importantly, robots might also one day become able to help maintain and improve the physical human\u2013robot social networks they reside within towards the benefit of the common good of all, as is advocated in\u00a0 [235].", "title": "A review of verbal and non-verbal human\u2013robot interactive communication"}, "S2589721719300029": {"highlights": ["Several emerging animal temperature measurement techniques are summarized.", "The application status of infrared technology has been analyzed.", "The infrared image processing technology of pigs was analyzed and summarized.", "The advantages, limitations and challenges are analyzed."], "abstract": "Body temperature is an important physiological indicator in the whole process of pig breeding. Temperature measurement is also an effective means to assist in disease diagnosis and pig health monitoring. In the conventional method of measuring body temperature, a mercury column is used to obtain the rectal temperature. The operation of this method is complicated and requires a large amount of labor. This kind of temperature measurement method is contact and can make the pig stressed, which is disadvantageous for the healthy growth of pigs. Therefore, rectal temperature measurement no longer meets the needs of the large-scale pig industry in China's welfare agriculture. In recent years, the emerging pig body temperature detection technologies are electronic temperature measurement technology, infrared temperature measurement technology and so on. Infrared temperature measurement technology has been the main means of measuring the temperature of pig body surface with its advantages of non-contact, long distance and real-time. At present, infrared temperature measurement technology and infrared image processing technology used in pig breeding are still in the exploration stage. Nowadays, the infrared temperature measurement equipment based on point-by-point analysis represented by infrared thermometer and temperature measurement equipment based on full-field analysis represented by infrared thermal imager have been applied to pig breeding industry. These types of temperature measurement are more in line with the needs of the pig breeding industry to transform and upgrade to the automation, in line with the development concept of welfare farming and smart agriculture, and its development prospects are very impressive.", "title": "Study on body temperature detection of pig based on infrared technology: A review"}, "S0957417419302489": {"highlights": ["The paper reviews the features used for latent palmprint identification.", "The paper evaluates the minutiae descriptors used for latent palmprint identification.", "The paper shows that there is room for improvements of the feature representations."], "abstract": "Latent palmprint identification is a crucial element for both law enforcement and integrated automated fingerprint identification systems because approximately 30% of the imprints found in a crime scene originate from a human\u2019s palms. To find the person whom the palmprint belongs to, forensic experts use systems that automatically compare the imprints found, called latent, against thousands of potential palmprints.\n                  Identification systems rely on features obtained from the palmprint, and different feature representations to include discriminative information. However, there is no consensus as to which representation allows for a better matching between latent palmprints, and those with a known identity. Furthermore, evaluating the identification performance when matching palmprints obtained when using different representations has not been done fairly. The current manner of evaluating palmprint identification methods uses different datasets, performance measures, and does not allow to discern the contributions of the feature representation and the methods for matching the palmprints. In this study, we have reviewed those features used for latent palmprint identification, and also we propose an evaluation methodology that allows for a fair comparison of minutiae-based features.\n                  Using our methodology, we evaluated each representation performing more than 5 billion comparisons. Our experiments are done using a dataset that includes information about the matching minutiae according to an expert. We aim with our results to provide a baseline for new research in latent palmprint identification feature representations, allowing for a fair comparison of newly developed representations in the future, which would enhance the whole latent palmprint identification methods. For this purpose, we also publicly provide our dataset, methodology implementation, and the feature representations implementation tested in our experiments.", "title": "A survey on minutiae-based palmprint feature representations, and a full analysis of palmprint feature representation role in latent identification performance"}, "S1875952119300394": {"highlights": ["Robot collaborators elicited a higher physiological arousal and valence, compared to the human ones.", "Comparable decision performance between the human and robot collaborators was found in the serious game.", "Better performance was associated with the robot collaborators compared to the human ones only for the \u2019lower\u2019 physiological arousal group.", "This paper extends the previously published paper with expanded Introduction and Related work with the theory of mind, physiology of affect, models of emotions and their motivation for the measurements of performance in previous work.", "Methodology introduces expanded details on the physiological data collection, reduction and analysis."], "abstract": "Elicited physiological affect in humans collaborating with their robot partners was investigated to determine its influence on decision-making performance in serious games. A turn-taking version of the Tower of Hanoi game was used, where physiological arousal and valence underlying such human-robot proximate collaboration were investigated. A comparable decision performance in the serious game was found between human and non-humanoid robot arm collaborator conditions, while higher physiological affect was found in humans collaborating with such robot collaborators. It is suggested that serious games which are carefully designed to take into consideration the elicited physiological arousal might witness a better decision-making performance and more positive valence using non-humanoid robot partners instead of human ones.", "title": "An affective serious game for collaboration between humans and robots"}}